{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run this cell if you are in colab with a single notebook opened, otherwise ignore this cell\n",
        "\n",
        "!git clone https://github.com/CowboyPhilip/HPML-Energy-Efficient-LLM\n",
        "%cd HPML-Energy-Efficient-LLM \n",
        "!ls\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(\"/content/HPML-Energy-Efficient-LLM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wuNCCRIGboV"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"DeepSeek Energy Consumption Benchmark\n",
        "\n",
        "This notebook measures energy consumption and carbon footprint of LLMs with\n",
        "different quantization methods (FP16, INT8, INT4).\n",
        "Optimized for Google Colab A100 GPU (40GB).\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1arRrz30lcj",
        "outputId": "9e4eb047-e9d6-4d8f-e88b-259f75239ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: zeus-ml in /usr/local/lib/python3.11/dist-packages (0.11.0.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (1.6.1)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (12.570.86)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (2.11.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (13.9.4)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (0.9.19)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (0.28.1)\n",
            "Requirement already satisfied: amdsmi in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (6.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->zeus-ml) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->zeus-ml) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->zeus-ml) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->zeus-ml) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->zeus-ml) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->zeus-ml) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->zeus-ml) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->zeus-ml) (1.17.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->zeus-ml) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->zeus-ml) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->zeus-ml) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->zeus-ml) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->zeus-ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->zeus-ml) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->zeus-ml) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->zeus-ml) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->zeus-ml) (3.6.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->zeus-ml) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->zeus-ml) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->zeus-ml) (4.4.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->zeus-ml) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->zeus-ml) (1.3.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (78.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: zeus-ml in /usr/local/lib/python3.11/dist-packages (0.11.0.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: geocoder in /usr/local/lib/python3.11/dist-packages (1.38.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.11/dist-packages (2.7.4.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (2.2.2)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (12.570.86)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (2.11.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (13.9.4)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (0.9.19)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (0.28.1)\n",
            "Requirement already satisfied: amdsmi in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (6.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from zeus-ml) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geocoder) (8.1.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from geocoder) (1.0.0)\n",
            "Requirement already satisfied: ratelim in /usr/local/lib/python3.11/dist-packages (from geocoder) (0.1.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geocoder) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->zeus-ml) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->zeus-ml) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->zeus-ml) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->zeus-ml) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->zeus-ml) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->zeus-ml) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->zeus-ml) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->zeus-ml) (0.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ratelim->geocoder) (4.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->zeus-ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->zeus-ml) (2.18.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->zeus-ml) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->zeus-ml) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->zeus-ml) (4.4.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->zeus-ml) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->zeus-ml) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install the correct Zeus package in colab\n",
        "!pip install zeus-ml  # The correct package name is zeus-ml, not zeus\n",
        "!pip install --upgrade pip setuptools\n",
        "!pip install transformers \\\n",
        "            bitsandbytes \\\n",
        "            zeus-ml \\\n",
        "            torch \\\n",
        "            datasets \\\n",
        "            evaluate \\\n",
        "            scikit-learn \\\n",
        "            geocoder \\\n",
        "            requests \\\n",
        "            flash-attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVPBch7V0nca",
        "outputId": "1f9c2744-9ea8-4937-cfe4-9abaed7fec34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/vLLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/rocm/lib/libamd_smi.so: cannot open shared object file: No such file or directory\n",
            "Unable to find libamd_smi.so library try installing amd-smi-lib from your package manager\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "GPU device: Tesla T4\n",
            "GPU memory: 15.64 GB\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Environment setup and imports\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from zeus.monitor import ZeusMonitor\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
        "import json\n",
        "import geocoder\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import gc\n",
        "\n",
        "# Clear GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "\n",
        "# Environment variables for better performance\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "os.environ[\"ZEUS_DISABLE_AMD_SMI\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_LLM_INT8_ENABLE_FP32_CPU_OFFLOAD\"] = \"1\"\n",
        "\n",
        "# Check GPU information\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-24_xQNlG1s4"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Memory management utilities\n",
        "from utils.memory_utils import clean_memory, print_gpu_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Kvq8jxkM0q7M"
      },
      "outputs": [],
      "source": [
        "# Cell 4: EnergyTracker and Carbon intensity estimation\n",
        "from utils.energy_utils import EnergyTracker, get_carbon_intensity, joules_to_co2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xa3fOyZr0y6C"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Model loading functions with memory optimization\n",
        "from utils.load_llm import load_llm, load_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sGh7Qm7l03wK"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Text Generation Energy Benchmark\n",
        "from utils.test_generation import compare_generation_energy, quick_test_generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EpWy1K1v9il2"
      },
      "outputs": [],
      "source": [
        "def convert_numpy(obj):\n",
        "    \"\"\"\n",
        "    Recursively convert NumPy types to Python native types for JSON serialization.\n",
        "    \"\"\"\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()  # Convert NumPy array to list\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: convert_numpy(v) for k, v in obj.items()}  # Recursively convert dict\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_numpy(i) for i in obj]  # Recursively convert list\n",
        "    else:\n",
        "        return obj  # Return unchanged if not a NumPy type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_--MOtkq1EtA"
      },
      "outputs": [],
      "source": [
        "# Cell 7: GLUE Task Energy Benchmarking, and GLUE benchmark with different quantization methods\n",
        "from utils.test_glue import run_glue_energy_monitoring, test_quantized_models_on_glue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "CuB47rql1Khy"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Full Benchmark Function\n",
        "def run_full_benchmark(model_name, run_fp16=False):\n",
        "    \"\"\"\n",
        "    Run a full benchmark of both generation and GLUE tasks with different quantization modes\n",
        "\n",
        "    Args:\n",
        "        model_name: HuggingFace model name to benchmark\n",
        "        run_fp16: Whether to include FP16 mode (memory intensive)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with benchmark results\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(f\"RUNNING ENERGY BENCHMARK FOR {model_name}\")\n",
        "    print(\"=\"*80)\n",
        "    results = {}\n",
        "\n",
        "    # Determine modes to test\n",
        "    modes = ['int8', 'int4']\n",
        "    if run_fp16:\n",
        "        modes.insert(0, 'fp16')  # Add fp16 at beginning if requested\n",
        "\n",
        "    # Part 1: Text Generation Benchmark\n",
        "    print(\"\\n\\n==== PART 1: TEXT GENERATION ENERGY BENCHMARK ====\\n\")\n",
        "    prompt = \"DeepSeek AI is an advanced open-source language model designed to power AI applications.\"\n",
        "    generation_results = compare_generation_energy(\n",
        "        model_name=model_name,\n",
        "        prompt=prompt,\n",
        "        quantization_modes=modes,\n",
        "        verbose=True\n",
        "    )\n",
        "    results['generation'] = generation_results\n",
        "\n",
        "    # Part 2: GLUE Tasks Benchmark\n",
        "    print(\"\\n\\n==== PART 2: GLUE TASKS ENERGY BENCHMARK ====\\n\")\n",
        "    glue_tasks = ['sst2']  # Just one task for memory efficiency\n",
        "    glue_results = test_quantized_models_on_glue(\n",
        "        model_name=model_name,\n",
        "        tasks=glue_tasks,\n",
        "        quantization_modes=modes,\n",
        "        batch_size=1  # Single sample batch size\n",
        "    )\n",
        "    results['glue'] = glue_results\n",
        "\n",
        "    # Final Summary\n",
        "    print(\"\\n\\n==== FINAL SUMMARY ====\\n\")\n",
        "    print(\"Comparison of Energy Efficiency Across Tasks and Quantization Modes:\")\n",
        "\n",
        "    # Get carbon intensity for final calculations\n",
        "    carbon_intensity = get_carbon_intensity()\n",
        "\n",
        "    # Calculate total energy and carbon footprint\n",
        "    total_energy = {mode: 0.0 for mode in modes}\n",
        "\n",
        "    # Add generation energy\n",
        "    for mode in modes:\n",
        "        if mode in generation_results and 'total_energy' in generation_results[mode]:\n",
        "            total_energy[mode] += generation_results[mode]['total_energy']\n",
        "\n",
        "    # Add GLUE energy\n",
        "    for task in glue_tasks:\n",
        "        for mode in modes:\n",
        "            if mode in glue_results[task] and 'total_energy' in glue_results[task][mode]:\n",
        "                total_energy[mode] += glue_results[task][mode]['total_energy']\n",
        "\n",
        "    # Print total energy and carbon footprint\n",
        "    print(\"\\nTotal Energy Consumption:\")\n",
        "    for mode in modes:\n",
        "        carbon = joules_to_co2(total_energy[mode], carbon_intensity)\n",
        "        print(f\"{mode.upper()}: {total_energy[mode]:.4f} J = {carbon:.6f} gCO2eq\")\n",
        "\n",
        "    # Calculate energy savings if we have fp16 data\n",
        "    if 'fp16' in modes and total_energy['fp16'] > 0:\n",
        "        baseline = total_energy['fp16']\n",
        "        print(\"\\nTotal Energy Savings:\")\n",
        "        for mode in ['int8', 'int4']:\n",
        "            savings = 100 * (baseline - total_energy[mode]) / baseline\n",
        "            print(f\"{mode.upper()} saves {savings:.2f}% energy compared to FP16\")\n",
        "    elif len(modes) > 1:\n",
        "        # If no fp16, compare to highest energy mode\n",
        "        baseline_mode = max([m for m in modes if total_energy[m] > 0], key=lambda m: total_energy[m])\n",
        "        baseline = total_energy[baseline_mode]\n",
        "        print(f\"\\nTotal Energy Savings (compared to {baseline_mode.upper()}):\")\n",
        "        for mode in modes:\n",
        "            if mode != baseline_mode and total_energy[mode] > 0:\n",
        "                savings = 100 * (baseline - total_energy[mode]) / baseline\n",
        "                print(f\"{mode.upper()} saves {savings:.2f}% energy compared to {baseline_mode.upper()}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tIF-iiA8HzXJ"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Results Visualization Functions\n",
        "from utils.plot_utils import plot_component_energy, plot_energy_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jZ9UFq7H8Q1"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Main execution cell\n",
        "\"\"\"\n",
        "# Set model name\n",
        "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "\n",
        "# Choose one of the following options to run:\n",
        "\n",
        "# Option 1: Quick single-mode test (fastest)\n",
        "quick_test_generation(MODEL_NAME, quant_mode='int4')\n",
        "\n",
        "# Option 2: Generation benchmark with INT8 and INT4 only\n",
        "generation_results = compare_generation_energy(\n",
        "    model_name=MODEL_NAME,\n",
        "    prompt=\"DeepSeek AI is an advanced open-source language model designed to power AI applications.\",\n",
        "    quantization_modes=['int8', 'int4'],\n",
        "    verbose=True\n",
        ")\n",
        "plot_energy_comparison({\"generation\": generation_results})\n",
        "plot_component_energy({\"generation\": generation_results}, task_type='generation', quant_mode='int4')\n",
        "\n",
        "# Option 3: GLUE benchmark with INT8 and INT4 only\n",
        "glue_results = test_quantized_models_on_glue(\n",
        "    model_name=MODEL_NAME,\n",
        "    tasks=['sst2'],\n",
        "    quantization_modes=['int8', 'int4'],\n",
        "    batch_size=1\n",
        ")\n",
        "plot_energy_comparison({\"glue\": glue_results})\n",
        "plot_component_energy({\"glue\": glue_results}, task_type='glue', quant_mode='int4')\n",
        "\n",
        "# Option 4: Full benchmark\n",
        "results = run_full_benchmark(MODEL_NAME, run_fp16=False)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaTdwTyeH8S5"
      },
      "outputs": [],
      "source": [
        "# Cell 14: Usage Instructions\n",
        "\"\"\"\n",
        "# DeepSeek Energy Consumption Benchmark for Google Colab A100 (40GB)\n",
        "\n",
        "This notebook measures energy consumption and carbon footprint of LLMs\n",
        "with different quantization methods (FP16, INT8, INT4).\n",
        "\n",
        "## Instructions for Running on Google Colab\n",
        "\n",
        "1. Run cells 1-12 to set up the environment and define all functions\n",
        "2. In cell 13, uncomment one of the benchmark options:\n",
        "   - Option 1: Quick single-mode test (recommended for initial testing)\n",
        "   - Option 2: Generation benchmark comparing INT8 and INT4\n",
        "   - Option 3: GLUE task benchmark comparing INT8 and INT4\n",
        "   - Option 4: Full benchmark of both tasks\n",
        "3. For FP16 testing (if your memory allows):\n",
        "   - Modify the quantization_modes parameter to include 'fp16'\n",
        "   - Or set run_fp16=True in the full benchmark function\n",
        "\n",
        "## Memory Management Tips\n",
        "\n",
        "- Run one benchmark at a time, not all options simultaneously\n",
        "- Monitor GPU memory usage in Colab (Runtime > Resource usage)\n",
        "- If you encounter OOM errors, try:\n",
        "  1. Restart the runtime to clear all memory\n",
        "  2. Run only INT4 benchmarks first\n",
        "  3. Reduce batch sizes further\n",
        "  4. Use shorter input sequences\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "d7X9o0zKIn5n"
      },
      "outputs": [],
      "source": [
        "# Cell 15: Step-by-step execution examples for Google Colab\n",
        "\n",
        "# Example 1: Testing a single model with INT4 quantization\n",
        "def run_int4_test():\n",
        "    \"\"\"Run a quick test with INT4 quantization only\"\"\"\n",
        "    MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "    print(f\"Running quick test on {MODEL_NAME} with INT4 quantization\")\n",
        "\n",
        "    # Clean memory first\n",
        "    clean_memory()\n",
        "    print_gpu_memory()\n",
        "\n",
        "    # Run generation test\n",
        "    stats = quick_test_generation(MODEL_NAME, quant_mode='int4')\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Example 2: Testing with both INT8 and INT4 on generation task\n",
        "def run_generation_benchmark():\n",
        "    \"\"\"Run generation benchmark with INT8 and INT4\"\"\"\n",
        "    MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "    print(f\"Running generation benchmark on {MODEL_NAME}\")\n",
        "\n",
        "    # Clean memory first\n",
        "    clean_memory()\n",
        "    print_gpu_memory()\n",
        "\n",
        "    # Run benchmark with both quantization modes\n",
        "    generation_results = compare_generation_energy(\n",
        "        model_name=MODEL_NAME,\n",
        "        prompt=\"DeepSeek AI is an advanced open-source language model designed to power AI applications.\",\n",
        "        quantization_modes=['int8', 'int4'],\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Visualize results\n",
        "    try:\n",
        "        plot_energy_comparison({\"generation\": generation_results})\n",
        "        for mode in ['int8', 'int4']:\n",
        "            if mode in generation_results and 'components' in generation_results[mode]:\n",
        "                plot_component_energy({\"generation\": generation_results}, task_type='generation', quant_mode=mode)\n",
        "    except Exception as e:\n",
        "        print(f\"Error plotting results: {e}\")\n",
        "\n",
        "    return generation_results\n",
        "\n",
        "# Example 3: Testing with both INT8 and INT4 on GLUE task\n",
        "def run_glue_benchmark():\n",
        "    \"\"\"Run GLUE benchmark with INT8 and INT4\"\"\"\n",
        "    MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "    print(f\"Running GLUE benchmark on {MODEL_NAME}\")\n",
        "\n",
        "    # Clean memory first\n",
        "    clean_memory()\n",
        "    print_gpu_memory()\n",
        "\n",
        "    # Run benchmark with both quantization modes\n",
        "    glue_results = test_quantized_models_on_glue(\n",
        "        model_name=MODEL_NAME,\n",
        "        tasks=['sst2'],\n",
        "        quantization_modes=['int8', 'int4'],\n",
        "        batch_size=1\n",
        "    )\n",
        "\n",
        "    # Visualize results\n",
        "    try:\n",
        "        plot_energy_comparison({\"glue\": glue_results})\n",
        "        for mode in ['int8', 'int4']:\n",
        "            task = list(glue_results.keys())[0]\n",
        "            if mode in glue_results[task] and 'component_energy' in glue_results[task][mode]:\n",
        "                plot_component_energy({\"glue\": glue_results}, task_type='glue', quant_mode=mode)\n",
        "    except Exception as e:\n",
        "        print(f\"Error plotting results: {e}\")\n",
        "\n",
        "    return glue_results\n",
        "\n",
        "# Example 4: Advanced - Testing with FP16 (if memory allows)\n",
        "def run_fp16_test():\n",
        "    \"\"\"Attempt to run FP16 test with careful memory management\"\"\"\n",
        "    MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "    print(f\"Attempting FP16 test on {MODEL_NAME}\")\n",
        "\n",
        "    # Clean memory thoroughly\n",
        "    clean_memory()\n",
        "    print_gpu_memory()\n",
        "\n",
        "    try:\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        # Load model with aggressive offloading\n",
        "        print(\"Loading model in FP16 mode with aggressive memory offloading...\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME,\n",
        "            torch_dtype=torch.float16,\n",
        "            offload_state_dict=True,\n",
        "            max_memory={0: \"30GB\"},  # Limit GPU memory usage\n",
        "            device_map=\"auto\",\n",
        "            offload_folder=\"offload\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "\n",
        "        print(\"Model loaded. Creating energy tracker...\")\n",
        "        print_gpu_memory()\n",
        "\n",
        "        # Create tracker\n",
        "        tracker = EnergyTracker(model, precision_mode='float16')\n",
        "\n",
        "        # Use a very short prompt\n",
        "        prompt = \"AI model\"\n",
        "        print(f\"Running inference with mini prompt: '{prompt}'\")\n",
        "\n",
        "        # Tokenize with max truncation\n",
        "        tokens = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=16)\n",
        "\n",
        "        # Run inference with minimal input\n",
        "        print(\"Starting energy measurement...\")\n",
        "        _, stats = tracker.measure_text(tokens.input_ids, tokenizer)\n",
        "\n",
        "        # Calculate carbon footprint\n",
        "        carbon_intensity = get_carbon_intensity()\n",
        "        carbon_emissions = joules_to_co2(stats['total_energy'], carbon_intensity)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nResults:\")\n",
        "        print(f\"Total Energy: {stats['total_energy']:.4f} J\")\n",
        "        print(f\"Energy per token: {stats['energy_per_token']:.6f} J/token\")\n",
        "        print(f\"Inference time: {stats['time']:.3f} s\")\n",
        "        print(f\"Carbon emissions: {carbon_emissions:.6f} gCO2eq\")\n",
        "\n",
        "        # Clean up immediately\n",
        "        del model, tracker\n",
        "        clean_memory()\n",
        "        print_gpu_memory()\n",
        "\n",
        "        return stats\n",
        "\n",
        "    except torch.cuda.OutOfMemoryError as e:\n",
        "        print(f\"Out of memory error: {e}\")\n",
        "        print(\"FP16 mode is too memory intensive for this GPU. Try INT8 or INT4 instead.\")\n",
        "        clean_memory()\n",
        "        return {\"error\": \"OOM\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error running FP16 test: {e}\")\n",
        "        clean_memory()\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Example 5: Full benchmark with safe mode\n",
        "def run_safe_full_benchmark():\n",
        "    \"\"\"Run full benchmark with the safest settings\"\"\"\n",
        "    MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "    print(f\"Running full safe benchmark on {MODEL_NAME}\")\n",
        "\n",
        "    # Use only INT4 for best memory efficiency\n",
        "    results = {\n",
        "        'generation': {},\n",
        "        'glue': {}\n",
        "    }\n",
        "\n",
        "    # Clean memory\n",
        "    clean_memory()\n",
        "    print_gpu_memory()\n",
        "\n",
        "    # Part 1: Generation benchmark with INT4 only\n",
        "    print(\"\\n==== PART 1: GENERATION BENCHMARK (INT4) ====\")\n",
        "    gen_results = compare_generation_energy(\n",
        "        model_name=MODEL_NAME,\n",
        "        prompt=\"DeepSeek AI is an advanced language model.\",  # Shorter prompt\n",
        "        quantization_modes=['int4'],\n",
        "        verbose=True\n",
        "    )\n",
        "    results['generation'] = gen_results\n",
        "\n",
        "    # Clean up thoroughly between tests\n",
        "    clean_memory()\n",
        "    print_gpu_memory()\n",
        "\n",
        "    # Part 2: GLUE benchmark with INT4 only\n",
        "    print(\"\\n==== PART 2: GLUE BENCHMARK (INT4) ====\")\n",
        "    glue_results = test_quantized_models_on_glue(\n",
        "        model_name=MODEL_NAME,\n",
        "        tasks=['sst2'],\n",
        "        quantization_modes=['int4'],\n",
        "        batch_size=1\n",
        "    )\n",
        "    results['glue'] = glue_results\n",
        "\n",
        "    # Final cleanup\n",
        "    clean_memory()\n",
        "    print_gpu_memory()\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "VphBi_QII2wt"
      },
      "outputs": [],
      "source": [
        "# Cell 16: Running basic tests to measure memory usage\n",
        "def measure_model_sizes():\n",
        "    \"\"\"Measure memory usage for different quantization modes\"\"\"\n",
        "    MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n",
        "    results = {}\n",
        "\n",
        "    for mode in ['int4', 'int8']:\n",
        "        try:\n",
        "            print(f\"\\n===== Testing {mode.upper()} Mode Memory Usage =====\")\n",
        "\n",
        "            # Clean memory\n",
        "            clean_memory()\n",
        "            print(\"Memory before loading:\")\n",
        "            before = torch.cuda.memory_allocated() / 1e9\n",
        "            print_gpu_memory()\n",
        "\n",
        "            # Load model\n",
        "            if mode == 'int4':\n",
        "                bnb = BitsAndBytesConfig(\n",
        "                    load_in_4bit=True,\n",
        "                    bnb_4bit_quant_type='nf4',\n",
        "                    bnb_4bit_compute_dtype=torch.float16,\n",
        "                    bnb_4bit_use_double_quant=True\n",
        "                )\n",
        "            else:\n",
        "                bnb = BitsAndBytesConfig(\n",
        "                    load_in_8bit=True,\n",
        "                    llm_int8_enable_fp32_cpu_offload=True\n",
        "                )\n",
        "\n",
        "            model = AutoModelForCausalLM.from_pretrained(\n",
        "                MODEL_NAME,\n",
        "                quantization_config=bnb,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,\n",
        "                offload_folder=\"offload\",\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "\n",
        "            # Measure memory\n",
        "            after = torch.cuda.memory_allocated() / 1e9\n",
        "            print(\"Memory after loading:\")\n",
        "            print_gpu_memory()\n",
        "\n",
        "            # Record result\n",
        "            results[mode] = {\n",
        "                'memory_before': before,\n",
        "                'memory_after': after,\n",
        "                'memory_used': after - before\n",
        "            }\n",
        "\n",
        "            # Clean up\n",
        "            del model\n",
        "            clean_memory()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error measuring {mode} mode: {e}\")\n",
        "            results[mode] = {\"error\": str(e)}\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n===== Memory Usage Summary =====\")\n",
        "    for mode in results:\n",
        "        if 'memory_used' in results[mode]:\n",
        "            print(f\"{mode.upper()}: {results[mode]['memory_used']:.2f} GB\")\n",
        "        else:\n",
        "            print(f\"{mode.upper()}: Failed - {results[mode].get('error', 'Unknown error')}\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709,
          "referenced_widgets": [
            "2181aff111534ffcb8a2135ce0eebcb3",
            "99e7217490484dc787603199a9c010ef",
            "23b2354c8fe9472eb8fc2e3fd35ea85b",
            "c8fa98b9a86d4a7b9d061801d99c6322",
            "f842a74d578e4c12b48b42016d42c5db",
            "a91c56525cc44258a8034e67a9256301",
            "443f27f2ab074fe2b80d196a7f18bef5",
            "4898ad2260c244928d90cc7d12df9a50",
            "8542633b8f1d483d88c09499a1f760cd",
            "086ede220eae40cbb89ed0903c113444",
            "36d3d15ccc5a46c2b704c68b4697a5a5"
          ]
        },
        "id": "K9sIuGAdH8VM",
        "outputId": "15e29928-d759-4c54-e742-60f8841fb48b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running quick test on deepseek-ai/DeepSeek-R1-Distill-Qwen-7B with INT4 quantization\n",
            "GPU Memory: Allocated: 0.01 GB | Reserved: 7.69 GB | Max: 41.77 GB\n",
            "Quick test for deepseek-ai/DeepSeek-R1-Distill-Qwen-7B with int4 quantization\n",
            "Starting to load model in INT4 mode...\n",
            "GPU Memory: Allocated: 0.01 GB | Reserved: 7.62 GB | Max: 41.77 GB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2181aff111534ffcb8a2135ce0eebcb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully in INT4 mode\n",
            "GPU Memory: Allocated: 5.57 GB | Reserved: 15.30 GB | Max: 41.77 GB\n",
            "[2025-04-18 23:03:51,190] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
            "[2025-04-18 23:03:51,190] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
            "Successfully initialized ZeusMonitor\n",
            "Running inference with prompt: 'DeepSeek AI is an advanced open-source language model designed to power AI applications.'\n",
            "Location detected: Council Bluffs, US (lat: 41.2619, lon: -95.8608)\n",
            "Using estimated carbon intensity.\n",
            "Using estimated carbon intensity for US: 417 gCO2eq/kWh\n",
            "\n",
            "Results:\n",
            "Total Energy: 46.0221 J\n",
            "Energy per token: 2.707184 J/token\n",
            "Inference time: 0.584 s\n",
            "Carbon emissions: 5.330897 gCO2eq\n",
            "\n",
            "Component Energy Breakdown:\n",
            "  embeddings: 0.1106 J (0.3%)\n",
            "  attention: 16.1398 J (44.8%)\n",
            "  ffn: 19.0231 J (52.8%)\n",
            "  layernorm: 0.1670 J (0.5%)\n",
            "  output_layer: 0.6192 J (1.7%)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'total_energy': 46.0221334354952,\n",
              " 'tokenization_energy': 0.1641334354877472,\n",
              " 'inference_energy': 45.85800000000745,\n",
              " 'energy_per_token': 2.7071843197350116,\n",
              " 'time': 0.583787202835083,\n",
              " 'components': {'embeddings': np.float64(0.11062207818031311),\n",
              "  'attention': np.float64(16.139825305203907),\n",
              "  'ffn': np.float64(19.023129172122573),\n",
              "  'layernorm': np.float64(0.16698828411102296),\n",
              "  'output_layer': np.float64(0.6192181134223939)},\n",
              " 'num_tokens': 17}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To run any of these examples, call the function:\n",
        "run_int4_test()\n",
        "# run_generation_benchmark()\n",
        "# run_glue_benchmark()\n",
        "# run_fp16_test()  # Only if you have enough memory!\n",
        "# run_safe_full_benchmark()\n",
        "# measure_model_sizes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/rocm/lib/libamd_smi.so: cannot open shared object file: No such file or directory\n",
            "Unable to find libamd_smi.so library try installing amd-smi-lib from your package manager\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/vLLM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Location detected: São Paulo, BR (lat: -23.5475, lon: -46.6361)\n",
            "Using estimated carbon intensity.\n",
            "Using estimated carbon intensity for BR: 110 gCO2eq/kWh\n",
            "Carbon intensity: 110 gCO2eq/kWh\n",
            "\n",
            "===== Testing FP16 Mode on MBPP =====\n",
            "Starting to load model in FP16 mode...\n",
            "GPU Memory: Allocated: 0.00 GB | Reserved: 0.00 GB | Max: 0.00 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully in FP16 mode\n",
            "GPU Memory: Allocated: 3.55 GB | Reserved: 3.64 GB | Max: 3.57 GB\n",
            "[2025-04-28 20:28:56,617] [zeus.device.gpu.nvidia](nvidia.py:47) pynvml is available and initialized.\n",
            "[2025-04-28 20:28:56,619] [zeus.device.cpu.rapl](rapl.py:137) RAPL is not supported on this CPU.\n",
            "[2025-04-28 20:28:56,620] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
            "[2025-04-28 20:28:56,621] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
            "Successfully initialized ZeusMonitor\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing FP16:   0%|          | 0/500 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-04-28 20:28:56,630] [zeus.utils.framework](framework.py:25) PyTorch with CUDA support is available.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing FP16: 100%|██████████| 500/500 [04:44<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Summary =====\n",
            "Mode | Avg Energy (J) | Avg Time (s) | Energy/Token (J) | Accuracy (%) | CO2 (gCO2eq)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "FP16 | 25.8369 | 0.567 | 1.524482 | 0.00 | 394.730730\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'fp16': {'examples': [{'prompt': 'Write a python function to remove first and last occurrence of a given character from the string.',\n",
              "    'ground_truth_code': 'def remove_Occ(s,ch): \\r\\n    for i in range(len(s)): \\r\\n        if (s[i] == ch): \\r\\n            s = s[0 : i] + s[i + 1:] \\r\\n            break\\r\\n    for i in range(len(s) - 1,-1,-1):  \\r\\n        if (s[i] == ch): \\r\\n            s = s[0 : i] + s[i + 1:] \\r\\n            break\\r\\n    return s ',\n",
              "    'generated_code': ')\\n\\n the function function that compute all occurrence last elements of a character number in a array, But',\n",
              "    'test_cases': ['assert remove_Occ(\"hello\",\"l\") == \"heo\"',\n",
              "     'assert remove_Occ(\"abcda\",\"a\") == \"bcd\"',\n",
              "     'assert remove_Occ(\"PHP\",\"P\") == \"H\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 33.34395526314038,\n",
              "     'tokenization_energy': 0.1349552631378174,\n",
              "     'inference_energy': 33.20900000000256,\n",
              "     'energy_per_token': 1.7549450138494938,\n",
              "     'time': 1.0944969654083252,\n",
              "     'components': {'embeddings': np.float64(2.6215873243808745),\n",
              "      'attention': np.float64(11.743203427789616),\n",
              "      'ffn': np.float64(16.612953878872215),\n",
              "      'layernorm': np.float64(0.10990307235717774),\n",
              "      'output_layer': np.float64(0.19926694536209108)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to sort a given matrix in ascending order according to the sum of its rows.',\n",
              "    'ground_truth_code': 'def sort_matrix(M):\\r\\n    result = sorted(M, key=sum)\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix matrix into a order, to the sorted of each elements.\\n If',\n",
              "    'test_cases': ['assert sort_matrix([[1, 2, 3], [2, 4, 5], [1, 1, 1]])==[[1, 1, 1], [1, 2, 3], [2, 4, 5]]',\n",
              "     'assert sort_matrix([[1, 2, 3], [-2, 4, -5], [1, -1, 1]])==[[-2, 4, -5], [1, -1, 1], [1, 2, 3]]',\n",
              "     'assert sort_matrix([[5,8,9],[6,4,3],[2,1,4]])==[[2, 1, 4], [6, 4, 3], [5, 8, 9]]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 20.703632746925344,\n",
              "     'tokenization_energy': 0.10763274693489075,\n",
              "     'inference_energy': 20.595999999990454,\n",
              "     'energy_per_token': 1.0351816373462672,\n",
              "     'time': 0.5671670436859131,\n",
              "     'components': {'embeddings': np.float64(0.09986422610282898),\n",
              "      'attention': np.float64(12.188934756268633),\n",
              "      'ffn': np.float64(11.64498573588196),\n",
              "      'layernorm': np.float64(0.11315899968147279),\n",
              "      'output_layer': np.float64(0.20835225939750673)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to count the most common words in a dictionary.',\n",
              "    'ground_truth_code': 'from collections import Counter\\r\\ndef count_common(words):\\r\\n  word_counts = Counter(words)\\r\\n  top_four = word_counts.most_common(4)\\r\\n  return (top_four)\\r\\n',\n",
              "    'generated_code': ')\\n\\n the function that compute the number common numbers in a text, The',\n",
              "    'test_cases': ['assert count_common([\\'red\\',\\'green\\',\\'black\\',\\'pink\\',\\'black\\',\\'white\\',\\'black\\',\\'eyes\\',\\'white\\',\\'black\\',\\'orange\\',\\'pink\\',\\'pink\\',\\'red\\',\\'red\\',\\'white\\',\\'orange\\',\\'white\\',\"black\",\\'pink\\',\\'green\\',\\'green\\',\\'pink\\',\\'green\\',\\'pink\\',\\'white\\',\\'orange\\',\"orange\",\\'red\\']) == [(\\'pink\\', 6), (\\'black\\', 5), (\\'white\\', 5), (\\'red\\', 4)]',\n",
              "     \"assert count_common(['one', 'two', 'three', 'four', 'five', 'one', 'two', 'one', 'three', 'one']) == [('one', 4), ('two', 2), ('three', 2), ('four', 1)]\",\n",
              "     \"assert count_common(['Facebook', 'Apple', 'Amazon', 'Netflix', 'Google', 'Apple', 'Netflix', 'Amazon']) == [('Apple', 2), ('Amazon', 2), ('Netflix', 2), ('Facebook', 1)]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.869290520196664,\n",
              "     'tokenization_energy': 0.11029052019119263,\n",
              "     'inference_energy': 24.75900000000547,\n",
              "     'energy_per_token': 1.7763778942997617,\n",
              "     'time': 0.5660679340362549,\n",
              "     'components': {'embeddings': np.float64(0.12228780984878541),\n",
              "      'attention': np.float64(8.16717302632914),\n",
              "      'ffn': np.float64(7.608418442966533),\n",
              "      'layernorm': np.float64(4.160999999992782),\n",
              "      'output_layer': np.float64(0.18932781600952148)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the volume of a triangular prism.',\n",
              "    'ground_truth_code': 'def find_Volume(l,b,h) : \\r\\n    return ((l * b * h) / 2) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of a cube prism.\\n The',\n",
              "    'test_cases': ['assert find_Volume(10,8,6) == 240',\n",
              "     'assert find_Volume(3,2,2) == 6',\n",
              "     'assert find_Volume(1,2,1) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 20.85281249236979,\n",
              "     'tokenization_energy': 0.10681249237060547,\n",
              "     'inference_energy': 20.745999999999185,\n",
              "     'energy_per_token': 1.489486606597842,\n",
              "     'time': 0.5609734058380127,\n",
              "     'components': {'embeddings': np.float64(0.10770358657836913),\n",
              "      'attention': np.float64(7.953717932702857),\n",
              "      'ffn': np.float64(7.796955329416902),\n",
              "      'layernorm': np.float64(0.11213305234909057),\n",
              "      'output_layer': np.float64(0.19524165201187133)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to split a string at lowercase letters.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef split_lowerstring(text):\\r\\n return (re.findall('[a-z][^a-z]*', text))\",\n",
              "    'generated_code': ')\\n\\n the function that compute a number into every alph, So',\n",
              "    'test_cases': ['assert split_lowerstring(\"AbCd\")==[\\'bC\\',\\'d\\']',\n",
              "     'assert split_lowerstring(\"Python\")==[\\'y\\', \\'t\\', \\'h\\', \\'o\\', \\'n\\']',\n",
              "     'assert split_lowerstring(\"Programming\")==[\\'r\\', \\'o\\', \\'g\\', \\'r\\', \\'a\\', \\'m\\', \\'m\\', \\'i\\', \\'n\\', \\'g\\']'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.982116607672886,\n",
              "     'tokenization_energy': 0.10911660766601562,\n",
              "     'inference_energy': 24.87300000000687,\n",
              "     'energy_per_token': 2.081843050639407,\n",
              "     'time': 0.5631251335144043,\n",
              "     'components': {'embeddings': np.float64(4.120999999999185),\n",
              "      'attention': np.float64(15.898717044116463),\n",
              "      'ffn': np.float64(11.973981043106644),\n",
              "      'layernorm': np.float64(0.11483420038223267),\n",
              "      'output_layer': np.float64(0.19309414577484132)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find sequences of lowercase letters joined with an underscore.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef text_lowercase_underscore(text):\\r\\n        patterns = '^[a-z]+_[a-z]+$'\\r\\n        if re.search(patterns,  text):\\r\\n                return 'Found a match!'\\r\\n        else:\\r\\n                return('Not matched!')\",\n",
              "    'generated_code': ')\\n\\n the function that compute the of consecutive letters that by spaces empty, The',\n",
              "    'test_cases': ['assert text_lowercase_underscore(\"aab_cbbbc\")==(\\'Found a match!\\')',\n",
              "     'assert text_lowercase_underscore(\"aab_Abbbc\")==(\\'Not matched!\\')',\n",
              "     'assert text_lowercase_underscore(\"Aaab_abbbc\")==(\\'Not matched!\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.060531454314944,\n",
              "     'tokenization_energy': 0.10853145432472229,\n",
              "     'inference_energy': 24.95199999999022,\n",
              "     'energy_per_token': 1.6707020969543296,\n",
              "     'time': 0.5600240230560303,\n",
              "     'components': {'embeddings': np.float64(0.11069006848335267),\n",
              "      'attention': np.float64(12.0071914446397),\n",
              "      'ffn': np.float64(11.806986375561449),\n",
              "      'layernorm': np.float64(0.1098237934112549),\n",
              "      'output_layer': np.float64(0.19042500972747803)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the perimeter of a square.',\n",
              "    'ground_truth_code': 'def square_perimeter(a):\\r\\n  perimeter=4*a\\r\\n  return perimeter',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a triangle given The',\n",
              "    'test_cases': ['assert square_perimeter(10)==40',\n",
              "     'assert square_perimeter(5)==20',\n",
              "     'assert square_perimeter(4)==16'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 20.76286250997684,\n",
              "     'tokenization_energy': 0.1198625099658966,\n",
              "     'inference_energy': 20.643000000010943,\n",
              "     'energy_per_token': 1.7302385424980702,\n",
              "     'time': 0.5589742660522461,\n",
              "     'components': {'embeddings': np.float64(0.11632417297363282),\n",
              "      'attention': np.float64(12.051883711092641),\n",
              "      'ffn': np.float64(15.838052672404098),\n",
              "      'layernorm': np.float64(0.11717512965202331),\n",
              "      'output_layer': np.float64(0.19908995151519773)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to remove characters from the first string which are present in the second string.',\n",
              "    'ground_truth_code': \"NO_OF_CHARS = 256\\r\\ndef str_to_list(string): \\r\\n\\ttemp = [] \\r\\n\\tfor x in string: \\r\\n\\t\\ttemp.append(x) \\r\\n\\treturn temp \\r\\ndef lst_to_string(List): \\r\\n\\treturn ''.join(List) \\r\\ndef get_char_count_array(string): \\r\\n\\tcount = [0] * NO_OF_CHARS \\r\\n\\tfor i in string: \\r\\n\\t\\tcount[ord(i)] += 1\\r\\n\\treturn count \\r\\ndef remove_dirty_chars(string, second_string): \\r\\n\\tcount = get_char_count_array(second_string) \\r\\n\\tip_ind = 0\\r\\n\\tres_ind = 0\\r\\n\\ttemp = '' \\r\\n\\tstr_list = str_to_list(string) \\r\\n\\twhile ip_ind != len(str_list): \\r\\n\\t\\ttemp = str_list[ip_ind] \\r\\n\\t\\tif count[ord(temp)] == 0: \\r\\n\\t\\t\\tstr_list[res_ind] = str_list[ip_ind] \\r\\n\\t\\t\\tres_ind += 1\\r\\n\\t\\tip_ind+=1\\r\\n\\treturn lst_to_string(str_list[0:res_ind]) \",\n",
              "    'generated_code': ')\\n\\n the function that compute the from a characters\\n that are also in the second string.\\n So',\n",
              "    'test_cases': ['assert remove_dirty_chars(\"probasscurve\", \"pros\") == \\'bacuve\\'',\n",
              "     'assert remove_dirty_chars(\"digitalindia\", \"talent\") == \\'digiidi\\'',\n",
              "     'assert remove_dirty_chars(\"exoticmiles\", \"toxic\") == \\'emles\\' '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.140309834948276,\n",
              "     'tokenization_energy': 0.1123098349571228,\n",
              "     'inference_energy': 25.027999999991152,\n",
              "     'energy_per_token': 1.323174201839383,\n",
              "     'time': 0.5651454925537109,\n",
              "     'components': {'embeddings': np.float64(0.1136595618724823),\n",
              "      'attention': np.float64(8.073772360574104),\n",
              "      'ffn': np.float64(11.822744584792527),\n",
              "      'layernorm': np.float64(0.15882859659194945),\n",
              "      'output_layer': np.float64(0.2945751616954803)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find whether a given array of integers contains any duplicate element.',\n",
              "    'ground_truth_code': 'def test_duplicate(arraynums):\\r\\n    nums_set = set(arraynums)    \\r\\n    return len(arraynums) != len(nums_set)     ',\n",
              "    'generated_code': ')\\n\\n the function that compute the the given integer of integers is a two numbers(s If',\n",
              "    'test_cases': ['assert test_duplicate(([1,2,3,4,5]))==False',\n",
              "     'assert test_duplicate(([1,2,3,4, 4]))==True',\n",
              "     'assert test_duplicate([1,1,2,2,3,3,4,4,5])==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.228504786487786,\n",
              "     'tokenization_energy': 0.21050478649139404,\n",
              "     'inference_energy': 25.01799999999639,\n",
              "     'energy_per_token': 1.484029693322811,\n",
              "     'time': 0.6000509262084961,\n",
              "     'components': {'embeddings': np.float64(0.11314475679397583),\n",
              "      'attention': np.float64(12.399357452391298),\n",
              "      'ffn': np.float64(7.705914281595614),\n",
              "      'layernorm': np.float64(0.1600278377532959),\n",
              "      'output_layer': np.float64(0.26164332389831546)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to check if the given number is woodball or not.',\n",
              "    'ground_truth_code': 'def is_woodall(x): \\r\\n\\tif (x % 2 == 0): \\r\\n\\t\\treturn False\\r\\n\\tif (x == 1): \\r\\n\\t\\treturn True\\r\\n\\tx = x + 1 \\r\\n\\tp = 0\\r\\n\\twhile (x % 2 == 0): \\r\\n\\t\\tx = x/2\\r\\n\\t\\tp = p + 1\\r\\n\\t\\tif (p == x): \\r\\n\\t\\t\\treturn True\\r\\n\\treturn False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number \\n is a number number not.\\n The',\n",
              "    'test_cases': ['assert is_woodall(383) == True',\n",
              "     'assert is_woodall(254) == False',\n",
              "     'assert is_woodall(200) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.978449441919803,\n",
              "     'tokenization_energy': 0.16144944190979005,\n",
              "     'inference_energy': 24.81700000001001,\n",
              "     'energy_per_token': 1.5611530901199877,\n",
              "     'time': 0.5999424457550049,\n",
              "     'components': {'embeddings': np.float64(0.10931746482849122),\n",
              "      'attention': np.float64(12.728404688837937),\n",
              "      'ffn': np.float64(3.7006446704864504),\n",
              "      'layernorm': np.float64(0.12414227056503296),\n",
              "      'output_layer': np.float64(0.24291633224487305)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find m number of multiples of n.',\n",
              "    'ground_truth_code': 'def multiples_of_num(m,n): \\r\\n    multiples_of_num= list(range(n,(m+1)*n, n)) \\r\\n    return list(multiples_of_num)',\n",
              "    'generated_code': ')\\n\\n the function that compute the such of m of , The',\n",
              "    'test_cases': ['assert multiples_of_num(4,3)== [3,6,9,12]',\n",
              "     'assert multiples_of_num(2,5)== [5,10]',\n",
              "     'assert multiples_of_num(9,2)== [2,4,6,8,10,12,14,16,18]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.949977995875408,\n",
              "     'tokenization_energy': 0.14997799587249758,\n",
              "     'inference_energy': 24.80000000000291,\n",
              "     'energy_per_token': 1.9192290766058007,\n",
              "     'time': 0.5993189811706543,\n",
              "     'components': {'embeddings': np.float64(0.11030205202102662),\n",
              "      'attention': np.float64(12.523229560138889),\n",
              "      'ffn': np.float64(3.6593555631637575),\n",
              "      'layernorm': np.float64(0.12112921237945556),\n",
              "      'output_layer': np.float64(0.2388100790977478)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the first duplicate element in a given array of integers.',\n",
              "    'ground_truth_code': 'def find_first_duplicate(nums):\\r\\n    num_set = set()\\r\\n    no_duplicate = -1\\r\\n\\r\\n    for i in range(len(nums)):\\r\\n\\r\\n        if nums[i] in num_set:\\r\\n            return nums[i]\\r\\n        else:\\r\\n            num_set.add(nums[i])\\r\\n\\r\\n    return no_duplicate',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-order in in an given array of integers, If',\n",
              "    'test_cases': ['assert find_first_duplicate(([1, 2, 3, 4, 4, 5]))==4',\n",
              "     'assert find_first_duplicate([1, 2, 3, 4])==-1',\n",
              "     'assert find_first_duplicate([1, 1, 2, 3, 3, 2, 2])==1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.06235151338484,\n",
              "     'tokenization_energy': 0.1383515133857727,\n",
              "     'inference_energy': 24.92399999999907,\n",
              "     'energy_per_token': 1.4742559713755787,\n",
              "     'time': 0.6110589504241943,\n",
              "     'components': {'embeddings': np.float64(0.11276575994491576),\n",
              "      'attention': np.float64(20.551459459065345),\n",
              "      'ffn': np.float64(3.789224862575531),\n",
              "      'layernorm': np.float64(0.2474571387767792),\n",
              "      'output_layer': np.float64(0.2019213993549347)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find the maximum sum of elements of list in a list of lists.',\n",
              "    'ground_truth_code': 'def maximum_Sum(list1): \\r\\n    maxi = -100000\\r\\n    for x in list1: \\r\\n        sum = 0 \\r\\n        for y in x: \\r\\n            sum+= y      \\r\\n        maxi = max(sum,maxi)     \\r\\n    return maxi ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number of a in a L which way of lists, The',\n",
              "    'test_cases': ['assert maximum_Sum([[1,2,3],[4,5,6],[10,11,12],[7,8,9]]) == 33',\n",
              "     'assert maximum_Sum([[0,1,1],[1,1,2],[3,2,1]]) == 6',\n",
              "     'assert maximum_Sum([[0,1,3],[1,2,1],[9,8,2],[0,1,0],[6,4,8]]) == 19'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.011581764928415,\n",
              "     'tokenization_energy': 0.10458176493644715,\n",
              "     'inference_energy': 24.906999999991967,\n",
              "     'energy_per_token': 1.2505790882464207,\n",
              "     'time': 0.6036655902862549,\n",
              "     'components': {'embeddings': np.float64(0.10895018720626831),\n",
              "      'attention': np.float64(4.637141972541809),\n",
              "      'ffn': np.float64(20.00138893080398),\n",
              "      'layernorm': np.float64(0.12550723743438721),\n",
              "      'output_layer': np.float64(0.21331849479675294)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to convert the given binary number to its decimal equivalent.',\n",
              "    'ground_truth_code': 'def binary_to_decimal(binary): \\r\\n    binary1 = binary \\r\\n    decimal, i, n = 0, 0, 0\\r\\n    while(binary != 0): \\r\\n        dec = binary % 10\\r\\n        decimal = decimal + dec * pow(2, i) \\r\\n        binary = binary//10\\r\\n        i += 1\\r\\n    return (decimal)',\n",
              "    'generated_code': ')\\n\\n the function that compute a digits matrix string to a hexadecimal equivalent.\\n The',\n",
              "    'test_cases': ['assert binary_to_decimal(100) == 4',\n",
              "     'assert binary_to_decimal(1011) == 11',\n",
              "     'assert binary_to_decimal(1101101) == 109'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.223673359868467,\n",
              "     'tokenization_energy': 0.11067335987091065,\n",
              "     'inference_energy': 25.112999999997555,\n",
              "     'energy_per_token': 1.6815782239912311,\n",
              "     'time': 0.5971386432647705,\n",
              "     'components': {'embeddings': np.float64(0.11223213958740234),\n",
              "      'attention': np.float64(8.546106258873714),\n",
              "      'ffn': np.float64(7.975218548292061),\n",
              "      'layernorm': np.float64(0.11965037584304809),\n",
              "      'output_layer': np.float64(0.19357308387756347)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the product of non-repeated elements in a given array.',\n",
              "    'ground_truth_code': 'def find_Product(arr,n): \\r\\n    arr.sort() \\r\\n    prod = 1\\r\\n    for i in range(0,n,1): \\r\\n        if (arr[i - 1] != arr[i]): \\r\\n            prod = prod * arr[i] \\r\\n    return prod; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all-overpeating elements in a matrix matrix.\\n Return',\n",
              "    'test_cases': ['assert find_Product([1,1,2,3],4) == 6',\n",
              "     'assert find_Product([1,2,3,1,1],5) == 6',\n",
              "     'assert find_Product([1,1,4,5,6],5) == 120'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.08383708000765,\n",
              "     'tokenization_energy': 0.10883708000183105,\n",
              "     'inference_energy': 24.97500000000582,\n",
              "     'energy_per_token': 1.3202019515793502,\n",
              "     'time': 0.605797529220581,\n",
              "     'components': {'embeddings': np.float64(0.1261484122276306),\n",
              "      'attention': np.float64(20.47207918500563),\n",
              "      'ffn': np.float64(3.7181529107093807),\n",
              "      'layernorm': np.float64(0.1194472005367279),\n",
              "      'output_layer': np.float64(0.21545672345161437)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to check if the given tuple list has all k elements.',\n",
              "    'ground_truth_code': 'def check_k_elements(test_list, K):\\r\\n  res = True\\r\\n  for tup in test_list:\\r\\n    for ele in tup:\\r\\n      if ele != K:\\r\\n        res = False\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number \\n of is the the consecutive in The',\n",
              "    'test_cases': ['assert check_k_elements([(4, 4), (4, 4, 4), (4, 4), (4, 4, 4, 4), (4, )], 4) == True',\n",
              "     'assert check_k_elements([(7, 7, 7), (7, 7)], 7) == True',\n",
              "     'assert check_k_elements([(9, 9), (9, 9, 9, 9)], 7) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.06798217677942,\n",
              "     'tokenization_energy': 0.10998217678070069,\n",
              "     'inference_energy': 24.95799999999872,\n",
              "     'energy_per_token': 1.5667488860487138,\n",
              "     'time': 0.5909931659698486,\n",
              "     'components': {'embeddings': np.float64(0.12472442603111267),\n",
              "      'attention': np.float64(16.584797102934562),\n",
              "      'ffn': np.float64(7.839096068386338),\n",
              "      'layernorm': np.float64(0.11667958307266237),\n",
              "      'output_layer': np.float64(0.18903276824951173)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to remove all digits from a list of strings.',\n",
              "    'ground_truth_code': \"import re  \\r\\ndef remove(list): \\r\\n    pattern = '[0-9]'\\r\\n    list = [re.sub(pattern, '', i) for i in list] \\r\\n    return list\",\n",
              "    'generated_code': ')\\n\\n the function function that compute all the from a string of integers, So',\n",
              "    'test_cases': [\"assert remove(['4words', '3letters', '4digits']) == ['words', 'letters', 'digits']\",\n",
              "     \"assert remove(['28Jan','12Jan','11Jan']) == ['Jan','Jan','Jan']\",\n",
              "     \"assert remove(['wonder1','wonder2','wonder3']) == ['wonder','wonder','wonder']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.083874659541063,\n",
              "     'tokenization_energy': 0.10587465953826905,\n",
              "     'inference_energy': 24.978000000002794,\n",
              "     'energy_per_token': 1.6722583106360709,\n",
              "     'time': 0.5845093727111816,\n",
              "     'components': {'embeddings': np.float64(0.10810748291015626),\n",
              "      'attention': np.float64(16.48183576060284),\n",
              "      'ffn': np.float64(7.743568175310617),\n",
              "      'layernorm': np.float64(0.1130042839050293),\n",
              "      'output_layer': np.float64(0.1894625015258789)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find binomial co-efficient.',\n",
              "    'ground_truth_code': 'def binomial_Coeff(n,k): \\r\\n    if k > n : \\r\\n       return 0\\r\\n    if k==0 or k ==n : \\r\\n        return 1 \\r\\n    return binomial_Coeff(n-1,k-1) + binomial_Coeff(n-1,k) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute theomial coefficientse C Write',\n",
              "    'test_cases': ['assert binomial_Coeff(5,2) == 10',\n",
              "     'assert binomial_Coeff(4,3) == 4',\n",
              "     'assert binomial_Coeff(3,2) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.18779752564826,\n",
              "     'tokenization_energy': 0.11479752564430236,\n",
              "     'inference_energy': 21.073000000003958,\n",
              "     'energy_per_token': 1.7656497938040216,\n",
              "     'time': 0.5589747428894043,\n",
              "     'components': {'embeddings': np.float64(0.10969830751419067),\n",
              "      'attention': np.float64(12.42769894170447),\n",
              "      'ffn': np.float64(12.123256836654154),\n",
              "      'layernorm': np.float64(0.11004049229621889),\n",
              "      'output_layer': np.float64(0.18534535861015322)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to find the element occurring odd number of times.',\n",
              "    'ground_truth_code': 'def get_Odd_Occurrence(arr,arr_size):   \\r\\n    for i in range(0,arr_size): \\r\\n        count = 0\\r\\n        for j in range(0,arr_size): \\r\\n            if arr[i] == arr[j]: \\r\\n                count+=1     \\r\\n        if (count % 2 != 0): \\r\\n            return arr[i]     \\r\\n    return -1',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number in the number of times in \\n',\n",
              "    'test_cases': ['assert get_Odd_Occurrence([1,2,3,1,2,3,1],7) == 1',\n",
              "     'assert get_Odd_Occurrence([1,2,3,2,3,1,3],7) == 3',\n",
              "     'assert get_Odd_Occurrence([2,3,5,4,5,2,4,3,5,2,4,4,2],13) == 5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.192227747919386,\n",
              "     'tokenization_energy': 0.1992277479171753,\n",
              "     'inference_energy': 20.993000000002212,\n",
              "     'energy_per_token': 1.4128151831946256,\n",
              "     'time': 0.5624024868011475,\n",
              "     'components': {'embeddings': np.float64(0.10988991737365723),\n",
              "      'attention': np.float64(12.339237493754714),\n",
              "      'ffn': np.float64(7.846568349590989),\n",
              "      'layernorm': np.float64(0.11349773025512695),\n",
              "      'output_layer': np.float64(0.20081368875503539)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to count all the substrings starting and ending with same characters.',\n",
              "    'ground_truth_code': 'def check_Equality(s): \\r\\n    return (ord(s[0]) == ord(s[len(s) - 1])); \\r\\ndef count_Substring_With_Equal_Ends(s): \\r\\n    result = 0; \\r\\n    n = len(s); \\r\\n    for i in range(n): \\r\\n        for j in range(1,n-i+1):  \\r\\n            if (check_Equality(s[i:i+j])): \\r\\n                result+=1; \\r\\n    return result; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the the possibleings of with ending with the character in So',\n",
              "    'test_cases': ['assert count_Substring_With_Equal_Ends(\"abc\") == 3',\n",
              "     'assert count_Substring_With_Equal_Ends(\"abcda\") == 6',\n",
              "     'assert count_Substring_With_Equal_Ends(\"ab\") == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.29926380586473,\n",
              "     'tokenization_energy': 0.11026380586624146,\n",
              "     'inference_energy': 25.188999999998487,\n",
              "     'energy_per_token': 1.4055146558813738,\n",
              "     'time': 0.5616700649261475,\n",
              "     'components': {'embeddings': np.float64(0.10822132730484009),\n",
              "      'attention': np.float64(4.2836168861389154),\n",
              "      'ffn': np.float64(7.922129185909404),\n",
              "      'layernorm': np.float64(4.283999999999651),\n",
              "      'output_layer': np.float64(0.20705430316925047)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the top k integers that occur most frequently from given lists of sorted and distinct integers using heap queue algorithm.',\n",
              "    'ground_truth_code': 'def func(nums, k):\\r\\n    import collections\\r\\n    d = collections.defaultdict(int)\\r\\n    for row in nums:\\r\\n        for i in row:\\r\\n            d[i] += 1\\r\\n    temp = []\\r\\n    import heapq\\r\\n    for key, v in d.items():\\r\\n        if len(temp) < k:\\r\\n            temp.append((v, key))\\r\\n            if len(temp) == k:\\r\\n                heapq.heapify(temp)\\r\\n        else:\\r\\n            if v > temp[0][0]:\\r\\n                heapq.heappop(temp)\\r\\n                heapq.heappush(temp, (v, key))\\r\\n    result = []\\r\\n    while temp:\\r\\n        v, key = heapq.heappop(temp)\\r\\n        result.append(key)\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum K smallest in are in frequently, a integers of integers integers...\\n integers. a-baseding.\\n Return',\n",
              "    'test_cases': ['assert func([[1, 2, 6], [1, 3, 4, 5, 7, 8], [1, 3, 5, 6, 8, 9], [2, 5, 7, 11], [1, 4, 7, 8, 12]],3)==[5, 7, 1]',\n",
              "     'assert func([[1, 2, 6], [1, 3, 4, 5, 7, 8], [1, 3, 5, 6, 8, 9], [2, 5, 7, 11], [1, 4, 7, 8, 12]],1)==[1]',\n",
              "     'assert func([[1, 2, 6], [1, 3, 4, 5, 7, 8], [1, 3, 5, 6, 8, 9], [2, 5, 7, 11], [1, 4, 7, 8, 12]],5)==[6, 5, 7, 8, 1]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.041125464205514,\n",
              "     'tokenization_energy': 0.1081254642009735,\n",
              "     'inference_energy': 20.93300000000454,\n",
              "     'energy_per_token': 0.7793009431187228,\n",
              "     'time': 0.5619375705718994,\n",
              "     'components': {'embeddings': np.float64(0.10750434136390685),\n",
              "      'attention': np.float64(8.183410080444185),\n",
              "      'ffn': np.float64(12.130046723597335),\n",
              "      'layernorm': np.float64(0.1747080373764038),\n",
              "      'output_layer': np.float64(0.21278294563293457)},\n",
              "     'num_tokens': 27}},\n",
              "   {'prompt': 'Write a python function to find the largest prime factor of a given number.',\n",
              "    'ground_truth_code': 'import math \\r\\ndef max_Prime_Factors (n): \\r\\n    maxPrime = -1 \\r\\n    while n%2 == 0: \\r\\n        maxPrime = 2\\r\\n        n >>= 1    \\r\\n    for i in range(3,int(math.sqrt(n))+1,2): \\r\\n        while n % i == 0: \\r\\n            maxPrime = i \\r\\n            n = n / i \\r\\n    if n > 2: \\r\\n        maxPrime = n  \\r\\n    return int(maxPrime)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number prime factor of a number integer n The',\n",
              "    'test_cases': ['assert max_Prime_Factors(15) == 5',\n",
              "     'assert max_Prime_Factors(6) == 3',\n",
              "     'assert max_Prime_Factors(2) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.432827386863064,\n",
              "     'tokenization_energy': 0.1128273868560791,\n",
              "     'inference_energy': 25.320000000006985,\n",
              "     'energy_per_token': 1.5895517116789415,\n",
              "     'time': 0.5543932914733887,\n",
              "     'components': {'embeddings': np.float64(4.370999999999185),\n",
              "      'attention': np.float64(16.153894908436342),\n",
              "      'ffn': np.float64(11.841371308087954),\n",
              "      'layernorm': np.float64(0.11160459899902343),\n",
              "      'output_layer': np.float64(0.18891197204589844)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to convert a decimal number to binary number.',\n",
              "    'ground_truth_code': 'def decimal_To_Binary(N): \\r\\n    B_Number = 0\\r\\n    cnt = 0\\r\\n    while (N != 0): \\r\\n        rem = N % 2\\r\\n        c = pow(10,cnt)  \\r\\n        B_Number += rem*c  \\r\\n        N //= 2 \\r\\n        cnt += 1\\r\\n    return B_Number  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute a given number to a.\\n.\\n The',\n",
              "    'test_cases': ['assert decimal_To_Binary(10) == 1010',\n",
              "     'assert decimal_To_Binary(1) == 1',\n",
              "     'assert decimal_To_Binary(20) == 10100'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.2013669624225,\n",
              "     'tokenization_energy': 0.10936696243286133,\n",
              "     'inference_energy': 21.09199999998964,\n",
              "     'energy_per_token': 1.5143833544587502,\n",
              "     'time': 0.5545713901519775,\n",
              "     'components': {'embeddings': np.float64(0.10790160751342773),\n",
              "      'attention': np.float64(16.299171025497838),\n",
              "      'ffn': np.float64(11.9467339091365),\n",
              "      'layernorm': np.float64(0.11071515440940856),\n",
              "      'output_layer': np.float64(0.247262864112854)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the missing number in a sorted array.',\n",
              "    'ground_truth_code': 'def find_missing(ar,N): \\r\\n    l = 0\\r\\n    r = N - 1\\r\\n    while (l <= r):  \\r\\n        mid = (l + r) / 2\\r\\n        mid= int (mid) \\r\\n        if (ar[mid] != mid + 1 and ar[mid - 1] == mid): \\r\\n            return (mid + 1)  \\r\\n        elif (ar[mid] != mid + 1): \\r\\n            r = mid - 1 \\r\\n        else: \\r\\n            l = mid + 1\\r\\n    return (-1) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number in a sequence array of The',\n",
              "    'test_cases': ['assert find_missing([1,2,3,5],4) == 4',\n",
              "     'assert find_missing([1,3,4,5],4) == 2',\n",
              "     'assert find_missing([1,2,3,5,6,7],5) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.02191269301693,\n",
              "     'tokenization_energy': 0.19791269302368164,\n",
              "     'inference_energy': 20.823999999993248,\n",
              "     'energy_per_token': 1.4014608462011287,\n",
              "     'time': 0.5598633289337158,\n",
              "     'components': {'embeddings': np.float64(0.1091705322265625),\n",
              "      'attention': np.float64(12.156529315947438),\n",
              "      'ffn': np.float64(7.953067902800277),\n",
              "      'layernorm': np.float64(0.11310867547988893),\n",
              "      'output_layer': np.float64(0.19071865916252137)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the n-th rectangular number.',\n",
              "    'ground_truth_code': 'def find_rect_num(n):\\r\\n  return n*(n + 1) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-th root number, The',\n",
              "    'test_cases': ['assert find_rect_num(4) == 20',\n",
              "     'assert find_rect_num(5) == 30',\n",
              "     'assert find_rect_num(6) == 42'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.43033726358728,\n",
              "     'tokenization_energy': 0.11133726358413697,\n",
              "     'inference_energy': 25.319000000003143,\n",
              "     'energy_per_token': 2.119194771965607,\n",
              "     'time': 0.5580298900604248,\n",
              "     'components': {'embeddings': np.float64(0.10793534755706788),\n",
              "      'attention': np.float64(16.21716061376815),\n",
              "      'ffn': np.float64(12.099085332639515),\n",
              "      'layernorm': np.float64(0.11355214691162109),\n",
              "      'output_layer': np.float64(4.228000000002794)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to find the nth digit in the proper fraction of two given numbers.',\n",
              "    'ground_truth_code': 'def find_Nth_Digit(p,q,N) :  \\r\\n    while (N > 0) : \\r\\n        N -= 1;  \\r\\n        p *= 10;  \\r\\n        res = p // q;  \\r\\n        p %= q;  \\r\\n    return res;  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number term in a sequence sequence representation a digits integers, The',\n",
              "    'test_cases': ['assert find_Nth_Digit(1,2,1) == 5',\n",
              "     'assert find_Nth_Digit(3,5,1) == 6',\n",
              "     'assert find_Nth_Digit(5,6,5) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.296841245647403,\n",
              "     'tokenization_energy': 0.17284124565124512,\n",
              "     'inference_energy': 21.12399999999616,\n",
              "     'energy_per_token': 1.1208863813498633,\n",
              "     'time': 0.5608201026916504,\n",
              "     'components': {'embeddings': np.float64(0.10737732911109925),\n",
              "      'attention': np.float64(12.296528309103103),\n",
              "      'ffn': np.float64(12.180411781544914),\n",
              "      'layernorm': np.float64(0.11523597049713134),\n",
              "      'output_layer': np.float64(0.20674393486976622)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to sort a given mixed list of integers and strings.',\n",
              "    'ground_truth_code': 'def sort_mixed_list(mixed_list):\\r\\n    int_part = sorted([i for i in mixed_list if type(i) is int])\\r\\n    str_part = sorted([i for i in mixed_list if type(i) is str])\\r\\n    return int_part + str_part',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix matrix array of integers and strings in The',\n",
              "    'test_cases': [\"assert sort_mixed_list([19,'red',12,'green','blue', 10,'white','green',1])==[1, 10, 12, 19, 'blue', 'green', 'green', 'red', 'white']\",\n",
              "     \"assert sort_mixed_list([19,'red',12,'green','blue', 10,'white','green',1])==[1, 10, 12, 19, 'blue', 'green', 'green', 'red', 'white']\",\n",
              "     \"assert sort_mixed_list([19,'red',12,'green','blue', 10,'white','green',1])==[1, 10, 12, 19, 'blue', 'green', 'green', 'red', 'white']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.458275481699033,\n",
              "     'tokenization_energy': 0.11027548170089721,\n",
              "     'inference_energy': 25.347999999998137,\n",
              "     'energy_per_token': 1.6972183654466022,\n",
              "     'time': 0.5658872127532959,\n",
              "     'components': {'embeddings': np.float64(0.10863872122764587),\n",
              "      'attention': np.float64(8.419397698872256),\n",
              "      'ffn': np.float64(8.002691787252552),\n",
              "      'layernorm': np.float64(0.1723182249069214),\n",
              "      'output_layer': np.float64(0.19097707986831663)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the division of first even and odd number of a given list.',\n",
              "    'ground_truth_code': 'def div_even_odd(list1):\\r\\n    first_even = next((el for el in list1 if el%2==0),-1)\\r\\n    first_odd = next((el for el in list1 if el%2!=0),-1)\\r\\n    return (first_even/first_odd)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a n number second numbers in the given array.\\n The',\n",
              "    'test_cases': ['assert div_even_odd([1,3,5,7,4,1,6,8])==4',\n",
              "     'assert div_even_odd([1,2,3,4,5,6,7,8,9,10])==2',\n",
              "     'assert div_even_odd([1,5,7,9,10])==10'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.502679468631978,\n",
              "     'tokenization_energy': 0.10867946863174438,\n",
              "     'inference_energy': 25.394000000000233,\n",
              "     'energy_per_token': 1.3422462878227357,\n",
              "     'time': 0.562222957611084,\n",
              "     'components': {'embeddings': np.float64(0.10886190176010131),\n",
              "      'attention': np.float64(12.149222066651214),\n",
              "      'ffn': np.float64(16.248780127751058),\n",
              "      'layernorm': np.float64(0.1697245388031006),\n",
              "      'output_layer': np.float64(0.2014239091873169)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to check if the letters of a given string can be rearranged so that two characters that are adjacent to each other are different.',\n",
              "    'ground_truth_code': 'import heapq\\r\\nfrom collections import Counter\\r\\ndef rearange_string(S):\\r\\n    ctr = Counter(S)\\r\\n    heap = [(-value, key) for key, value in ctr.items()]\\r\\n    heapq.heapify(heap)\\r\\n    if (-heap[0][0]) * 2 > len(S) + 1: \\r\\n        return \"\"\\r\\n    ans = []\\r\\n    while len(heap) >= 2:\\r\\n        nct1, char1 = heapq.heappop(heap)\\r\\n        nct2, char2 = heapq.heappop(heap)\\r\\n        ans.extend([char1, char2])\\r\\n        if nct1 + 1: heapq.heappush(heap, (nct1 + 1, char1))\\r\\n        if nct2 + 1: heapq.heappush(heap, (nct2 + 1, char2))\\r\\n    return \"\".join(ans) + (heap[0][1] if heap else \"\")',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number in a given string can form rearranged to that the\\n are are the to each other are different.\\n So',\n",
              "    'test_cases': ['assert rearange_string(\"aab\")==(\\'aba\\')',\n",
              "     'assert rearange_string(\"aabb\")==(\\'abab\\')',\n",
              "     'assert rearange_string(\"abccdd\")==(\\'cdabcd\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.108186277386267,\n",
              "     'tokenization_energy': 0.12418627738952637,\n",
              "     'inference_energy': 20.98399999999674,\n",
              "     'energy_per_token': 0.7036062092462089,\n",
              "     'time': 0.5681252479553223,\n",
              "     'components': {'embeddings': np.float64(0.18434599041938782),\n",
              "      'attention': np.float64(16.508112346649053),\n",
              "      'ffn': np.float64(7.907511659622308),\n",
              "      'layernorm': np.float64(0.11399443674087525),\n",
              "      'output_layer': np.float64(0.2812739729881287)},\n",
              "     'num_tokens': 30}},\n",
              "   {'prompt': 'Write a function to find frequency of the elements in a given list of lists using collections module.',\n",
              "    'ground_truth_code': 'from collections import Counter\\r\\nfrom itertools import chain\\r\\ndef freq_element(nums):\\r\\n  result = Counter(chain.from_iterable(nums))\\r\\n  return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the of each digits in a matrix array.\\n integers.\\n\\n the..\\n The',\n",
              "    'test_cases': ['assert freq_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]])==({2: 3, 1: 2, 5: 2, 3: 1, 4: 1, 6: 1, 7: 1, 9: 1})',\n",
              "     'assert freq_element([[1,2,3,4],[5,6,7,8],[9,10,11,12]])==({1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1})',\n",
              "     'assert freq_element([[15,20,30,40],[80,90,100,110],[30,30,80,90]])==({30: 3, 80: 2, 90: 2, 15: 1, 20: 1, 40: 1, 100: 1, 110: 1})'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.622158914098982,\n",
              "     'tokenization_energy': 0.1991589140892029,\n",
              "     'inference_energy': 25.42300000000978,\n",
              "     'energy_per_token': 1.281107945704949,\n",
              "     'time': 0.5666944980621338,\n",
              "     'components': {'embeddings': np.float64(0.10764646434783937),\n",
              "      'attention': np.float64(12.496882138496614),\n",
              "      'ffn': np.float64(12.192883992186514),\n",
              "      'layernorm': np.float64(0.11434934616088867),\n",
              "      'output_layer': np.float64(0.20564373970031738)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to filter even numbers using lambda function.',\n",
              "    'ground_truth_code': 'def filter_evennumbers(nums):\\r\\n even_nums = list(filter(lambda x: x%2 == 0, nums))\\r\\n return even_nums',\n",
              "    'generated_code': ')\\n\\n the function that compute the numbers from the expressions in The',\n",
              "    'test_cases': ['assert filter_evennumbers([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[2, 4, 6, 8, 10]',\n",
              "     'assert filter_evennumbers([10,20,45,67,84,93])==[10,20,84]',\n",
              "     'assert filter_evennumbers([5,7,9,8,6,4,3])==[8,6,4]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.291841250890283,\n",
              "     'tokenization_energy': 0.10784125089645386,\n",
              "     'inference_energy': 25.18399999999383,\n",
              "     'energy_per_token': 2.10765343757419,\n",
              "     'time': 0.5668158531188965,\n",
              "     'components': {'embeddings': np.float64(0.10878678560256957),\n",
              "      'attention': np.float64(8.279072793003522),\n",
              "      'ffn': np.float64(7.940328732246183),\n",
              "      'layernorm': np.float64(0.1263836498260498),\n",
              "      'output_layer': np.float64(4.244999999995343)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to find the sum of repeated elements in a given array.',\n",
              "    'ground_truth_code': 'def find_Sum(arr,n): \\r\\n    return sum([x for x in arr if arr.count(x) > 1])',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all elements in a list array.\\n The',\n",
              "    'test_cases': ['assert find_Sum([1,2,3,1,1,4,5,6],8) == 3',\n",
              "     'assert find_Sum([1,2,3,1,1],5) == 3',\n",
              "     'assert find_Sum([1,1,2],3) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.38177468729869,\n",
              "     'tokenization_energy': 0.12577468729019167,\n",
              "     'inference_energy': 21.2560000000085,\n",
              "     'energy_per_token': 1.2577514521940407,\n",
              "     'time': 0.5643618106842041,\n",
              "     'components': {'embeddings': np.float64(0.12568153810501098),\n",
              "      'attention': np.float64(8.68487826919637),\n",
              "      'ffn': np.float64(12.284507931006722),\n",
              "      'layernorm': np.float64(0.11037189722061157),\n",
              "      'output_layer': np.float64(0.25738404750823973)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find sequences of lowercase letters joined with an underscore using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef text_match(text):\\r\\n  patterns = '^[a-z]+_[a-z]+$'\\r\\n  if re.search(patterns,  text):\\r\\n    return ('Found a match!')\\r\\n  else:\\r\\n    return ('Not matched!')\",\n",
              "    'generated_code': ')\\n\\n the function that compute the of consecutive letters that by spaces empty, the.\\n The',\n",
              "    'test_cases': ['assert text_match(\"aab_cbbbc\") == \\'Found a match!\\'',\n",
              "     'assert text_match(\"aab_Abbbc\") == \\'Not matched!\\'',\n",
              "     'assert text_match(\"Aaab_abbbc\") == \\'Not matched!\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.398733021488297,\n",
              "     'tokenization_energy': 0.10573302149772644,\n",
              "     'inference_energy': 25.29299999999057,\n",
              "     'energy_per_token': 1.4940431189110763,\n",
              "     'time': 0.5701446533203125,\n",
              "     'components': {'embeddings': np.float64(0.11984579563140868),\n",
              "      'attention': np.float64(8.256464722399018),\n",
              "      'ffn': np.float64(8.332921067240763),\n",
              "      'layernorm': np.float64(0.167849951505661),\n",
              "      'output_layer': np.float64(0.20345719170570373)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function that matches a word at the beginning of a string.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef text_match_string(text):\\r\\n        patterns = '^\\\\w+'\\r\\n        if re.search(patterns,  text):\\r\\n                return 'Found a match!'\\r\\n        else:\\r\\n                return 'Not matched!'\",\n",
              "    'generated_code': ')\\n\\n the function that, the given by the same and the word, So',\n",
              "    'test_cases': ['assert text_match_string(\" python\")==(\\'Not matched!\\')',\n",
              "     'assert text_match_string(\"python\")==(\\'Found a match!\\')',\n",
              "     'assert text_match_string(\"  lang\")==(\\'Not matched!\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.559395227202447,\n",
              "     'tokenization_energy': 0.10639522719383239,\n",
              "     'inference_energy': 25.453000000008615,\n",
              "     'energy_per_token': 1.7039596818134966,\n",
              "     'time': 0.5631873607635498,\n",
              "     'components': {'embeddings': np.float64(0.10774413657188416),\n",
              "      'attention': np.float64(8.4975697917972),\n",
              "      'ffn': np.float64(8.13904217958916),\n",
              "      'layernorm': np.float64(0.11466935634613036),\n",
              "      'output_layer': np.float64(4.2960000000020955)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the gcd of the given array elements.',\n",
              "    'ground_truth_code': 'def find_gcd(x, y): \\r\\n\\twhile(y): \\r\\n\\t\\tx, y = y, x % y \\r\\n\\treturn x \\r\\ndef get_gcd(l):\\r\\n  num1 = l[0]\\r\\n  num2 = l[1]\\r\\n  gcd = find_gcd(num1, num2)\\r\\n  for i in range(2, len(l)):\\r\\n    gcd = find_gcd(gcd, l[i])\\r\\n  return gcd',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of two two integers of.\\n Return',\n",
              "    'test_cases': ['assert get_gcd([2, 4, 6, 8, 16]) == 2',\n",
              "     'assert get_gcd([1, 2, 3]) == 1',\n",
              "     'assert get_gcd([2, 4, 6, 8]) == 2 '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.157019751300222,\n",
              "     'tokenization_energy': 0.1710197513103485,\n",
              "     'inference_energy': 20.985999999989872,\n",
              "     'energy_per_token': 1.5112156965214445,\n",
              "     'time': 0.560096025466919,\n",
              "     'components': {'embeddings': np.float64(0.12605849981307982),\n",
              "      'attention': np.float64(4.269733780384064),\n",
              "      'ffn': np.float64(8.215539053435204),\n",
              "      'layernorm': np.float64(0.11139759635925293),\n",
              "      'output_layer': np.float64(0.1892423005104065)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to determine whether all the numbers are different from each other are not.',\n",
              "    'ground_truth_code': 'def test_distinct(data):\\r\\n  if len(data) == len(set(data)):\\r\\n    return True\\r\\n  else:\\r\\n    return False;',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a the elements in even in each other in in in If',\n",
              "    'test_cases': ['assert test_distinct([1,5,7,9]) == True',\n",
              "     'assert test_distinct([2,4,5,5,7,9]) == False',\n",
              "     'assert test_distinct([1,2,3]) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.65138919735851,\n",
              "     'tokenization_energy': 0.10738919734954834,\n",
              "     'inference_energy': 25.544000000008964,\n",
              "     'energy_per_token': 1.350073115650448,\n",
              "     'time': 0.5672106742858887,\n",
              "     'components': {'embeddings': np.float64(0.10906434917449952),\n",
              "      'attention': np.float64(16.69697664999834),\n",
              "      'ffn': np.float64(12.464558811435591),\n",
              "      'layernorm': np.float64(0.11411798238754273),\n",
              "      'output_layer': np.float64(0.2673638796806335)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to find the last digit when factorial of a divides factorial of b.',\n",
              "    'ground_truth_code': 'def compute_Last_Digit(A,B): \\r\\n    variable = 1\\r\\n    if (A == B): \\r\\n        return 1\\r\\n    elif ((B - A) >= 5):  \\r\\n        return 0\\r\\n    else:   \\r\\n        for i in range(A + 1,B + 1): \\r\\n            variable = (variable * (i % 10)) % 10\\r\\n        return variable % 10',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number digit of the of n number by of b.\\n So',\n",
              "    'test_cases': ['assert compute_Last_Digit(2,4) == 2',\n",
              "     'assert compute_Last_Digit(6,8) == 6',\n",
              "     'assert compute_Last_Digit(1,2) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.4216566324234,\n",
              "     'tokenization_energy': 0.17165663242340087,\n",
              "     'inference_energy': 21.25,\n",
              "     'energy_per_token': 1.1274556122328105,\n",
              "     'time': 0.5553224086761475,\n",
              "     'components': {'embeddings': np.float64(0.11068893194198608),\n",
              "      'attention': np.float64(12.349720744857914),\n",
              "      'ffn': np.float64(8.129451212160639),\n",
              "      'layernorm': np.float64(0.11674614667892455),\n",
              "      'output_layer': np.float64(0.2142089855670929)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to set all odd bits of a given number.',\n",
              "    'ground_truth_code': 'def odd_bit_set_number(n):\\r\\n    count = 0;res = 0;temp = n\\r\\n    while temp > 0:\\r\\n        if count % 2 == 0:\\r\\n            res |= (1 << count)\\r\\n        count += 1\\r\\n        temp >>= 1\\r\\n    return (n | res)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the the numbers to a number integer to So',\n",
              "    'test_cases': ['assert odd_bit_set_number(10) == 15',\n",
              "     'assert odd_bit_set_number(20) == 21',\n",
              "     'assert odd_bit_set_number(30) == 31'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.406999999991967,\n",
              "     'tokenization_energy': 4.298999999999069,\n",
              "     'inference_energy': 21.1079999999929,\n",
              "     'energy_per_token': 1.6937999999994644,\n",
              "     'time': 0.5591409206390381,\n",
              "     'components': {'embeddings': np.float64(0.11604027271270752),\n",
              "      'attention': np.float64(8.338123363970661),\n",
              "      'ffn': np.float64(8.043109714270802),\n",
              "      'layernorm': np.float64(0.11192656874656678),\n",
              "      'output_layer': np.float64(0.1869513466358185)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to extract every first or specified element from a given two-dimensional list.',\n",
              "    'ground_truth_code': 'def specified_element(nums, N):\\r\\n    result = [i[N] for i in nums]\\r\\n    return result\\r\\n    ',\n",
              "    'generated_code': ')\\n\\n the function that compute the\\n-order second number from a given matrix-dimensional array.\\n The',\n",
              "    'test_cases': ['assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],0)==[1, 4, 7]',\n",
              "     'assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],2)==[3, 6, 9]',\n",
              "     'assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],1)==[2,5,1]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.654672862528823,\n",
              "     'tokenization_energy': 0.10567286252975465,\n",
              "     'inference_energy': 25.54899999999907,\n",
              "     'energy_per_token': 1.4252596034738234,\n",
              "     'time': 0.5599648952484131,\n",
              "     'components': {'embeddings': np.float64(0.10645088267326355),\n",
              "      'attention': np.float64(12.579740923887584),\n",
              "      'ffn': np.float64(8.122066293474287),\n",
              "      'layernorm': np.float64(0.11297663855552673),\n",
              "      'output_layer': np.float64(4.296999999991385)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the list with minimum length using lambda function.',\n",
              "    'ground_truth_code': 'def min_length_list(input_list):\\r\\n    min_length = min(len(x) for x in input_list )  \\r\\n    min_list = min(input_list, key = lambda i: len(i))\\r\\n    return(min_length, min_list)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of the sum in the expressions in The',\n",
              "    'test_cases': ['assert min_length_list([[0], [1, 3], [5, 7], [9, 11], [13, 15, 17]])==(1, [0])',\n",
              "     'assert min_length_list([[1,2,3,4,5],[1,2,3,4],[1,2,3],[1,2],[1]])==(1,[1])',\n",
              "     'assert min_length_list([[3,4,5],[6,7,8,9],[10,11,12],[1,2]])==(2,[1,2])'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.312136777879555,\n",
              "     'tokenization_energy': 0.1071367778778076,\n",
              "     'inference_energy': 21.205000000001746,\n",
              "     'energy_per_token': 1.4208091185253038,\n",
              "     'time': 0.5580685138702393,\n",
              "     'components': {'embeddings': np.float64(0.10953565835952758),\n",
              "      'attention': np.float64(12.371424132574816),\n",
              "      'ffn': np.float64(8.196531752828044),\n",
              "      'layernorm': np.float64(0.1143889389038086),\n",
              "      'output_layer': np.float64(0.19003999185562134)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to print check if the triangle is equilateral or not.',\n",
              "    'ground_truth_code': 'def check_equilateral(x,y,z):\\r\\n  if x == y == z:\\r\\n\\t   return True\\r\\n  else:\\r\\n     return False',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits a number is equilateral, not.\\n The',\n",
              "    'test_cases': ['assert check_equilateral(6,8,12)==False ',\n",
              "     'assert check_equilateral(6,6,12)==False',\n",
              "     'assert check_equilateral(6,6,6)==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.670000322827953,\n",
              "     'tokenization_energy': 0.10700032281875611,\n",
              "     'inference_energy': 25.563000000009197,\n",
              "     'energy_per_token': 1.604375020176747,\n",
              "     'time': 0.5576653480529785,\n",
              "     'components': {'embeddings': np.float64(0.10760856246948243),\n",
              "      'attention': np.float64(16.453275398977453),\n",
              "      'ffn': np.float64(16.20262200641772),\n",
              "      'layernorm': np.float64(0.13936563563346863),\n",
              "      'output_layer': np.float64(0.1897336757183075)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to caluclate area of a parallelogram.',\n",
              "    'ground_truth_code': 'def parallelogram_area(b,h):\\r\\n  area=b*h\\r\\n  return area',\n",
              "    'generated_code': ')\\n\\n the function that computeibrateclate the of a trianglelogram.\\n The',\n",
              "    'test_cases': ['assert parallelogram_area(10,20)==200',\n",
              "     'assert parallelogram_area(15,20)==300',\n",
              "     'assert parallelogram_area(8,9)==72'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.373076398610486,\n",
              "     'tokenization_energy': 0.10807639861106871,\n",
              "     'inference_energy': 21.264999999999418,\n",
              "     'energy_per_token': 1.3358172749131554,\n",
              "     'time': 0.5592386722564697,\n",
              "     'components': {'embeddings': np.float64(0.16272210717201233),\n",
              "      'attention': np.float64(12.438183739656932),\n",
              "      'ffn': np.float64(16.300136894230732),\n",
              "      'layernorm': np.float64(0.11362811803817749),\n",
              "      'output_layer': np.float64(0.19465984582901)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to check whether the first and last characters of a given string are equal or not.',\n",
              "    'ground_truth_code': 'def check_Equality(str):\\r\\n  if (str[0] == str[-1]):  \\r\\n    return (\"Equal\") \\r\\n  else:  \\r\\n    return (\"Not Equal\") ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given and last elements of a string string are the. not. Return',\n",
              "    'test_cases': ['assert check_Equality(\"abcda\") == \"Equal\"',\n",
              "     'assert check_Equality(\"ab\") == \"Not Equal\"',\n",
              "     'assert check_Equality(\"mad\") == \"Not Equal\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.577999999994063,\n",
              "     'tokenization_energy': 4.285999999992782,\n",
              "     'inference_energy': 21.29200000000128,\n",
              "     'energy_per_token': 1.1626363636360937,\n",
              "     'time': 0.5630381107330322,\n",
              "     'components': {'embeddings': np.float64(0.14114243030548096),\n",
              "      'attention': np.float64(8.434395454644228),\n",
              "      'ffn': np.float64(12.19799362254271),\n",
              "      'layernorm': np.float64(0.11548396825790405),\n",
              "      'output_layer': np.float64(0.21191154742240906)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to sort the given array by using counting sort.',\n",
              "    'ground_truth_code': 'def counting_sort(my_list):\\r\\n    max_value = 0\\r\\n    for i in range(len(my_list)):\\r\\n        if my_list[i] > max_value:\\r\\n            max_value = my_list[i]\\r\\n    buckets = [0] * (max_value + 1)\\r\\n    for i in my_list:\\r\\n        buckets[i] += 1\\r\\n    i = 0\\r\\n    for j in range(max_value + 1):\\r\\n         for a in range(buckets[j]):\\r\\n             my_list[i] = j\\r\\n             i += 1\\r\\n    return my_list',\n",
              "    'generated_code': ')\\n\\n the function that compute a sorted matrix in the the sort as But',\n",
              "    'test_cases': ['assert counting_sort([1,23,4,5,6,7,8]) == [1, 4, 5, 6, 7, 8, 23]',\n",
              "     'assert counting_sort([12, 9, 28, 33, 69, 45]) == [9, 12, 28, 33, 45, 69]',\n",
              "     'assert counting_sort([8, 4, 14, 3, 2, 1]) == [1, 2, 3, 4, 8, 14]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.621471820829903,\n",
              "     'tokenization_energy': 0.11047182083129882,\n",
              "     'inference_energy': 25.510999999998603,\n",
              "     'energy_per_token': 1.8301051300592788,\n",
              "     'time': 0.5606210231781006,\n",
              "     'components': {'embeddings': np.float64(0.1101444969177246),\n",
              "      'attention': np.float64(12.36074636292539),\n",
              "      'ffn': np.float64(12.091479267593705),\n",
              "      'layernorm': np.float64(0.11602638339996338),\n",
              "      'output_layer': np.float64(0.23296585893630983)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find t-nth term of geometric series.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef tn_gp(a,n,r):\\r\\n  tn = a * (math.pow(r, n - 1))\\r\\n  return tn',\n",
              "    'generated_code': ')\\n\\n the function that compute the suchorm term of an sequence.\\n The',\n",
              "    'test_cases': ['assert tn_gp(1,5,2)==16',\n",
              "     'assert tn_gp(1,5,4)==256',\n",
              "     'assert tn_gp(2,6,3)==486'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.449689169884078,\n",
              "     'tokenization_energy': 0.10868916988372804,\n",
              "     'inference_energy': 21.34100000000035,\n",
              "     'energy_per_token': 1.53212065499172,\n",
              "     'time': 0.565345048904419,\n",
              "     'components': {'embeddings': np.float64(0.11301455521583557),\n",
              "      'attention': np.float64(12.561410317904317),\n",
              "      'ffn': np.float64(16.359841277116328),\n",
              "      'layernorm': np.float64(0.11386248707771301),\n",
              "      'output_layer': np.float64(0.1931438398361206)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to check if a given number is one less than twice its reverse.',\n",
              "    'ground_truth_code': 'def rev(num):    \\r\\n    rev_num = 0\\r\\n    while (num > 0):  \\r\\n        rev_num = (rev_num * 10 + num % 10) \\r\\n        num = num // 10  \\r\\n    return rev_num  \\r\\ndef check(n):    \\r\\n    return (2 * rev(n) == n + 1)  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n is a of than a a own.\\n So',\n",
              "    'test_cases': ['assert check(70) == False',\n",
              "     'assert check(23) == False',\n",
              "     'assert check(73) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.433793335441734,\n",
              "     'tokenization_energy': 0.11079333543777466,\n",
              "     'inference_energy': 25.323000000003958,\n",
              "     'energy_per_token': 1.3386207018653544,\n",
              "     'time': 0.5661137104034424,\n",
              "     'components': {'embeddings': np.float64(4.297999999995227),\n",
              "      'attention': np.float64(8.47189537192497),\n",
              "      'ffn': np.float64(11.980882290596725),\n",
              "      'layernorm': np.float64(0.21271397304534911),\n",
              "      'output_layer': np.float64(0.21119399666786193)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to find the largest number that can be formed with the given digits.',\n",
              "    'ground_truth_code': 'def find_Max_Num(arr,n) : \\r\\n    arr.sort(reverse = True) \\r\\n    num = arr[0] \\r\\n    for i in range(1,n) : \\r\\n        num = num * 10 + arr[i] \\r\\n    return num ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number prime of can be formed by the digits digits, The',\n",
              "    'test_cases': ['assert find_Max_Num([1,2,3],3) == 321',\n",
              "     'assert find_Max_Num([4,5,6,1],4) == 6541',\n",
              "     'assert find_Max_Num([1,2,3,9],4) == 9321'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.747978955509723,\n",
              "     'tokenization_energy': 0.11097895550727845,\n",
              "     'inference_energy': 25.637000000002445,\n",
              "     'energy_per_token': 1.3551567871320906,\n",
              "     'time': 0.566110372543335,\n",
              "     'components': {'embeddings': np.float64(0.11190955328941345),\n",
              "      'attention': np.float64(8.539593840592657),\n",
              "      'ffn': np.float64(12.367183946129634),\n",
              "      'layernorm': np.float64(0.11876158952713012),\n",
              "      'output_layer': np.float64(4.358000000007451)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to check whether the given two integers have opposite sign or not.',\n",
              "    'ground_truth_code': 'def opposite_Signs(x,y): \\r\\n    return ((x ^ y) < 0); ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n\\n are the signs.\\n not.\\n Return',\n",
              "    'test_cases': ['assert opposite_Signs(1,-2) == True',\n",
              "     'assert opposite_Signs(3,2) == False',\n",
              "     'assert opposite_Signs(-10,-10) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.45562746334111,\n",
              "     'tokenization_energy': 0.11462746334075927,\n",
              "     'inference_energy': 21.34100000000035,\n",
              "     'energy_per_token': 1.1919793035189505,\n",
              "     'time': 0.5602643489837646,\n",
              "     'components': {'embeddings': np.float64(0.11296833992004394),\n",
              "      'attention': np.float64(12.778192520868734),\n",
              "      'ffn': np.float64(12.31522505544359),\n",
              "      'layernorm': np.float64(0.11327746295928955),\n",
              "      'output_layer': np.float64(0.20501879167556764)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the nth octagonal number.',\n",
              "    'ground_truth_code': 'def is_octagonal(n): \\r\\n\\treturn 3 * n * n - 2 * n ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum rootah number.\\n The',\n",
              "    'test_cases': ['assert is_octagonal(5) == 65',\n",
              "     'assert is_octagonal(10) == 280',\n",
              "     'assert is_octagonal(15) == 645'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.724635470387874,\n",
              "     'tokenization_energy': 0.11163547039031982,\n",
              "     'inference_energy': 25.612999999997555,\n",
              "     'energy_per_token': 2.143719622532323,\n",
              "     'time': 0.5641050338745117,\n",
              "     'components': {'embeddings': np.float64(0.10856174039840698),\n",
              "      'attention': np.float64(12.417114883671514),\n",
              "      'ffn': np.float64(12.288409632200375),\n",
              "      'layernorm': np.float64(0.11268674612045287),\n",
              "      'output_layer': np.float64(0.24607861804962158)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find the maximum length of the subsequence with difference between adjacent elements for the given array.',\n",
              "    'ground_truth_code': 'def max_len_sub( arr, n): \\r\\n\\tmls=[] \\r\\n\\tmax = 0\\r\\n\\tfor i in range(n): \\r\\n\\t\\tmls.append(1) \\r\\n\\tfor i in range(n): \\r\\n\\t\\tfor j in range(i): \\r\\n\\t\\t\\tif (abs(arr[i] - arr[j]) <= 1 and mls[i] < mls[j] + 1): \\r\\n\\t\\t\\t\\tmls[i] = mls[j] + 1\\r\\n\\tfor i in range(n): \\r\\n\\t\\tif (max < mls[i]): \\r\\n\\t\\t\\tmax = mls[i] \\r\\n\\treturn max',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of a maximumsequence of the at consecutive elements at each sub array.\\n The',\n",
              "    'test_cases': ['assert max_len_sub([2, 5, 6, 3, 7, 6, 5, 8], 8) == 5',\n",
              "     'assert max_len_sub([-2, -1, 5, -1, 4, 0, 3], 7) == 4',\n",
              "     'assert max_len_sub([9, 11, 13, 15, 18], 5) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.61857053756574,\n",
              "     'tokenization_energy': 0.10757053756713868,\n",
              "     'inference_energy': 21.510999999998603,\n",
              "     'energy_per_token': 0.9399378494593801,\n",
              "     'time': 0.5606288909912109,\n",
              "     'components': {'embeddings': np.float64(0.10719007587432862),\n",
              "      'attention': np.float64(4.34629896235466),\n",
              "      'ffn': np.float64(8.038690627816715),\n",
              "      'layernorm': np.float64(0.1135934386253357),\n",
              "      'output_layer': np.float64(0.2663946418762207)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a python function to count number of substrings with the sum of digits equal to their length.',\n",
              "    'ground_truth_code': \"from collections import defaultdict\\r\\ndef count_Substrings(s,n):\\r\\n    count,sum = 0,0\\r\\n    mp = defaultdict(lambda : 0)\\r\\n    mp[0] += 1\\r\\n    for i in range(n):\\r\\n        sum += ord(s[i]) - ord('0')\\r\\n        count += mp[sum - (i + 1)]\\r\\n        mp[sum - (i + 1)] += 1\\r\\n    return count\",\n",
              "    'generated_code': ')\\n\\n the function function that compute the of validings of exactly same of digits equal to  length.\\n\\n You',\n",
              "    'test_cases': [\"assert count_Substrings('112112',6) == 6\",\n",
              "     \"assert count_Substrings('111',3) == 6\",\n",
              "     \"assert count_Substrings('1101112',7) == 12\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.519960649501417,\n",
              "     'tokenization_energy': 0.17996064949035645,\n",
              "     'inference_energy': 21.34000000001106,\n",
              "     'energy_per_token': 1.0247600309286389,\n",
              "     'time': 0.5686144828796387,\n",
              "     'components': {'embeddings': np.float64(0.11805208969116211),\n",
              "      'attention': np.float64(8.514039125204786),\n",
              "      'ffn': np.float64(12.350533401734777),\n",
              "      'layernorm': np.float64(0.17965241980552674),\n",
              "      'output_layer': np.float64(0.22140525937080385)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a python function to find smallest number in a list.',\n",
              "    'ground_truth_code': 'def smallest_num(xs):\\n  return min(xs)\\n',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of a matrix of Write',\n",
              "    'test_cases': ['assert smallest_num([10, 20, 1, 45, 99]) == 1',\n",
              "     'assert smallest_num([1, 2, 3]) == 1',\n",
              "     'assert smallest_num([45, 46, 50, 60]) == 45'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.827241677522192,\n",
              "     'tokenization_energy': 0.1152416775226593,\n",
              "     'inference_energy': 25.711999999999534,\n",
              "     'energy_per_token': 1.9867108982709378,\n",
              "     'time': 0.5651860237121582,\n",
              "     'components': {'embeddings': np.float64(0.11650044989585877),\n",
              "      'attention': np.float64(8.338772134064463),\n",
              "      'ffn': np.float64(8.018586226946676),\n",
              "      'layernorm': np.float64(0.11330331182479858),\n",
              "      'output_layer': np.float64(0.19522147512435914)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the maximum difference between available pairs in the given tuple list.',\n",
              "    'ground_truth_code': 'def max_difference(test_list):\\r\\n  temp = [abs(b - a) for a, b in test_list]\\r\\n  res = max(temp)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number between two\\n of a function matrix.\\n\\n.\\n The',\n",
              "    'test_cases': ['assert max_difference([(3, 5), (1, 7), (10, 3), (1, 2)]) == 7',\n",
              "     'assert max_difference([(4, 6), (2, 17), (9, 13), (11, 12)]) == 15',\n",
              "     'assert max_difference([(12, 35), (21, 27), (13, 23), (41, 22)]) == 23'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.52445077037555,\n",
              "     'tokenization_energy': 0.10845077037811279,\n",
              "     'inference_energy': 21.41599999999744,\n",
              "     'energy_per_token': 1.1958028205764195,\n",
              "     'time': 0.5603032112121582,\n",
              "     'components': {'embeddings': np.float64(0.11030704402923584),\n",
              "      'attention': np.float64(16.566318220838323),\n",
              "      'ffn': np.float64(12.445627627147246),\n",
              "      'layernorm': np.float64(0.11420290756225586),\n",
              "      'output_layer': np.float64(0.20730841636657715)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to sort a list of tuples using lambda.',\n",
              "    'ground_truth_code': \"def subject_marks(subjectmarks):\\r\\n#subject_marks = [('English', 88), ('Science', 90), ('Maths', 97), ('Social sciences', 82)])\\r\\n subjectmarks.sort(key = lambda x: x[1])\\r\\n return subjectmarks\",\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix of integers in the expressions So',\n",
              "    'test_cases': [\"assert subject_marks([('English', 88), ('Science', 90), ('Maths', 97), ('Social sciences', 82)])==[('Social sciences', 82), ('English', 88), ('Science', 90), ('Maths', 97)]\",\n",
              "     \"assert subject_marks([('Telugu',49),('Hindhi',54),('Social',33)])==([('Social',33),('Telugu',49),('Hindhi',54)])\",\n",
              "     \"assert subject_marks([('Physics',96),('Chemistry',97),('Biology',45)])==([('Biology',45),('Physics',96),('Chemistry',97)])\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.711999999999534,\n",
              "     'tokenization_energy': 4.43399999999383,\n",
              "     'inference_energy': 21.278000000005704,\n",
              "     'energy_per_token': 1.977846153846118,\n",
              "     'time': 0.559995174407959,\n",
              "     'components': {'embeddings': np.float64(0.11141323447227477),\n",
              "      'attention': np.float64(12.49922599602351),\n",
              "      'ffn': np.float64(12.34999303460168),\n",
              "      'layernorm': np.float64(0.1146180522441864),\n",
              "      'output_layer': np.float64(0.19245545625686644)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function of recursion list sum.',\n",
              "    'ground_truth_code': 'def recursive_list_sum(data_list):\\r\\n\\ttotal = 0\\r\\n\\tfor element in data_list:\\r\\n\\t\\tif type(element) == type([]):\\r\\n\\t\\t\\ttotal = total + recursive_list_sum(element)\\r\\n\\t\\telse:\\r\\n\\t\\t\\ttotal = total + element\\r\\n\\treturn total',\n",
              "    'generated_code': ')\\n\\n the function that the that,, The',\n",
              "    'test_cases': ['assert recursive_list_sum(([1, 2, [3,4],[5,6]]))==21',\n",
              "     'assert recursive_list_sum(([7, 10, [15,14],[19,41]]))==106',\n",
              "     'assert recursive_list_sum(([10, 20, [30,40],[50,60]]))==210'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.573933724396046,\n",
              "     'tokenization_energy': 0.10993372440338135,\n",
              "     'inference_energy': 25.463999999992666,\n",
              "     'energy_per_token': 2.8415481915995606,\n",
              "     'time': 0.5552546977996826,\n",
              "     'components': {'embeddings': np.float64(0.11222996354103089),\n",
              "      'attention': np.float64(16.49539784502296),\n",
              "      'ffn': np.float64(12.198522500996013),\n",
              "      'layernorm': np.float64(0.11452108383178711),\n",
              "      'output_layer': np.float64(4.244999999995343)},\n",
              "     'num_tokens': 9}},\n",
              "   {'prompt': 'Write a python function to count positive numbers in a list.',\n",
              "    'ground_truth_code': 'def pos_count(list):\\r\\n  pos_count= 0\\r\\n  for num in list: \\r\\n    if num >= 0: \\r\\n      pos_count += 1\\r\\n  return pos_count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the integers in a matrix, The',\n",
              "    'test_cases': ['assert pos_count([1,-2,3,-4]) == 2',\n",
              "     'assert pos_count([3,4,5,-1]) == 3',\n",
              "     'assert pos_count([1,2,3,4]) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.63974967002729,\n",
              "     'tokenization_energy': 0.1287496700286865,\n",
              "     'inference_energy': 21.510999999998603,\n",
              "     'energy_per_token': 1.6645961284636377,\n",
              "     'time': 0.5584850311279297,\n",
              "     'components': {'embeddings': np.float64(0.19477176284790038),\n",
              "      'attention': np.float64(8.27345704888308),\n",
              "      'ffn': np.float64(8.26314966870239),\n",
              "      'layernorm': np.float64(0.16836148381233215),\n",
              "      'output_layer': np.float64(0.18954034900665284)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the number of ways to partition a set of bell numbers.',\n",
              "    'ground_truth_code': 'def bell_number(n):   \\r\\n    bell = [[0 for i in range(n+1)] for j in range(n+1)] \\r\\n    bell[0][0] = 1\\r\\n    for i in range(1, n+1): \\r\\n        bell[i][0] = bell[i-1][i-1]  \\r\\n        for j in range(1, i+1): \\r\\n            bell[i][j] = bell[i-1][j-1] + bell[i][j-1]   \\r\\n    return bell[n][0] ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of unique to split a number of n numbers. So',\n",
              "    'test_cases': ['assert bell_number(2)==2',\n",
              "     'assert bell_number(10)==115975',\n",
              "     'assert bell_number(56)==6775685320645824322581483068371419745979053216268760300'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.70774335384951,\n",
              "     'tokenization_energy': 0.10774335384368897,\n",
              "     'inference_energy': 25.60000000000582,\n",
              "     'energy_per_token': 1.4282079641027505,\n",
              "     'time': 0.5593323707580566,\n",
              "     'components': {'embeddings': np.float64(0.19170920872688293),\n",
              "      'attention': np.float64(16.83642302228266),\n",
              "      'ffn': np.float64(16.294358572476426),\n",
              "      'layernorm': np.float64(0.2085406775474548),\n",
              "      'output_layer': np.float64(0.2187309408187866)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to check whether the given array is monotonic or not.',\n",
              "    'ground_truth_code': 'def is_Monotonic(A): \\r\\n    return (all(A[i] <= A[i + 1] for i in range(len(A) - 1)) or\\r\\n            all(A[i] >= A[i + 1] for i in range(len(A) - 1))) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n of aonic. not. The',\n",
              "    'test_cases': ['assert is_Monotonic([6, 5, 4, 4]) == True',\n",
              "     'assert is_Monotonic([1, 2, 2, 3]) == True',\n",
              "     'assert is_Monotonic([1, 3, 2]) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.621539760583545,\n",
              "     'tokenization_energy': 0.1155397605895996,\n",
              "     'inference_energy': 21.505999999993946,\n",
              "     'energy_per_token': 1.2718552800343261,\n",
              "     'time': 0.5636475086212158,\n",
              "     'components': {'embeddings': np.float64(0.21907455348968505),\n",
              "      'attention': np.float64(12.653476022964693),\n",
              "      'ffn': np.float64(12.42760915373196),\n",
              "      'layernorm': np.float64(0.11831375885009765),\n",
              "      'output_layer': np.float64(0.20959783935546875)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to check whether a list contains the given sublist or not.',\n",
              "    'ground_truth_code': 'def is_sublist(l, s):\\r\\n\\tsub_set = False\\r\\n\\tif s == []:\\r\\n\\t\\tsub_set = True\\r\\n\\telif s == l:\\r\\n\\t\\tsub_set = True\\r\\n\\telif len(s) > len(l):\\r\\n\\t\\tsub_set = False\\r\\n\\telse:\\r\\n\\t\\tfor i in range(len(l)):\\r\\n\\t\\t\\tif l[i] == s[0]:\\r\\n\\t\\t\\t\\tn = 1\\r\\n\\t\\t\\t\\twhile (n < len(s)) and (l[i+n] == s[n]):\\r\\n\\t\\t\\t\\t\\tn += 1\\t\\t\\t\\t\\r\\n\\t\\t\\t\\tif n == len(s):\\r\\n\\t\\t\\t\\t\\tsub_set = True\\r\\n\\treturn sub_set',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given of exactly same\\n, not.\\n But',\n",
              "    'test_cases': ['assert is_sublist([2,4,3,5,7],[3,7])==False',\n",
              "     'assert is_sublist([2,4,3,5,7],[4,3])==True',\n",
              "     'assert is_sublist([2,4,3,5,7],[1,6])==False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.74900000001071,\n",
              "     'tokenization_energy': 4.385000000009313,\n",
              "     'inference_energy': 21.364000000001397,\n",
              "     'energy_per_token': 1.6093125000006694,\n",
              "     'time': 0.5597789287567139,\n",
              "     'components': {'embeddings': np.float64(0.11261265993118286),\n",
              "      'attention': np.float64(8.384242696056724),\n",
              "      'ffn': np.float64(4.136482959985733),\n",
              "      'layernorm': np.float64(0.11367058181762696),\n",
              "      'output_layer': np.float64(0.1913138144016266)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find whether all the given tuples have equal length or not.',\n",
              "    'ground_truth_code': 'def find_equal_tuple(Input, k):\\r\\n  flag = 1\\r\\n  for tuple in Input:\\r\\n    if len(tuple) != k:\\r\\n      flag = 0\\r\\n      break\\r\\n  return flag\\r\\ndef get_equal(Input, k):\\r\\n  if find_equal_tuple(Input, k) == 1:\\r\\n    return (\"All tuples have same length\")\\r\\n  else:\\r\\n    return (\"All tuples do not have same length\")',\n",
              "    'generated_code': ')\\n\\n the function that compute the the the elements numbers in the elements. not. If',\n",
              "    'test_cases': [\"assert get_equal([(11, 22, 33), (44, 55, 66)], 3) == 'All tuples have same length'\",\n",
              "     \"assert get_equal([(1, 2, 3), (4, 5, 6, 7)], 3) == 'All tuples do not have same length'\",\n",
              "     \"assert get_equal([(1, 2), (3, 4)], 2) == 'All tuples have same length'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.9625165991704,\n",
              "     'tokenization_energy': 0.10851659917831422,\n",
              "     'inference_energy': 25.853999999992084,\n",
              "     'energy_per_token': 1.5272068587747294,\n",
              "     'time': 0.5605168342590332,\n",
              "     'components': {'embeddings': np.float64(0.10936549043655396),\n",
              "      'attention': np.float64(12.443685206410477),\n",
              "      'ffn': np.float64(12.430416707985685),\n",
              "      'layernorm': np.float64(0.11900376462936402),\n",
              "      'output_layer': np.float64(0.23016065526008606)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to sort a list of elements using comb sort.',\n",
              "    'ground_truth_code': 'def comb_sort(nums):\\r\\n    shrink_fact = 1.3\\r\\n    gaps = len(nums)\\r\\n    swapped = True\\r\\n    i = 0\\r\\n    while gaps > 1 or swapped:\\r\\n        gaps = int(float(gaps) / shrink_fact)\\r\\n        swapped = False\\r\\n        i = 0\\r\\n        while gaps + i < len(nums):\\r\\n            if nums[i] > nums[i+gaps]:\\r\\n                nums[i], nums[i+gaps] = nums[i+gaps], nums[i]\\r\\n                swapped = True\\r\\n            i += 1\\r\\n    return nums',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix of integers in ainator.\\n\\n The',\n",
              "    'test_cases': ['assert comb_sort([5, 15, 37, 25, 79]) == [5, 15, 25, 37, 79]',\n",
              "     'assert comb_sort([41, 32, 15, 19, 22]) == [15, 19, 22, 32, 41]',\n",
              "     'assert comb_sort([99, 15, 13, 47]) == [13, 15, 47, 99]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.585544200423172,\n",
              "     'tokenization_energy': 0.10754420042037963,\n",
              "     'inference_energy': 21.478000000002794,\n",
              "     'energy_per_token': 1.5418245857445123,\n",
              "     'time': 0.5582308769226074,\n",
              "     'components': {'embeddings': np.float64(0.10903033876419067),\n",
              "      'attention': np.float64(16.9568689992571),\n",
              "      'ffn': np.float64(12.315642346609037),\n",
              "      'layernorm': np.float64(0.1155201551914215),\n",
              "      'output_layer': np.float64(0.196727290391922)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to check whether the given number can be represented as difference of two squares or not.',\n",
              "    'ground_truth_code': 'def dif_Square(n): \\r\\n    if (n % 4 != 2): \\r\\n        return True\\r\\n    return False',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n is be represented as the of two prime.\\n not.\\n \\n',\n",
              "    'test_cases': ['assert dif_Square(5) == True',\n",
              "     'assert dif_Square(10) == False',\n",
              "     'assert dif_Square(15) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.820167552235304,\n",
              "     'tokenization_energy': 0.1111675522327423,\n",
              "     'inference_energy': 25.70900000000256,\n",
              "     'energy_per_token': 1.1736439796470592,\n",
              "     'time': 0.5596902370452881,\n",
              "     'components': {'embeddings': np.float64(0.11242151641845703),\n",
              "      'attention': np.float64(12.365294770724022),\n",
              "      'ffn': np.float64(4.034499900341034),\n",
              "      'layernorm': np.float64(0.11580205965042113),\n",
              "      'output_layer': np.float64(0.21134677696228027)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to split the given string with multiple delimiters by using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef multiple_split(text):\\r\\n  return (re.split('; |, |\\\\*|\\\\n',text))\",\n",
              "    'generated_code': ')\\n\\n the function that compute a split matrix into the spacesimiters and using the.\\n The',\n",
              "    'test_cases': [\"assert multiple_split('Forces of the \\\\ndarkness*are coming into the play.') == ['Forces of the ', 'darkness', 'are coming into the play.']\",\n",
              "     \"assert multiple_split('Mi Box runs on the \\\\n Latest android*which has google assistance and chromecast.') == ['Mi Box runs on the ', ' Latest android', 'which has google assistance and chromecast.']\",\n",
              "     \"assert multiple_split('Certain services\\\\nare subjected to change*over the seperate subscriptions.') == ['Certain services', 'are subjected to change', 'over the seperate subscriptions.']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.02061195564235,\n",
              "     'tokenization_energy': 0.1116119556427002,\n",
              "     'inference_energy': 25.90899999999965,\n",
              "     'energy_per_token': 1.5306242326848443,\n",
              "     'time': 0.5657644271850586,\n",
              "     'components': {'embeddings': np.float64(0.11280173826217652),\n",
              "      'attention': np.float64(12.76708915662358),\n",
              "      'ffn': np.float64(12.457635856150185),\n",
              "      'layernorm': np.float64(0.11958140850067138),\n",
              "      'output_layer': np.float64(0.2821639142036438)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to check whether it follows the sequence given in the patterns array.',\n",
              "    'ground_truth_code': 'def is_samepatterns(colors, patterns):    \\r\\n    if len(colors) != len(patterns):\\r\\n        return False    \\r\\n    sdict = {}\\r\\n    pset = set()\\r\\n    sset = set()    \\r\\n    for i in range(len(patterns)):\\r\\n        pset.add(patterns[i])\\r\\n        sset.add(colors[i])\\r\\n        if patterns[i] not in sdict.keys():\\r\\n            sdict[patterns[i]] = []\\r\\n\\r\\n        keys = sdict[patterns[i]]\\r\\n        keys.append(colors[i])\\r\\n        sdict[patterns[i]] = keys\\r\\n\\r\\n    if len(pset) != len(sset):\\r\\n        return False   \\r\\n\\r\\n    for values in sdict.values():\\r\\n\\r\\n        for i in range(len(values) - 1):\\r\\n            if values[i] != values[i+1]:\\r\\n                return False\\r\\n\\r\\n    return True',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a is the following of by the sequence below.\\n\\n The',\n",
              "    'test_cases': ['assert is_samepatterns([\"red\",\"green\",\"green\"], [\"a\", \"b\", \"b\"])==True ',\n",
              "     'assert is_samepatterns([\"red\",\"green\",\"greenn\"], [\"a\",\"b\",\"b\"])==False ',\n",
              "     'assert is_samepatterns([\"red\",\"green\",\"greenn\"], [\"a\",\"b\"])==False '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.68877428316581,\n",
              "     'tokenization_energy': 0.21277428317070007,\n",
              "     'inference_energy': 21.47599999999511,\n",
              "     'energy_per_token': 1.27581025195093,\n",
              "     'time': 0.5599210262298584,\n",
              "     'components': {'embeddings': np.float64(0.11948464798927307),\n",
              "      'attention': np.float64(12.449223217958817),\n",
              "      'ffn': np.float64(8.3095378005401),\n",
              "      'layernorm': np.float64(0.11625425720214844),\n",
              "      'output_layer': np.float64(0.26819629669189454)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find tuples which have all elements divisible by k from the given list of tuples.',\n",
              "    'ground_truth_code': 'def find_tuples(test_list, K):\\r\\n  res = [sub for sub in test_list if all(ele % K == 0 for ele in sub)]\\r\\n  return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the in are the the in by , a given array of integers.\\n\\n The',\n",
              "    'test_cases': [\"assert find_tuples([(6, 24, 12), (7, 9, 6), (12, 18, 21)], 6) == '[(6, 24, 12)]'\",\n",
              "     \"assert find_tuples([(5, 25, 30), (4, 2, 3), (7, 8, 9)], 5) == '[(5, 25, 30)]'\",\n",
              "     \"assert find_tuples([(7, 9, 16), (8, 16, 4), (19, 17, 18)], 4) == '[(8, 16, 4)]'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.942116226204437,\n",
              "     'tokenization_energy': 0.15211622619628906,\n",
              "     'inference_energy': 25.79000000000815,\n",
              "     'energy_per_token': 1.235338867914497,\n",
              "     'time': 0.568779468536377,\n",
              "     'components': {'embeddings': np.float64(0.1100347671508789),\n",
              "      'attention': np.float64(12.485718229037593),\n",
              "      'ffn': np.float64(12.420058870806825),\n",
              "      'layernorm': np.float64(0.24975770711898804),\n",
              "      'output_layer': np.float64(0.2270494878292084)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a python function to count the number of squares in a rectangle.',\n",
              "    'ground_truth_code': 'def count_Squares(m,n):\\r\\n    if(n < m):\\r\\n        temp = m\\r\\n        m = n\\r\\n        n = temp\\r\\n    return ((m * (m + 1) * (2 * m + 1) / 6 + (n - m) * m * (m + 1) / 2))',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of integers in a given, The',\n",
              "    'test_cases': ['assert count_Squares(4,3) == 20',\n",
              "     'assert count_Squares(2,2) == 5',\n",
              "     'assert count_Squares(1,1) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.057643087147152,\n",
              "     'tokenization_energy': 0.11864308714866638,\n",
              "     'inference_energy': 25.938999999998487,\n",
              "     'energy_per_token': 1.7371762058098101,\n",
              "     'time': 0.5712530612945557,\n",
              "     'components': {'embeddings': np.float64(0.17523375749588013),\n",
              "      'attention': np.float64(8.987132729048609),\n",
              "      'ffn': np.float64(12.247877104996935),\n",
              "      'layernorm': np.float64(0.12285373878479004),\n",
              "      'output_layer': np.float64(0.20383332586288452)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the difference between sum of even and odd digits.',\n",
              "    'ground_truth_code': 'def is_Diff(n): \\r\\n    return (n % 11 == 0) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number between the of even numbers sum numbers in So',\n",
              "    'test_cases': ['assert is_Diff (12345) == False',\n",
              "     'assert is_Diff(1212112) == True',\n",
              "     'assert is_Diff(1212) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.85453481292189,\n",
              "     'tokenization_energy': 0.1665348129272461,\n",
              "     'inference_energy': 21.687999999994645,\n",
              "     'energy_per_token': 1.2855608713483466,\n",
              "     'time': 0.569178581237793,\n",
              "     'components': {'embeddings': np.float64(0.12511754608154296),\n",
              "      'attention': np.float64(12.670495081188388),\n",
              "      'ffn': np.float64(8.36502037310717),\n",
              "      'layernorm': np.float64(0.11673310089111329),\n",
              "      'output_layer': np.float64(0.21099674272537233)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find number of integers with odd number of set bits.',\n",
              "    'ground_truth_code': \"def count_With_Odd_SetBits(n): \\r\\n    if (n % 2 != 0): \\r\\n        return (n + 1) / 2\\r\\n    count = bin(n).count('1') \\r\\n    ans = n / 2\\r\\n    if (count % 2 != 0): \\r\\n        ans += 1\\r\\n    return ans \",\n",
              "    'generated_code': ')\\n\\n the function function that compute the of unique in the number of div bits in Given',\n",
              "    'test_cases': ['assert count_With_Odd_SetBits(5) == 3',\n",
              "     'assert count_With_Odd_SetBits(10) == 5',\n",
              "     'assert count_With_Odd_SetBits(15) == 8'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.03545350551512,\n",
              "     'tokenization_energy': 0.11145350551605225,\n",
              "     'inference_energy': 25.92399999999907,\n",
              "     'energy_per_token': 1.5314972650303014,\n",
              "     'time': 0.5702414512634277,\n",
              "     'components': {'embeddings': np.float64(0.17088013219833376),\n",
              "      'attention': np.float64(12.728512150535359),\n",
              "      'ffn': np.float64(8.159629054547754),\n",
              "      'layernorm': np.float64(0.11996972370147706),\n",
              "      'output_layer': np.float64(0.2164329357147217)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to check whether the length of the word is odd or not.',\n",
              "    'ground_truth_code': \"def word_len(s): \\r\\n    s = s.split(' ')   \\r\\n    for word in s:    \\r\\n        if len(word)%2!=0: \\r\\n            return True  \\r\\n        else:\\r\\n          return False\",\n",
              "    'generated_code': \")\\n\\n the function function that compute whether a given of the length ' even or even.\\n If\",\n",
              "    'test_cases': ['assert word_len(\"Hadoop\") == False',\n",
              "     'assert word_len(\"great\") == True',\n",
              "     'assert word_len(\"structure\") == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.035477508553885,\n",
              "     'tokenization_energy': 0.11647750854492188,\n",
              "     'inference_energy': 25.919000000008964,\n",
              "     'energy_per_token': 1.4464154171418826,\n",
              "     'time': 0.5697100162506104,\n",
              "     'components': {'embeddings': np.float64(0.114251353263855),\n",
              "      'attention': np.float64(12.420381614910092),\n",
              "      'ffn': np.float64(8.354971888784785),\n",
              "      'layernorm': np.float64(0.1944884419441223),\n",
              "      'output_layer': np.float64(4.3510000000096625)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the nth tetrahedral number.',\n",
              "    'ground_truth_code': 'def tetrahedral_number(n): \\r\\n\\treturn (n * (n + 1) * (n + 2)) / 6',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum rootrahedral number.\\n The',\n",
              "    'test_cases': ['assert tetrahedral_number(5) == 35.0',\n",
              "     'assert tetrahedral_number(6) == 56.0',\n",
              "     'assert tetrahedral_number(7) == 84.0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.769249372958555,\n",
              "     'tokenization_energy': 0.12924937295913697,\n",
              "     'inference_energy': 21.639999999999418,\n",
              "     'energy_per_token': 1.674557644073735,\n",
              "     'time': 0.5662539005279541,\n",
              "     'components': {'embeddings': np.float64(0.19652041864395142),\n",
              "      'attention': np.float64(8.459804685359819),\n",
              "      'ffn': np.float64(8.096229869364878),\n",
              "      'layernorm': np.float64(0.11516002893447876),\n",
              "      'output_layer': np.float64(0.2521505708694458)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to zip the two given tuples.',\n",
              "    'ground_truth_code': 'def zip_tuples(test_tup1, test_tup2):\\r\\n  res = []\\r\\n  for i, j in enumerate(test_tup1):\\r\\n    res.append((j, test_tup2[i % len(test_tup2)])) \\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute two elements arrays arrays, The',\n",
              "    'test_cases': ['assert zip_tuples((7, 8, 4, 5, 9, 10),(1, 5, 6) ) == [(7, 1), (8, 5), (4, 6), (5, 1), (9, 5), (10, 6)]',\n",
              "     'assert zip_tuples((8, 9, 5, 6, 10, 11),(2, 6, 7) ) == [(8, 2), (9, 6), (5, 7), (6, 2), (10, 6), (11, 7)]',\n",
              "     'assert zip_tuples((9, 10, 6, 7, 11, 12),(3, 7, 8) ) == [(9, 3), (10, 7), (6, 8), (7, 3), (11, 7), (12, 8)]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 25.733471943377634,\n",
              "     'tokenization_energy': 0.11247194337844849,\n",
              "     'inference_energy': 25.620999999999185,\n",
              "     'energy_per_token': 2.3394065403070576,\n",
              "     'time': 0.56520676612854,\n",
              "     'components': {'embeddings': np.float64(4.265999999988708),\n",
              "      'attention': np.float64(12.66729340409662),\n",
              "      'ffn': np.float64(12.02868004729005),\n",
              "      'layernorm': np.float64(0.1168326473236084),\n",
              "      'output_layer': np.float64(0.20278801918029787)},\n",
              "     'num_tokens': 11}},\n",
              "   {'prompt': 'Write a function to find the volume of a sphere.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef volume_sphere(r):\\r\\n  volume=(4/3)*math.pi*r*r*r\\r\\n  return volume',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a cube given The',\n",
              "    'test_cases': ['assert volume_sphere(10)==4188.790204786391',\n",
              "     'assert volume_sphere(25)==65449.84694978735',\n",
              "     'assert volume_sphere(20)==33510.32163829113'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.0149706344615,\n",
              "     'tokenization_energy': 0.11697063446044922,\n",
              "     'inference_energy': 25.898000000001048,\n",
              "     'energy_per_token': 2.167914219538458,\n",
              "     'time': 0.5674991607666016,\n",
              "     'components': {'embeddings': np.float64(0.11507065773010254),\n",
              "      'attention': np.float64(16.738316137567747),\n",
              "      'ffn': np.float64(12.576789588196554),\n",
              "      'layernorm': np.float64(0.1721581506729126),\n",
              "      'output_layer': np.float64(4.349000000001979)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to find the character made by adding all the characters of the given string.',\n",
              "    'ground_truth_code': \"def get_Char(strr):  \\r\\n    summ = 0\\r\\n    for i in range(len(strr)): \\r\\n        summ += (ord(strr[i]) - ord('a') + 1)  \\r\\n    if (summ % 26 == 0): \\r\\n        return ord('z') \\r\\n    else: \\r\\n        summ = summ % 26\\r\\n        return chr(ord('a') + summ - 1)\",\n",
              "    'generated_code': ')\\n\\n the function function that compute the number in by the the the characters in the character matrix s So',\n",
              "    'test_cases': ['assert get_Char(\"abc\") == \"f\"',\n",
              "     'assert get_Char(\"gfg\") == \"t\"',\n",
              "     'assert get_Char(\"ab\") == \"c\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.872534401887563,\n",
              "     'tokenization_energy': 0.11653440189361572,\n",
              "     'inference_energy': 21.755999999993946,\n",
              "     'energy_per_token': 1.0936267200943781,\n",
              "     'time': 0.5643067359924316,\n",
              "     'components': {'embeddings': np.float64(0.18049566173553466),\n",
              "      'attention': np.float64(12.860303599363194),\n",
              "      'ffn': np.float64(12.505681107751792),\n",
              "      'layernorm': np.float64(0.1149668664932251),\n",
              "      'output_layer': np.float64(0.2110724606513977)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find the n-th number in newman conway sequence.',\n",
              "    'ground_truth_code': 'def sequence(n): \\r\\n\\tif n == 1 or n == 2: \\r\\n\\t\\treturn 1\\r\\n\\telse: \\r\\n\\t\\treturn sequence(sequence(n-1)) + sequence(n-sequence(n-1))',\n",
              "    'generated_code': \")\\n\\n the function that compute the maximum-th root in a arrangement'sway game.\\n The\",\n",
              "    'test_cases': ['assert sequence(10) == 6',\n",
              "     'assert sequence(2) == 1',\n",
              "     'assert sequence(3) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.046926970964066,\n",
              "     'tokenization_energy': 0.10992697095870972,\n",
              "     'inference_energy': 25.937000000005355,\n",
              "     'energy_per_token': 1.532172174762592,\n",
              "     'time': 0.5684528350830078,\n",
              "     'components': {'embeddings': np.float64(4.434000000008382),\n",
              "      'attention': np.float64(8.316990050077555),\n",
              "      'ffn': np.float64(12.45166772508796),\n",
              "      'layernorm': np.float64(0.11289266395568848),\n",
              "      'output_layer': np.float64(0.204332111120224)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the surface area of a sphere.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef surfacearea_sphere(r):\\r\\n  surfacearea=4*math.pi*r*r\\r\\n  return surfacearea',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum area of a cube given The',\n",
              "    'test_cases': ['assert surfacearea_sphere(10)==1256.6370614359173',\n",
              "     'assert surfacearea_sphere(15)==2827.4333882308138',\n",
              "     'assert surfacearea_sphere(20)==5026.548245743669'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.002064329616726,\n",
              "     'tokenization_energy': 0.11006432962417603,\n",
              "     'inference_energy': 25.89199999999255,\n",
              "     'energy_per_token': 2.000158794585902,\n",
              "     'time': 0.5692164897918701,\n",
              "     'components': {'embeddings': np.float64(0.10923187661170959),\n",
              "      'attention': np.float64(8.60231835866149),\n",
              "      'ffn': np.float64(12.38155580448627),\n",
              "      'layernorm': np.float64(0.12238118219375611),\n",
              "      'output_layer': np.float64(0.24041056084632875)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find nth centered hexagonal number.',\n",
              "    'ground_truth_code': 'def centered_hexagonal_number(n):\\r\\n  return 3 * n * (n - 1) + 1',\n",
              "    'generated_code': ')\\n\\n the function that compute the term decagonal number.\\n The',\n",
              "    'test_cases': ['assert centered_hexagonal_number(10) == 271',\n",
              "     'assert centered_hexagonal_number(2) == 7',\n",
              "     'assert centered_hexagonal_number(9) == 217'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.598659522054135,\n",
              "     'tokenization_energy': 0.1106595220565796,\n",
              "     'inference_energy': 21.487999999997555,\n",
              "     'energy_per_token': 1.7998882935045113,\n",
              "     'time': 0.5588047504425049,\n",
              "     'components': {'embeddings': np.float64(0.11050678992271423),\n",
              "      'attention': np.float64(16.658756808292587),\n",
              "      'ffn': np.float64(12.352095480189542),\n",
              "      'layernorm': np.float64(0.12107256746292115),\n",
              "      'output_layer': np.float64(0.1987733430862427)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to merge three dictionaries into a single expression.',\n",
              "    'ground_truth_code': 'import collections as ct\\r\\ndef merge_dictionaries_three(dict1,dict2, dict3):\\r\\n    merged_dict = dict(ct.ChainMap({},dict1,dict2,dict3))\\r\\n    return merged_dict',\n",
              "    'generated_code': ')\\n\\n the function that compute two arrays into a single dictionary, The',\n",
              "    'test_cases': ['assert merge_dictionaries_three({ \"R\": \"Red\", \"B\": \"Black\", \"P\": \"Pink\" }, { \"G\": \"Green\", \"W\": \"White\" },{ \"O\": \"Orange\", \"W\": \"White\", \"B\": \"Black\" })=={\\'B\\': \\'Black\\', \\'R\\': \\'Red\\', \\'P\\': \\'Pink\\', \\'G\\': \\'Green\\', \\'W\\': \\'White\\', \\'O\\': \\'Orange\\'}',\n",
              "     'assert merge_dictionaries_three({ \"R\": \"Red\", \"B\": \"Black\", \"P\": \"Pink\" }, { \"G\": \"Green\", \"W\": \"White\" },{\"L\":\"lavender\",\"B\":\"Blue\"})=={\\'W\\': \\'White\\', \\'P\\': \\'Pink\\', \\'B\\': \\'Black\\', \\'R\\': \\'Red\\', \\'G\\': \\'Green\\', \\'L\\': \\'lavender\\'}',\n",
              "     'assert merge_dictionaries_three({ \"R\": \"Red\", \"B\": \"Black\", \"P\": \"Pink\" },{\"L\":\"lavender\",\"B\":\"Blue\"},{ \"G\": \"Green\", \"W\": \"White\" })=={\\'B\\': \\'Black\\', \\'P\\': \\'Pink\\', \\'R\\': \\'Red\\', \\'G\\': \\'Green\\', \\'L\\': \\'lavender\\', \\'W\\': \\'White\\'}'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.101978367330624,\n",
              "     'tokenization_energy': 0.12797836732864382,\n",
              "     'inference_energy': 25.97400000000198,\n",
              "     'energy_per_token': 2.0078444897946635,\n",
              "     'time': 0.565558671951294,\n",
              "     'components': {'embeddings': np.float64(0.11626166725158692),\n",
              "      'attention': np.float64(8.541579447986557),\n",
              "      'ffn': np.float64(3.9630667405128475),\n",
              "      'layernorm': np.float64(0.11680520939826965),\n",
              "      'output_layer': np.float64(0.26752963185310363)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to get the frequency of the elements in a list.',\n",
              "    'ground_truth_code': 'import collections\\r\\ndef freq_count(list1):\\r\\n  freq_count= collections.Counter(list1)\\r\\n  return freq_count',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of each digits in a matrix, The',\n",
              "    'test_cases': ['assert freq_count([10,10,10,10,20,20,20,20,40,40,50,50,30])==({10: 4, 20: 4, 40: 2, 50: 2, 30: 1}) ',\n",
              "     'assert freq_count([1,2,3,4,3,2,4,1,3,1,4])==({1:3, 2:2,3:3,4:3}) ',\n",
              "     'assert freq_count([5,6,7,4,9,10,4,5,6,7,9,5])==({10:1,5:3,6:2,7:2,4:2,9:2}) '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.20969608259015,\n",
              "     'tokenization_energy': 0.1116960825920105,\n",
              "     'inference_energy': 26.097999999998137,\n",
              "     'energy_per_token': 1.7473130721726766,\n",
              "     'time': 0.5616357326507568,\n",
              "     'components': {'embeddings': np.float64(0.11177898931503295),\n",
              "      'attention': np.float64(12.830971996294569),\n",
              "      'ffn': np.float64(12.378696670066798),\n",
              "      'layernorm': np.float64(0.11477086544036866),\n",
              "      'output_layer': np.float64(0.25351526737213137)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the closest smaller number than n.',\n",
              "    'ground_truth_code': 'def closest_num(N):\\r\\n  return (N - 1)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum prime number in a in If',\n",
              "    'test_cases': ['assert closest_num(11) == 10',\n",
              "     'assert closest_num(7) == 6',\n",
              "     'assert closest_num(12) == 11'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.981120330810196,\n",
              "     'tokenization_energy': 0.32212033081054686,\n",
              "     'inference_energy': 21.65899999999965,\n",
              "     'energy_per_token': 1.6908554100623228,\n",
              "     'time': 0.568476676940918,\n",
              "     'components': {'embeddings': np.float64(0.12384152984619141),\n",
              "      'attention': np.float64(12.830217574118054),\n",
              "      'ffn': np.float64(8.202975847720051),\n",
              "      'layernorm': np.float64(0.1742900505065918),\n",
              "      'output_layer': np.float64(0.1918947982788086)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to find the length of the longest word.',\n",
              "    'ground_truth_code': 'def len_log(list1):\\r\\n    max=len(list1[0])\\r\\n    for i in list1:\\r\\n        if len(i)>max:\\r\\n            max=len(i)\\r\\n    return max',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of the length substring in You',\n",
              "    'test_cases': ['assert len_log([\"python\",\"PHP\",\"bigdata\"]) == 7',\n",
              "     'assert len_log([\"a\",\"ab\",\"abc\"]) == 3',\n",
              "     'assert len_log([\"small\",\"big\",\"tall\"]) == 5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 30.62527540207235,\n",
              "     'tokenization_energy': 0.1092754020690918,\n",
              "     'inference_energy': 30.51600000000326,\n",
              "     'energy_per_token': 2.1875196715765965,\n",
              "     'time': 0.7319967746734619,\n",
              "     'components': {'embeddings': np.float64(0.10867604827880858),\n",
              "      'attention': np.float64(16.30660522151634),\n",
              "      'ffn': np.float64(11.730676927804362),\n",
              "      'layernorm': np.float64(0.11654870796203613),\n",
              "      'output_layer': np.float64(0.20715051460266112)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to check if a substring is present in a given list of string values.',\n",
              "    'ground_truth_code': 'def find_substring(str1, sub_str):\\r\\n   if any(sub_str in s for s in str1):\\r\\n       return True\\r\\n   return False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number is a in a binary string of strings,.\\n Return',\n",
              "    'test_cases': ['assert find_substring([\"red\", \"black\", \"white\", \"green\", \"orange\"],\"ack\")==True',\n",
              "     'assert find_substring([\"red\", \"black\", \"white\", \"green\", \"orange\"],\"abc\")==False',\n",
              "     'assert find_substring([\"red\", \"black\", \"white\", \"green\", \"orange\"],\"ange\")==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.708538904199493,\n",
              "     'tokenization_energy': 0.12653890419006347,\n",
              "     'inference_energy': 21.58200000000943,\n",
              "     'energy_per_token': 1.1425546791683943,\n",
              "     'time': 0.5587809085845947,\n",
              "     'components': {'embeddings': np.float64(0.11483770561218261),\n",
              "      'attention': np.float64(16.779636825573164),\n",
              "      'ffn': np.float64(12.377860820052797),\n",
              "      'layernorm': np.float64(0.11701860666275025),\n",
              "      'output_layer': np.float64(0.21490034341812136)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to check whether the given number is undulating or not.',\n",
              "    'ground_truth_code': 'def is_undulating(n): \\r\\n\\tif (len(n) <= 2): \\r\\n\\t\\treturn False\\r\\n\\tfor i in range(2, len(n)): \\r\\n\\t\\tif (n[i - 2] != n[i]): \\r\\n\\t\\t\\treturn False\\r\\n\\treturn True',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given\\n is airected a not. The',\n",
              "    'test_cases': ['assert is_undulating(\"1212121\") == True',\n",
              "     'assert is_undulating(\"1991\") == False',\n",
              "     'assert is_undulating(\"121\") == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.145653405193006,\n",
              "     'tokenization_energy': 0.11065340518951416,\n",
              "     'inference_energy': 26.035000000003492,\n",
              "     'energy_per_token': 1.6341033378245629,\n",
              "     'time': 0.5607175827026367,\n",
              "     'components': {'embeddings': np.float64(0.16854888439178467),\n",
              "      'attention': np.float64(4.40940804195404),\n",
              "      'ffn': np.float64(8.40140361309354),\n",
              "      'layernorm': np.float64(4.260000000009313),\n",
              "      'output_layer': np.float64(0.19312234544754028)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': \"Write a function to calculate the value of 'a' to the power 'b'.\",\n",
              "    'ground_truth_code': 'def power(a,b):\\r\\n\\tif b==0:\\r\\n\\t\\treturn 1\\r\\n\\telif a==0:\\r\\n\\t\\treturn 0\\r\\n\\telif b==1:\\r\\n\\t\\treturn a\\r\\n\\telse:\\r\\n\\t\\treturn a*power(a,b-1)',\n",
              "    'generated_code': \")\\n\\n the function that compute the probability of ax' in the nearest ofb' The\",\n",
              "    'test_cases': ['assert power(3,4) == 81',\n",
              "     'assert power(2,3) == 8',\n",
              "     'assert power(5,5) == 3125'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.91186609768856,\n",
              "     'tokenization_energy': 0.10886609768867492,\n",
              "     'inference_energy': 21.802999999999884,\n",
              "     'energy_per_token': 1.217325894316031,\n",
              "     'time': 0.5556502342224121,\n",
              "     'components': {'embeddings': np.float64(0.11060218858718872),\n",
              "      'attention': np.float64(16.94578283048479),\n",
              "      'ffn': np.float64(12.616393666736084),\n",
              "      'layernorm': np.float64(0.17815140509605407),\n",
              "      'output_layer': np.float64(0.21239802646636963)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to extract the index minimum value record from the given tuples.',\n",
              "    'ground_truth_code': 'from operator import itemgetter \\r\\ndef index_minimum(test_list):\\r\\n  res = min(test_list, key = itemgetter(1))[0]\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits of of from from a given\\n in The',\n",
              "    'test_cases': [\"assert index_minimum([('Rash', 143), ('Manjeet', 200), ('Varsha', 100)]) == 'Varsha'\",\n",
              "     \"assert index_minimum([('Yash', 185), ('Dawood', 125), ('Sanya', 175)]) == 'Dawood'\",\n",
              "     \"assert index_minimum([('Sai', 345), ('Salman', 145), ('Ayesha', 96)]) == 'Ayesha'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.426967745291883,\n",
              "     'tokenization_energy': 0.11196774530410766,\n",
              "     'inference_energy': 26.314999999987776,\n",
              "     'energy_per_token': 1.6516854840807427,\n",
              "     'time': 0.5602490901947021,\n",
              "     'components': {'embeddings': np.float64(0.11329497170448302),\n",
              "      'attention': np.float64(17.216388177865184),\n",
              "      'ffn': np.float64(8.190101349585923),\n",
              "      'layernorm': np.float64(0.11650053405761719),\n",
              "      'output_layer': np.float64(0.19557142639160155)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find the minimum length of sublist.',\n",
              "    'ground_truth_code': 'def Find_Min_Length(lst):  \\r\\n    minLength = min(len(x) for x in lst )\\r\\n    return minLength ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number of a in The',\n",
              "    'test_cases': ['assert Find_Min_Length([[1],[1,2]]) == 1',\n",
              "     'assert Find_Min_Length([[1,2],[1,2,3],[1,2,3,4]]) == 2',\n",
              "     'assert Find_Min_Length([[3,3,3],[4,4,4,4]]) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.0832476348927,\n",
              "     'tokenization_energy': 0.1122476348876953,\n",
              "     'inference_energy': 21.971000000005006,\n",
              "     'energy_per_token': 1.6987113565302077,\n",
              "     'time': 0.5520362854003906,\n",
              "     'components': {'embeddings': np.float64(0.180025634765625),\n",
              "      'attention': np.float64(16.83348656034167),\n",
              "      'ffn': np.float64(12.471155102022575),\n",
              "      'layernorm': np.float64(0.115086181640625),\n",
              "      'output_layer': np.float64(0.19324478149414062)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to find the number of divisors of a given integer.',\n",
              "    'ground_truth_code': 'def divisor(n):\\r\\n  for i in range(n):\\r\\n    x = len([i for i in range(1,n+1) if not n % i])\\r\\n  return x',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of uniqueisors of a number integer n The',\n",
              "    'test_cases': ['assert divisor(15) == 4 ',\n",
              "     'assert divisor(12) == 6',\n",
              "     'assert divisor(9) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.9621517944386,\n",
              "     'tokenization_energy': 0.11615179443359375,\n",
              "     'inference_energy': 21.846000000005006,\n",
              "     'energy_per_token': 1.2918912820258,\n",
              "     'time': 0.5634663105010986,\n",
              "     'components': {'embeddings': np.float64(0.11240794038772582),\n",
              "      'attention': np.float64(4.427125725746155),\n",
              "      'ffn': np.float64(8.615378722188877),\n",
              "      'layernorm': np.float64(0.11751379251480103),\n",
              "      'output_layer': np.float64(0.20952551364898683)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find frequency count of list of lists.',\n",
              "    'ground_truth_code': 'def frequency_lists(list1):\\r\\n    list1 = [item for sublist in list1 for item in sublist]\\r\\n    dic_data = {}\\r\\n    for num in list1:\\r\\n        if num in dic_data.keys():\\r\\n            dic_data[num] += 1\\r\\n        else:\\r\\n            key = num\\r\\n            value = 1\\r\\n            dic_data[key] = value\\r\\n    return dic_data\\r\\n',\n",
              "    'generated_code': ')\\n\\n the function that compute the of of each of integers in So',\n",
              "    'test_cases': ['assert frequency_lists([[1, 2, 3, 2], [4, 5, 6, 2], [7, 8, 9, 5]])=={1: 1, 2: 3, 3: 1, 4: 1, 5: 2, 6: 1, 7: 1, 8: 1, 9: 1}',\n",
              "     'assert frequency_lists([[1,2,3,4],[5,6,7,8],[9,10,11,12]])=={1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1,10:1,11:1,12:1}',\n",
              "     'assert frequency_lists([[20,30,40,17],[18,16,14,13],[10,20,30,40]])=={20:2,30:2,40:2,17: 1,18:1, 16: 1,14: 1,13: 1, 10: 1}'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.45951998042874,\n",
              "     'tokenization_energy': 0.11151998043060303,\n",
              "     'inference_energy': 26.347999999998137,\n",
              "     'energy_per_token': 2.035347690802211,\n",
              "     'time': 0.5598342418670654,\n",
              "     'components': {'embeddings': np.float64(0.11067403793334962),\n",
              "      'attention': np.float64(17.183999982359477),\n",
              "      'ffn': np.float64(12.276577987665776),\n",
              "      'layernorm': np.float64(0.12042403149604797),\n",
              "      'output_layer': np.float64(4.379000000000815)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to multiply all the numbers in a list and divide with the length of the list.',\n",
              "    'ground_truth_code': 'def multiply_num(numbers):  \\r\\n    total = 1\\r\\n    for x in numbers:\\r\\n        total *= x  \\r\\n    return total/len(numbers) ',\n",
              "    'generated_code': ')\\n\\n the function that compute two the digits in a given, return by the sum of the list. So',\n",
              "    'test_cases': ['assert multiply_num((8, 2, 3, -1, 7))==-67.2',\n",
              "     'assert multiply_num((-10,-20,-30))==-2000.0',\n",
              "     'assert multiply_num((19,15,18))==1710.0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.216736190314172,\n",
              "     'tokenization_energy': 0.11573619031906128,\n",
              "     'inference_energy': 22.10099999999511,\n",
              "     'energy_per_token': 1.057939818586389,\n",
              "     'time': 0.5685553550720215,\n",
              "     'components': {'embeddings': np.float64(0.11591941952705384),\n",
              "      'attention': np.float64(13.196534568065077),\n",
              "      'ffn': np.float64(12.623651357656579),\n",
              "      'layernorm': np.float64(0.11971041345596313),\n",
              "      'output_layer': np.float64(0.21691488790512084)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function to convert the given decimal number to its binary equivalent.',\n",
              "    'ground_truth_code': 'def decimal_to_binary(n): \\r\\n    return bin(n).replace(\"0b\",\"\") ',\n",
              "    'generated_code': ')\\n\\n the function that compute a digits matrix number to the hexadecimal representation, You',\n",
              "    'test_cases': [\"assert decimal_to_binary(8) == '1000'\",\n",
              "     \"assert decimal_to_binary(18) == '10010'\",\n",
              "     \"assert decimal_to_binary(7) == '111' \"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.622626718999584,\n",
              "     'tokenization_energy': 0.11462671899795532,\n",
              "     'inference_energy': 26.50800000000163,\n",
              "     'energy_per_token': 1.7748417812666388,\n",
              "     'time': 0.5633594989776611,\n",
              "     'components': {'embeddings': np.float64(4.471999999994296),\n",
              "      'attention': np.float64(4.396118121623993),\n",
              "      'ffn': np.float64(8.29307027268072),\n",
              "      'layernorm': np.float64(0.11794079661369324),\n",
              "      'output_layer': np.float64(0.27366925120353697)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the next smallest palindrome of a specified number.',\n",
              "    'ground_truth_code': 'import sys\\r\\ndef next_smallest_palindrome(num):\\r\\n    numstr = str(num)\\r\\n    for i in range(num+1,sys.maxsize):\\r\\n        if str(i) == str(i)[::-1]:\\r\\n            return i',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum prime number after a given\\n.\\n The',\n",
              "    'test_cases': ['assert next_smallest_palindrome(99)==101',\n",
              "     'assert next_smallest_palindrome(1221)==1331',\n",
              "     'assert next_smallest_palindrome(120)==121'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.455187388423948,\n",
              "     'tokenization_energy': 0.20418738842010498,\n",
              "     'inference_energy': 26.25100000000384,\n",
              "     'energy_per_token': 1.7636791592282632,\n",
              "     'time': 0.5714931488037109,\n",
              "     'components': {'embeddings': np.float64(0.11726030945777892),\n",
              "      'attention': np.float64(4.7539035203456885),\n",
              "      'ffn': np.float64(8.296252552515712),\n",
              "      'layernorm': np.float64(4.372000000003027),\n",
              "      'output_layer': np.float64(0.19756033110618593)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the kth element in the given array.',\n",
              "    'ground_truth_code': 'def kth_element(arr, n, k):\\r\\n  for i in range(n):\\r\\n    for j in range(0, n-i-1):\\r\\n      if arr[j] > arr[j+1]:\\r\\n        arr[j], arr[j+1] == arr[j+1], arr[j]\\r\\n  return arr[k-1]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-th smallest in a matrix matrix, The',\n",
              "    'test_cases': ['assert kth_element([12,3,5,7,19], 5, 2) == 3',\n",
              "     'assert kth_element([17,24,8,23], 4, 3) == 8',\n",
              "     'assert kth_element([16,21,25,36,4], 5, 4) == 36'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 21.968153037782407,\n",
              "     'tokenization_energy': 0.11315303778648376,\n",
              "     'inference_energy': 21.854999999995925,\n",
              "     'energy_per_token': 1.4645435358521606,\n",
              "     'time': 0.5589752197265625,\n",
              "     'components': {'embeddings': np.float64(0.17129284834861755),\n",
              "      'attention': np.float64(12.762693084219006),\n",
              "      'ffn': np.float64(8.210908772242256),\n",
              "      'layernorm': np.float64(0.11966871595382692),\n",
              "      'output_layer': np.float64(0.20188362002372742)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to convert snake case string to camel case string.',\n",
              "    'ground_truth_code': \"def snake_to_camel(word):\\r\\n        import re\\r\\n        return ''.join(x.capitalize() or '_' for x in word.split('_'))\",\n",
              "    'generated_code': ')\\n\\n the function that compute a_case to to Pascal case string.\\n The',\n",
              "    'test_cases': [\"assert snake_to_camel('python_program')=='PythonProgram'\",\n",
              "     \"assert snake_to_camel('python_language')==('PythonLanguage')\",\n",
              "     \"assert snake_to_camel('programming_language')==('ProgrammingLanguage')\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.499060664896852,\n",
              "     'tokenization_energy': 0.11906066489219666,\n",
              "     'inference_energy': 26.380000000004657,\n",
              "     'energy_per_token': 1.8927900474926322,\n",
              "     'time': 0.5599873065948486,\n",
              "     'components': {'embeddings': np.float64(4.408999999999651),\n",
              "      'attention': np.float64(17.046754224789908),\n",
              "      'ffn': np.float64(12.446798717967932),\n",
              "      'layernorm': np.float64(0.11737354397773742),\n",
              "      'output_layer': np.float64(0.1966878705024719)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find eulerian number a(n, m).',\n",
              "    'ground_truth_code': 'def eulerian_num(n, m): \\r\\n\\tif (m >= n or n == 0): \\r\\n\\t\\treturn 0 \\r\\n\\tif (m == 0): \\r\\n\\t\\treturn 1 \\r\\n\\treturn ((n - m) * eulerian_num(n - 1, m - 1) +(m + 1) * eulerian_num(n - 1, m))',\n",
              "    'generated_code': ')\\n\\n the function that compute theian trails E(n, k) \\n',\n",
              "    'test_cases': ['assert eulerian_num(3, 1) == 4',\n",
              "     'assert eulerian_num(4, 1) == 11',\n",
              "     'assert eulerian_num(5, 3) == 26'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.66073128580954,\n",
              "     'tokenization_energy': 0.11173128581047058,\n",
              "     'inference_energy': 26.54899999999907,\n",
              "     'energy_per_token': 1.9043379489863956,\n",
              "     'time': 0.5658493041992188,\n",
              "     'components': {'embeddings': np.float64(0.16878888177871704),\n",
              "      'attention': np.float64(8.449044428115362),\n",
              "      'ffn': np.float64(8.425523128983215),\n",
              "      'layernorm': np.float64(0.1154463653564453),\n",
              "      'output_layer': np.float64(0.19520687580108642)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to sort each sublist of strings in a given list of lists using lambda function.',\n",
              "    'ground_truth_code': 'def sort_sublists(input_list):\\r\\n    result = [sorted(x, key = lambda x:x[0]) for x in input_list] \\r\\n    return result\\r',\n",
              "    'generated_code': ')\\n\\n the function that compute a row in a in a matrix matrix of strings of the functions as But',\n",
              "    'test_cases': ['assert sort_sublists(([\"green\", \"orange\"], [\"black\", \"white\"], [\"white\", \"black\", \"orange\"]))==[[\\'green\\', \\'orange\\'], [\\'black\\', \\'white\\'], [\\'black\\', \\'orange\\', \\'white\\']]',\n",
              "     'assert sort_sublists(([\" red \",\"green\" ],[\"blue \",\" black\"],[\" orange\",\"brown\"]))==[[\\' red \\', \\'green\\'], [\\' black\\', \\'blue \\'], [\\' orange\\', \\'brown\\']]',\n",
              "     'assert sort_sublists(([\"zilver\",\"gold\"], [\"magnesium\",\"aluminium\"], [\"steel\", \"bronze\"]))==[[\\'gold\\', \\'zilver\\'],[\\'aluminium\\', \\'magnesium\\'], [\\'bronze\\', \\'steel\\']]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.1369829192186,\n",
              "     'tokenization_energy': 0.12498291921615601,\n",
              "     'inference_energy': 22.012000000002445,\n",
              "     'energy_per_token': 1.10684914596093,\n",
              "     'time': 0.5621769428253174,\n",
              "     'components': {'embeddings': np.float64(0.1275328781604767),\n",
              "      'attention': np.float64(12.735540382616687),\n",
              "      'ffn': np.float64(8.564605623731739),\n",
              "      'layernorm': np.float64(0.11854346871376037),\n",
              "      'output_layer': np.float64(0.26908837676048275)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to count true booleans in the given list.',\n",
              "    'ground_truth_code': 'def count(lst):   \\r\\n    return sum(lst) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the oroleans in a boolean string of The',\n",
              "    'test_cases': ['assert count([True,False,True]) == 2',\n",
              "     'assert count([False,False]) == 0',\n",
              "     'assert count([True,True,True]) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.598573512785368,\n",
              "     'tokenization_energy': 0.18757351279258727,\n",
              "     'inference_energy': 26.410999999992782,\n",
              "     'energy_per_token': 1.7732382341856912,\n",
              "     'time': 0.5665276050567627,\n",
              "     'components': {'embeddings': np.float64(0.11238415241241455),\n",
              "      'attention': np.float64(8.572788448085891),\n",
              "      'ffn': np.float64(12.62591063071799),\n",
              "      'layernorm': np.float64(0.1159058837890625),\n",
              "      'output_layer': np.float64(0.1935521697998047)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to add the given list to the given tuples.',\n",
              "    'ground_truth_code': 'def add_lists(test_list, test_tup):\\r\\n  res = tuple(list(test_tup) + test_list)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute two digits two of the given list in The',\n",
              "    'test_cases': ['assert add_lists([5, 6, 7], (9, 10)) == (9, 10, 5, 6, 7)',\n",
              "     'assert add_lists([6, 7, 8], (10, 11)) == (10, 11, 6, 7, 8)',\n",
              "     'assert add_lists([7, 8, 9], (11, 12)) == (11, 12, 7, 8, 9)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.418223335266813,\n",
              "     'tokenization_energy': 0.11122333526611328,\n",
              "     'inference_energy': 26.3070000000007,\n",
              "     'energy_per_token': 1.887015952519058,\n",
              "     'time': 0.5689098834991455,\n",
              "     'components': {'embeddings': np.float64(0.11043437194824218),\n",
              "      'attention': np.float64(8.568046991106703),\n",
              "      'ffn': np.float64(12.40677157617826),\n",
              "      'layernorm': np.float64(0.12938160467147827),\n",
              "      'output_layer': np.float64(0.2034483504295349)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to count hexadecimal numbers for a given range.',\n",
              "    'ground_truth_code': 'def count_Hexadecimal(L,R) :  \\r\\n    count = 0;  \\r\\n    for i in range(L,R + 1) : \\r\\n        if (i >= 10 and i <= 15) : \\r\\n            count += 1;  \\r\\n        elif (i > 15) : \\r\\n            k = i;  \\r\\n            while (k != 0) :  \\r\\n                if (k % 16 >= 10) : \\r\\n                    count += 1;  \\r\\n                k = k // 16;  \\r\\n    return count;  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the digits with which given n of The',\n",
              "    'test_cases': ['assert count_Hexadecimal(10,15) == 6',\n",
              "     'assert count_Hexadecimal(2,4) == 0',\n",
              "     'assert count_Hexadecimal(15,16) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.135799368864625,\n",
              "     'tokenization_energy': 0.12279936885833741,\n",
              "     'inference_energy': 22.013000000006286,\n",
              "     'energy_per_token': 1.5811285263474733,\n",
              "     'time': 0.5593268871307373,\n",
              "     'components': {'embeddings': np.float64(0.12294617700576782),\n",
              "      'attention': np.float64(12.690818334577022),\n",
              "      'ffn': np.float64(12.533344966418227),\n",
              "      'layernorm': np.float64(0.11777134704589844),\n",
              "      'output_layer': np.float64(0.19959265899658205)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to merge multiple sorted inputs into a single sorted iterator using heap queue algorithm.',\n",
              "    'ground_truth_code': 'import heapq\\r\\ndef merge_sorted_list(num1,num2,num3):\\r\\n  num1=sorted(num1)\\r\\n  num2=sorted(num2)\\r\\n  num3=sorted(num3)\\r\\n  result = heapq.merge(num1,num2,num3)\\r\\n  return list(result)',\n",
              "    'generated_code': ')\\n\\n the function that compute two arrays arrays into a single sorted output. the-based algorithm.\\n The',\n",
              "    'test_cases': ['assert merge_sorted_list([25, 24, 15, 4, 5, 29, 110],[19, 20, 11, 56, 25, 233, 154],[24, 26, 54, 48])==[4, 5, 11, 15, 19, 20, 24, 24, 25, 25, 26, 29, 48, 54, 56, 110, 154, 233]',\n",
              "     'assert merge_sorted_list([1, 3, 5, 6, 8, 9], [2, 5, 7, 11], [1, 4, 7, 8, 12])==[1, 1, 2, 3, 4, 5, 5, 6, 7, 7, 8, 8, 9, 11, 12]',\n",
              "     'assert merge_sorted_list([18, 14, 10, 9, 8, 7, 9, 3, 2, 4, 1],[25, 35, 22, 85, 14, 65, 75, 25, 58],[12, 74, 9, 50, 61, 41])==[1, 2, 3, 4, 7, 8, 9, 9, 9, 10, 12, 14, 14, 18, 22, 25, 25, 35, 41, 50, 58, 61, 65, 74, 75, 85]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.645552963252644,\n",
              "     'tokenization_energy': 0.11255296325683593,\n",
              "     'inference_energy': 26.53299999999581,\n",
              "     'energy_per_token': 1.4023975243817182,\n",
              "     'time': 0.5662143230438232,\n",
              "     'components': {'embeddings': np.float64(0.11513059234619141),\n",
              "      'attention': np.float64(12.734861279246982),\n",
              "      'ffn': np.float64(12.680037315836643),\n",
              "      'layernorm': np.float64(0.11601039099693299),\n",
              "      'output_layer': np.float64(0.21038494157791138)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to find the count of rotations of a binary string with odd value.',\n",
              "    'ground_truth_code': \"def odd_Equivalent(s,n): \\r\\n    count=0\\r\\n    for i in range(0,n): \\r\\n        if (s[i] == '1'): \\r\\n            count = count + 1\\r\\n    return count \",\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all for a given string that the length, Return',\n",
              "    'test_cases': ['assert odd_Equivalent(\"011001\",6) == 3',\n",
              "     'assert odd_Equivalent(\"11011\",5) == 4',\n",
              "     'assert odd_Equivalent(\"1010\",4) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.33255686331191,\n",
              "     'tokenization_energy': 0.13455686330795288,\n",
              "     'inference_energy': 22.198000000003958,\n",
              "     'energy_per_token': 1.1753977296479954,\n",
              "     'time': 0.5691876411437988,\n",
              "     'components': {'embeddings': np.float64(0.11186386370658874),\n",
              "      'attention': np.float64(8.537503519529826),\n",
              "      'ffn': np.float64(8.326972928523086),\n",
              "      'layernorm': np.float64(0.20608460903167725),\n",
              "      'output_layer': np.float64(0.21559051275253296)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to extract the ranges that are missing from the given list with the given start range and end range values.',\n",
              "    'ground_truth_code': 'def extract_missing(test_list, strt_val, stop_val):\\r\\n  res = []\\r\\n  for sub in test_list:\\r\\n    if sub[0] > strt_val:\\r\\n      res.append((strt_val, sub[0]))\\r\\n      strt_val = sub[1]\\r\\n    if strt_val < stop_val:\\r\\n      res.append((strt_val, stop_val))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits of are in in the ranges ... of the given constraints and. end range..\\n The',\n",
              "    'test_cases': ['assert extract_missing([(6, 9), (15, 34), (48, 70)], 2, 100) == [(2, 6), (9, 100), (9, 15), (34, 100), (34, 48), (70, 100)]',\n",
              "     'assert extract_missing([(7, 2), (15, 19), (38, 50)], 5, 60) == [(5, 7), (2, 60), (2, 15), (19, 60), (19, 38), (50, 60)]',\n",
              "     'assert extract_missing([(7, 2), (15, 19), (38, 50)], 1, 52) == [(1, 7), (2, 52), (2, 15), (19, 52), (19, 38), (50, 52)]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.204698051921326,\n",
              "     'tokenization_energy': 0.11969805192947389,\n",
              "     'inference_energy': 22.08499999999185,\n",
              "     'energy_per_token': 0.888187922076853,\n",
              "     'time': 0.5693304538726807,\n",
              "     'components': {'embeddings': np.float64(0.18092419409751892),\n",
              "      'attention': np.float64(12.8199491777363),\n",
              "      'ffn': np.float64(8.214345154521288),\n",
              "      'layernorm': np.float64(0.11675339269638062),\n",
              "      'output_layer': np.float64(0.2742761664390564)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a function to find common elements in given nested lists. * list item * list item * list item * list item',\n",
              "    'ground_truth_code': 'def common_in_nested_lists(nestedlist):\\r\\n    result = list(set.intersection(*map(set, nestedlist)))\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the div in all n arrays. TheYou elements item * item * list item * list item *',\n",
              "    'test_cases': ['assert common_in_nested_lists([[12, 18, 23, 25, 45], [7, 12, 18, 24, 28], [1, 5, 8, 12, 15, 16, 18]])==[18, 12]',\n",
              "     'assert common_in_nested_lists([[12, 5, 23, 25, 45], [7, 11, 5, 23, 28], [1, 5, 8, 18, 23, 16]])==[5,23]',\n",
              "     'assert common_in_nested_lists([[2, 3,4, 1], [4, 5], [6,4, 8],[4, 5], [6, 8,4]])==[4]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.969945544010727,\n",
              "     'tokenization_energy': 0.2069455440044403,\n",
              "     'inference_energy': 26.763000000006286,\n",
              "     'energy_per_token': 1.078797821760429,\n",
              "     'time': 0.5741088390350342,\n",
              "     'components': {'embeddings': np.float64(0.11069083857536316),\n",
              "      'attention': np.float64(13.182470407234623),\n",
              "      'ffn': np.float64(12.483524775037425),\n",
              "      'layernorm': np.float64(0.11960097551345826),\n",
              "      'output_layer': np.float64(0.21788504123687744)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a python function to find the perimeter of a cylinder.',\n",
              "    'ground_truth_code': 'def perimeter(diameter,height) : \\r\\n    return 2*(diameter+height)  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of a triangle given The',\n",
              "    'test_cases': ['assert perimeter(2,4) == 12',\n",
              "     'assert perimeter(1,2) == 6',\n",
              "     'assert perimeter(3,1) == 8'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.6370179753314,\n",
              "     'tokenization_energy': 0.11401797533035278,\n",
              "     'inference_energy': 26.523000000001048,\n",
              "     'energy_per_token': 2.0490013827178,\n",
              "     'time': 0.5694715976715088,\n",
              "     'components': {'embeddings': np.float64(0.11372190713882446),\n",
              "      'attention': np.float64(8.771097063059571),\n",
              "      'ffn': np.float64(12.685761421682313),\n",
              "      'layernorm': np.float64(0.11879760980606079),\n",
              "      'output_layer': np.float64(4.39100000000326)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to check if a string represents an integer or not.',\n",
              "    'ground_truth_code': 'def check_integer(text):\\r\\n text = text.strip()\\r\\n if len(text) < 1:\\r\\n    return None\\r\\n else:\\r\\n     if all(text[i] in \"0123456789\" for i in range(len(text))):\\r\\n          return True\\r\\n     elif (text[0] in \"+-\") and \\\\\\r\\n         all(text[i] in \"0123456789\" for i in range(1,len(text))):\\r\\n         return True\\r\\n     else:\\r\\n        return False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number is a integer that a, The',\n",
              "    'test_cases': ['assert check_integer(\"python\")==False',\n",
              "     'assert check_integer(\"1\")==True',\n",
              "     'assert check_integer(\"12345\")==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.164907161952346,\n",
              "     'tokenization_energy': 0.12290716195106506,\n",
              "     'inference_energy': 22.04200000000128,\n",
              "     'energy_per_token': 1.4776604774634898,\n",
              "     'time': 0.5691699981689453,\n",
              "     'components': {'embeddings': np.float64(0.12243483138084411),\n",
              "      'attention': np.float64(8.6890940718574),\n",
              "      'ffn': np.float64(12.572165330171819),\n",
              "      'layernorm': np.float64(0.11705392956733704),\n",
              "      'output_layer': np.float64(0.1966132936477661)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to assign frequency to each tuple in the given tuple list.',\n",
              "    'ground_truth_code': 'from collections import Counter \\r\\ndef assign_freq(test_list):\\r\\n  res = [(*key, val) for key, val in Counter(test_list).items()]\\r\\n  return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the to each character in a tuple matrix list.\\n The',\n",
              "    'test_cases': [\"assert assign_freq([(6, 5, 8), (2, 7), (6, 5, 8), (6, 5, 8), (9, ), (2, 7)] ) == '[(6, 5, 8, 3), (2, 7, 2), (9, 1)]'\",\n",
              "     \"assert assign_freq([(4, 2, 4), (7, 1), (4, 8), (4, 2, 4), (9, 2), (7, 1)] ) == '[(4, 2, 4, 2), (7, 1, 2), (4, 8, 1), (9, 2, 1)]'\",\n",
              "     \"assert assign_freq([(11, 13, 10), (17, 21), (4, 2, 3), (17, 21), (9, 2), (4, 2, 3)] ) == '[(11, 13, 10, 1), (17, 21, 2), (4, 2, 3, 2), (9, 2, 1)]'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.611753766776527,\n",
              "     'tokenization_energy': 0.12275376677513122,\n",
              "     'inference_energy': 26.489000000001397,\n",
              "     'energy_per_token': 1.663234610423533,\n",
              "     'time': 0.5743687152862549,\n",
              "     'components': {'embeddings': np.float64(4.509999999994761),\n",
              "      'attention': np.float64(12.83624391080567),\n",
              "      'ffn': np.float64(12.491815181250217),\n",
              "      'layernorm': np.float64(0.11779290962219238),\n",
              "      'output_layer': np.float64(0.19808816528320314)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to check whether all dictionaries in a list are empty or not.',\n",
              "    'ground_truth_code': 'def empty_dit(list1):\\r\\n empty_dit=all(not d for d in list1)\\r\\n return empty_dit',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a the in a given are non.\\n not. Return',\n",
              "    'test_cases': ['assert empty_dit([{},{},{}])==True',\n",
              "     'assert empty_dit([{1,2},{},{}])==False',\n",
              "     'assert empty_dit({})==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.604922404287617,\n",
              "     'tokenization_energy': 0.11292240428924562,\n",
              "     'inference_energy': 26.49199999999837,\n",
              "     'energy_per_token': 1.5649954355463305,\n",
              "     'time': 0.576207160949707,\n",
              "     'components': {'embeddings': np.float64(0.11504866790771485),\n",
              "      'attention': np.float64(12.840606115341533),\n",
              "      'ffn': np.float64(8.240775676250923),\n",
              "      'layernorm': np.float64(0.116841721534729),\n",
              "      'output_layer': np.float64(0.21134909629821777)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to convert a given tuple of positive integers into an integer.',\n",
              "    'ground_truth_code': \"def tuple_to_int(nums):\\r\\n    result = int(''.join(map(str,nums)))\\r\\n    return result\",\n",
              "    'generated_code': ')\\n\\n the function that compute a given integer of integers integers into a array, The',\n",
              "    'test_cases': ['assert tuple_to_int((1,2,3))==123',\n",
              "     'assert tuple_to_int((4,5,6))==456',\n",
              "     'assert tuple_to_int((5,6,7))==567'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.815832788696046,\n",
              "     'tokenization_energy': 0.1138327887058258,\n",
              "     'inference_energy': 26.70199999999022,\n",
              "     'energy_per_token': 1.6759895492935029,\n",
              "     'time': 0.57029128074646,\n",
              "     'components': {'embeddings': np.float64(0.11380176877975463),\n",
              "      'attention': np.float64(12.88798716019001),\n",
              "      'ffn': np.float64(12.722782147646765),\n",
              "      'layernorm': np.float64(0.1205722804069519),\n",
              "      'output_layer': np.float64(0.2022082028388977)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to convert all possible convertible elements in the list to float.',\n",
              "    'ground_truth_code': 'def list_to_float(test_list):\\r\\n  res = []\\r\\n  for tup in test_list:\\r\\n    temp = []\\r\\n    for ele in tup:\\r\\n      if ele.isalpha():\\r\\n        temp.append(ele)\\r\\n      else:\\r\\n        temp.append(float(ele))\\r\\n    res.append((temp[0],temp[1])) \\r\\n  return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute a the numbers\\n in a function of their.\\n The',\n",
              "    'test_cases': ['assert list_to_float( [(\"3\", \"4\"), (\"1\", \"26.45\"), (\"7.32\", \"8\"), (\"4\", \"8\")] ) == \\'[(3.0, 4.0), (1.0, 26.45), (7.32, 8.0), (4.0, 8.0)]\\'',\n",
              "     'assert list_to_float( [(\"4\", \"4\"), (\"2\", \"27\"), (\"4.12\", \"9\"), (\"7\", \"11\")] ) == \\'[(4.0, 4.0), (2.0, 27.0), (4.12, 9.0), (7.0, 11.0)]\\'',\n",
              "     'assert list_to_float( [(\"6\", \"78\"), (\"5\", \"26.45\"), (\"1.33\", \"4\"), (\"82\", \"13\")] ) == \\'[(6.0, 78.0), (5.0, 26.45), (1.33, 4.0), (82.0, 13.0)]\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.21860920572479,\n",
              "     'tokenization_energy': 0.11960920572280885,\n",
              "     'inference_energy': 22.09900000000198,\n",
              "     'energy_per_token': 1.3886630753577993,\n",
              "     'time': 0.5696749687194824,\n",
              "     'components': {'embeddings': np.float64(0.12055319666862488),\n",
              "      'attention': np.float64(12.875487748379703),\n",
              "      'ffn': np.float64(8.320647557262449),\n",
              "      'layernorm': np.float64(0.11969839453697204),\n",
              "      'output_layer': np.float64(0.20101276206970214)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': '[link text](https:// [link text](https:// [link text](https://)))write a function to convert a string to a list.',\n",
              "    'ground_truth_code': 'def string_to_list(string): \\r\\n    lst = list(string.split(\" \")) \\r\\n    return lst',\n",
              "    'generated_code': ')\\n\\n4]]https://linklink text](https:// [link text](https:// [ is a function that compute a given into a number of The',\n",
              "    'test_cases': ['assert string_to_list(\"python programming\")==[\\'python\\',\\'programming\\']',\n",
              "     'assert string_to_list(\"lists tuples strings\")==[\\'lists\\',\\'tuples\\',\\'strings\\']',\n",
              "     'assert string_to_list(\"write a program\")==[\\'write\\',\\'a\\',\\'program\\']'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.973777331598104,\n",
              "     'tokenization_energy': 0.11577733159065245,\n",
              "     'inference_energy': 26.85800000000745,\n",
              "     'energy_per_token': 0.8701218494063905,\n",
              "     'time': 0.5672159194946289,\n",
              "     'components': {'embeddings': np.float64(0.11525805568695068),\n",
              "      'attention': np.float64(17.287699953104834),\n",
              "      'ffn': np.float64(12.851308698397713),\n",
              "      'layernorm': np.float64(0.18185267686843873),\n",
              "      'output_layer': np.float64(0.224413259267807)},\n",
              "     'num_tokens': 31}},\n",
              "   {'prompt': 'Write a python function to find the element that appears only once in a sorted array.',\n",
              "    'ground_truth_code': 'def search(arr,n) :\\r\\n    XOR = 0\\r\\n    for i in range(n) :\\r\\n        XOR = XOR ^ arr[i]\\r\\n    return (XOR)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number in appears most once in a given array.\\n You',\n",
              "    'test_cases': ['assert search([1,1,2,2,3],5) == 3',\n",
              "     'assert search([1,1,3,3,4,4,5,5,7,7,8],11) == 8',\n",
              "     'assert search([1,2,2,3,3,4,4],7) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.772467132087915,\n",
              "     'tokenization_energy': 0.12946713209152222,\n",
              "     'inference_energy': 26.64299999999639,\n",
              "     'energy_per_token': 1.4873592851159954,\n",
              "     'time': 0.5683145523071289,\n",
              "     'components': {'embeddings': np.float64(0.1975041947364807),\n",
              "      'attention': np.float64(12.874727693321184),\n",
              "      'ffn': np.float64(8.257512462384533),\n",
              "      'layernorm': np.float64(0.11747619223594666),\n",
              "      'output_layer': np.float64(4.426999999996042)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the maximum product from the pairs of tuples within a given list.',\n",
              "    'ground_truth_code': 'def max_product_tuple(list1):\\r\\n    result_max = max([abs(x * y) for x, y in list1] )\\r\\n    return result_max',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of a given of consecutive in a given range of The',\n",
              "    'test_cases': ['assert max_product_tuple([(2, 7), (2, 6), (1, 8), (4, 9)] )==36',\n",
              "     'assert max_product_tuple([(10,20), (15,2), (5,10)] )==200',\n",
              "     'assert max_product_tuple([(11,44), (10,15), (20,5), (12, 9)] )==484'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.250357450014445,\n",
              "     'tokenization_energy': 0.13135745000839233,\n",
              "     'inference_energy': 22.119000000006054,\n",
              "     'energy_per_token': 1.1710714447376023,\n",
              "     'time': 0.5692441463470459,\n",
              "     'components': {'embeddings': np.float64(0.13115100860595702),\n",
              "      'attention': np.float64(12.792857536077499),\n",
              "      'ffn': np.float64(13.056240397224087),\n",
              "      'layernorm': np.float64(0.11909403228759766),\n",
              "      'output_layer': np.float64(0.21622192573547364)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the triplet with sum of the given array',\n",
              "    'ground_truth_code': 'def check_triplet(A, n, sum, count):\\r\\n    if count == 3 and sum == 0:\\r\\n        return True\\r\\n    if count == 3 or n == 0 or sum < 0:\\r\\n        return False\\r\\n    return check_triplet(A, n - 1, sum - A[n - 1], count + 1) or\\\\\\r\\n           check_triplet(A, n - 1, sum, count)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum ( the equal  maximum value,',\n",
              "    'test_cases': ['assert check_triplet([2, 7, 4, 0, 9, 5, 1, 3], 8, 6, 0) == True',\n",
              "     'assert check_triplet([1, 4, 5, 6, 7, 8, 5, 9], 8, 6, 0) == False',\n",
              "     'assert check_triplet([10, 4, 2, 3, 5], 5, 15, 0) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.708245397557388,\n",
              "     'tokenization_energy': 0.11624539756774903,\n",
              "     'inference_energy': 26.59199999998964,\n",
              "     'energy_per_token': 1.907731814111242,\n",
              "     'time': 0.5661835670471191,\n",
              "     'components': {'embeddings': np.float64(4.456999999994878),\n",
              "      'attention': np.float64(12.774322346194763),\n",
              "      'ffn': np.float64(12.503418582923942),\n",
              "      'layernorm': np.float64(0.11645137786865234),\n",
              "      'output_layer': np.float64(0.19699135303497314)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find n’th smart number.',\n",
              "    'ground_truth_code': 'MAX = 3000 \\r\\ndef smartNumber(n): \\r\\n\\tprimes = [0] * MAX \\r\\n\\tresult = [] \\r\\n\\tfor i in range(2, MAX): \\r\\n\\t\\tif (primes[i] == 0): \\r\\n\\t\\t\\tprimes[i] = 1 \\r\\n\\t\\t\\tj = i * 2 \\r\\n\\t\\t\\twhile (j < MAX): \\r\\n\\t\\t\\t\\tprimes[j] -= 1 \\r\\n\\t\\t\\t\\tif ( (primes[j] + 3) == 0): \\r\\n\\t\\t\\t\\t\\tresult.append(j) \\r\\n\\t\\t\\t\\tj = j + i \\r\\n\\tresult.sort() \\r\\n\\treturn result[n - 1] ',\n",
              "    'generated_code': ')\\n\\n the function that compute the-thth smallest number in A',\n",
              "    'test_cases': ['assert smartNumber(1) == 30',\n",
              "     'assert smartNumber(50) == 273',\n",
              "     'assert smartNumber(1000) == 2664'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.602394168147583,\n",
              "     'tokenization_energy': 0.11139416813850403,\n",
              "     'inference_energy': 26.49100000000908,\n",
              "     'energy_per_token': 2.216866180678965,\n",
              "     'time': 0.5705559253692627,\n",
              "     'components': {'embeddings': np.float64(0.11454319357872009),\n",
              "      'attention': np.float64(8.640373485097314),\n",
              "      'ffn': np.float64(12.600202375178224),\n",
              "      'layernorm': np.float64(0.12025155258178712),\n",
              "      'output_layer': np.float64(0.2303019878864288)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to sum all amicable numbers from 1 to a specified number.',\n",
              "    'ground_truth_code': 'def amicable_numbers_sum(limit):\\r\\n    if not isinstance(limit, int):\\r\\n        return \"Input is not an integer!\"\\r\\n    if limit < 1:\\r\\n        return \"Input must be bigger than 0!\"\\r\\n    amicables = set()\\r\\n    for num in range(2, limit+1):\\r\\n        if num in amicables:\\r\\n            continue\\r\\n        sum_fact = sum([fact for fact in range(1, num) if num % fact == 0])\\r\\n        sum_fact2 = sum([fact for fact in range(1, sum_fact) if sum_fact % fact == 0])\\r\\n        if num == sum_fact2 and num != sum_fact:\\r\\n            amicables.add(num)\\r\\n            amicables.add(sum_fact2)\\r\\n    return sum(amicables)',\n",
              "    'generated_code': ')\\n\\n the function that compute all theicable numbers up 1 to  given range.\\n The',\n",
              "    'test_cases': ['assert amicable_numbers_sum(999)==504',\n",
              "     'assert amicable_numbers_sum(9999)==31626',\n",
              "     'assert amicable_numbers_sum(99)==0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.266948630800936,\n",
              "     'tokenization_energy': 0.11394863080978393,\n",
              "     'inference_energy': 22.152999999991152,\n",
              "     'energy_per_token': 1.2370527017111632,\n",
              "     'time': 0.5637869834899902,\n",
              "     'components': {'embeddings': np.float64(0.11263696193695068),\n",
              "      'attention': np.float64(8.55570824217191),\n",
              "      'ffn': np.float64(12.688713748700103),\n",
              "      'layernorm': np.float64(0.21593925476074222),\n",
              "      'output_layer': np.float64(0.21717052459716799)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to get the angle of a complex number.',\n",
              "    'ground_truth_code': 'import cmath\\r\\ndef angle_complex(a,b):\\r\\n  cn=complex(a,b)\\r\\n  angle=cmath.phase(a+b)\\r\\n  return angle',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum between a triangle number in The',\n",
              "    'test_cases': ['assert angle_complex(0,1j)==1.5707963267948966 ',\n",
              "     'assert angle_complex(2,1j)==0.4636476090008061',\n",
              "     'assert angle_complex(0,2j)==1.5707963267948966'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.74329580688558,\n",
              "     'tokenization_energy': 0.11429580688476564,\n",
              "     'inference_energy': 26.629000000000815,\n",
              "     'energy_per_token': 2.05717660052966,\n",
              "     'time': 0.5869386196136475,\n",
              "     'components': {'embeddings': np.float64(4.612999999997555),\n",
              "      'attention': np.float64(17.27188452483248),\n",
              "      'ffn': np.float64(8.361277832982596),\n",
              "      'layernorm': np.float64(0.12386052989959716),\n",
              "      'output_layer': np.float64(0.2012681357860565)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the maximum difference between the number of 0s and number of 1s in any sub-string of the given binary string.',\n",
              "    'ground_truth_code': \"def find_length(string, n): \\r\\n\\tcurrent_sum = 0\\r\\n\\tmax_sum = 0\\r\\n\\tfor i in range(n): \\r\\n\\t\\tcurrent_sum += (1 if string[i] == '0' else -1) \\r\\n\\t\\tif current_sum < 0: \\r\\n\\t\\t\\tcurrent_sum = 0\\r\\n\\t\\tmax_sum = max(current_sum, max_sum) \\r\\n\\treturn max_sum if max_sum else 0\",\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number between two maximum of\\n1s and  of 1s in a subarray of length string string string.\\n The',\n",
              "    'test_cases': ['assert find_length(\"11000010001\", 11) == 6',\n",
              "     'assert find_length(\"10111\", 5) == 1',\n",
              "     'assert find_length(\"11011101100101\", 14) == 2 '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.655612424859427,\n",
              "     'tokenization_energy': 0.11161242485046387,\n",
              "     'inference_energy': 26.544000000008964,\n",
              "     'energy_per_token': 0.8329878882768571,\n",
              "     'time': 0.6072957515716553,\n",
              "     'components': {'embeddings': np.float64(0.11658691120147704),\n",
              "      'attention': np.float64(30.185471927174948),\n",
              "      'ffn': np.float64(3.887019113540649),\n",
              "      'layernorm': np.float64(0.12865001606941223),\n",
              "      'output_layer': np.float64(0.22415197467803957)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a python function to find the sum of common divisors of two given numbers.',\n",
              "    'ground_truth_code': 'def sum(a,b): \\r\\n    sum = 0\\r\\n    for i in range (1,min(a,b)): \\r\\n        if (a % i == 0 and b % i == 0): \\r\\n            sum += i \\r\\n    return sum',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all divisors of two integers integers, \\n',\n",
              "    'test_cases': ['assert sum(10,15) == 6',\n",
              "     'assert sum(100,150) == 93',\n",
              "     'assert sum(4,6) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.674495361083537,\n",
              "     'tokenization_energy': 0.11549536108970643,\n",
              "     'inference_energy': 26.55899999999383,\n",
              "     'energy_per_token': 1.4819164089490853,\n",
              "     'time': 0.610919713973999,\n",
              "     'components': {'embeddings': np.float64(0.11677109074592591),\n",
              "      'attention': np.float64(9.205721069567256),\n",
              "      'ffn': np.float64(25.205673375607464),\n",
              "      'layernorm': np.float64(0.12415797472000122),\n",
              "      'output_layer': np.float64(0.21486897468566893)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to multiply two integers without using the * operator in python.',\n",
              "    'ground_truth_code': 'def multiply_int(x, y):\\r\\n    if y < 0:\\r\\n        return -multiply_int(x, -y)\\r\\n    elif y == 0:\\r\\n        return 0\\r\\n    elif y == 1:\\r\\n        return x\\r\\n    else:\\r\\n        return x + multiply_int(x, y - 1)',\n",
              "    'generated_code': ')\\n\\n the function that compute two matrices without using multiplication multiplication operator.\\n Python.\\n\\n So',\n",
              "    'test_cases': ['assert multiply_int(10,20)==200',\n",
              "     'assert multiply_int(5,10)==50',\n",
              "     'assert multiply_int(4,8)==32'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.139434926992397,\n",
              "     'tokenization_energy': 0.11143492698669433,\n",
              "     'inference_energy': 22.028000000005704,\n",
              "     'energy_per_token': 1.3837146829370248,\n",
              "     'time': 0.6069798469543457,\n",
              "     'components': {'embeddings': np.float64(0.1177368574142456),\n",
              "      'attention': np.float64(13.231030173541047),\n",
              "      'ffn': np.float64(4.017983299732208),\n",
              "      'layernorm': np.float64(0.127347993850708),\n",
              "      'output_layer': np.float64(0.20498919010162353)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to shortlist words that are longer than n from a given list of words.',\n",
              "    'ground_truth_code': 'def long_words(n, str):\\r\\n    word_len = []\\r\\n    txt = str.split(\" \")\\r\\n    for x in txt:\\r\\n        if len(x) > n:\\r\\n            word_len.append(x)\\r\\n    return word_len\\t',\n",
              "    'generated_code': ')\\n\\n the function that compute-term candidates that are not than a, a given string of words.\\n The',\n",
              "    'test_cases': ['assert long_words(3,\"python is a programming language\")==[\\'python\\',\\'programming\\',\\'language\\']',\n",
              "     'assert long_words(2,\"writing a program\")==[\\'writing\\',\\'program\\']',\n",
              "     'assert long_words(5,\"sorting list\")==[\\'sorting\\']'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 30.83299999999872,\n",
              "     'tokenization_energy': 4.572000000000116,\n",
              "     'inference_energy': 26.260999999998603,\n",
              "     'energy_per_token': 1.541649999999936,\n",
              "     'time': 0.6385924816131592,\n",
              "     'components': {'embeddings': np.float64(0.13313156843185425),\n",
              "      'attention': np.float64(13.77909235525725),\n",
              "      'ffn': np.float64(8.165214025964726),\n",
              "      'layernorm': np.float64(0.12551297593116761),\n",
              "      'output_layer': np.float64(0.2189026608467102)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to calculate magic square.',\n",
              "    'ground_truth_code': 'def magic_square_test(my_matrix):\\r\\n    iSize = len(my_matrix[0])\\r\\n    sum_list = []\\r\\n    sum_list.extend([sum (lines) for lines in my_matrix])   \\r\\n    for col in range(iSize):\\r\\n        sum_list.append(sum(row[col] for row in my_matrix))\\r\\n    result1 = 0\\r\\n    for i in range(0,iSize):\\r\\n        result1 +=my_matrix[i][i]\\r\\n    sum_list.append(result1)      \\r\\n    result2 = 0\\r\\n    for i in range(iSize-1,-1,-1):\\r\\n        result2 +=my_matrix[i][i]\\r\\n    sum_list.append(result2)\\r\\n    if len(set(sum_list))>1:\\r\\n        return False\\r\\n    return True',\n",
              "    'generated_code': ')\\n\\n the function that compute the squares in The',\n",
              "    'test_cases': ['assert magic_square_test([[7, 12, 1, 14], [2, 13, 8, 11], [16, 3, 10, 5], [9, 6, 15, 4]])==True',\n",
              "     'assert magic_square_test([[2, 7, 6], [9, 5, 1], [4, 3, 8]])==True',\n",
              "     'assert magic_square_test([[2, 7, 6], [9, 5, 1], [4, 3, 7]])==False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.581279621120775,\n",
              "     'tokenization_energy': 0.11627962112426758,\n",
              "     'inference_energy': 26.464999999996508,\n",
              "     'energy_per_token': 2.953475513457864,\n",
              "     'time': 0.5958766937255859,\n",
              "     'components': {'embeddings': np.float64(0.11685474514961243),\n",
              "      'attention': np.float64(17.435608732690685),\n",
              "      'ffn': np.float64(8.14264707899245),\n",
              "      'layernorm': np.float64(0.13079259872436524),\n",
              "      'output_layer': np.float64(0.2957984256744385)},\n",
              "     'num_tokens': 9}},\n",
              "   {'prompt': 'Write a function to find the item with maximum frequency in a given list.',\n",
              "    'ground_truth_code': 'from collections import defaultdict\\r\\ndef max_occurrences(nums):\\r\\n    dict = defaultdict(int)\\r\\n    for i in nums:\\r\\n        dict[i] += 1\\r\\n    result = max(dict.items(), key=lambda x: x[1]) \\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum in the frequency in a given array of If',\n",
              "    'test_cases': ['assert max_occurrences([2,3,8,4,7,9,8,2,6,5,1,6,1,2,3,2,4,6,9,1,2])==(2, 5)',\n",
              "     'assert max_occurrences([2,3,8,4,7,9,8,7,9,15,14,10,12,13,16,16,18])==(8, 2)',\n",
              "     'assert max_occurrences([10,20,20,30,40,90,80,50,30,20,50,10])==(20, 3)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.80198689079238,\n",
              "     'tokenization_energy': 0.2149868907928467,\n",
              "     'inference_energy': 26.586999999999534,\n",
              "     'energy_per_token': 1.6751241806745238,\n",
              "     'time': 0.6003961563110352,\n",
              "     'components': {'embeddings': np.float64(0.12181231498718262),\n",
              "      'attention': np.float64(17.879318060870517),\n",
              "      'ffn': np.float64(3.9547920506000516),\n",
              "      'layernorm': np.float64(0.12392029571533203),\n",
              "      'output_layer': np.float64(0.25792273998260495)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to reverse only the vowels of a given string.',\n",
              "    'ground_truth_code': 'def reverse_vowels(str1):\\r\\n\\tvowels = \"\"\\r\\n\\tfor char in str1:\\r\\n\\t\\tif char in \"aeiouAEIOU\":\\r\\n\\t\\t\\tvowels += char\\r\\n\\tresult_string = \"\"\\r\\n\\tfor char in str1:\\r\\n\\t\\tif char in \"aeiouAEIOU\":\\r\\n\\t\\t\\tresult_string += vowels[-1]\\r\\n\\t\\t\\tvowels = vowels[:-1]\\r\\n\\t\\telse:\\r\\n\\t\\t\\tresult_string += char\\r\\n\\treturn result_string',\n",
              "    'generated_code': ')\\n\\n the function function that compute a the even in a string string, Return',\n",
              "    'test_cases': ['assert reverse_vowels(\"Python\") == \"Python\"',\n",
              "     'assert reverse_vowels(\"USA\") == \"ASU\"',\n",
              "     'assert reverse_vowels(\"ab\") == \"ab\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.860856690882358,\n",
              "     'tokenization_energy': 0.15285669088363646,\n",
              "     'inference_energy': 26.70799999999872,\n",
              "     'energy_per_token': 1.790723779392157,\n",
              "     'time': 0.5926973819732666,\n",
              "     'components': {'embeddings': np.float64(0.11720235681533812),\n",
              "      'attention': np.float64(9.338410679582854),\n",
              "      'ffn': np.float64(12.740711755753262),\n",
              "      'layernorm': np.float64(0.11910400390625),\n",
              "      'output_layer': np.float64(0.20099858045578003)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to convert tuple to a string.',\n",
              "    'ground_truth_code': \"def tup_string(tup1):\\r\\n  str =  ''.join(tup1)\\r\\n  return str\",\n",
              "    'generated_code': ')\\n\\n the function that compute a of list string in The',\n",
              "    'test_cases': ['assert tup_string((\\'e\\', \\'x\\', \\'e\\', \\'r\\', \\'c\\', \\'i\\', \\'s\\', \\'e\\', \\'s\\'))==(\"exercises\")',\n",
              "     'assert tup_string((\\'p\\',\\'y\\',\\'t\\',\\'h\\',\\'o\\',\\'n\\'))==(\"python\")',\n",
              "     'assert tup_string((\\'p\\',\\'r\\',\\'o\\',\\'g\\',\\'r\\',\\'a\\',\\'m\\'))==(\"program\")'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.386637316228008,\n",
              "     'tokenization_energy': 0.11363731622695923,\n",
              "     'inference_energy': 22.273000000001048,\n",
              "     'energy_per_token': 2.0351488469298187,\n",
              "     'time': 0.559786319732666,\n",
              "     'components': {'embeddings': np.float64(0.11474757194519043),\n",
              "      'attention': np.float64(12.817545919169673),\n",
              "      'ffn': np.float64(12.85710342336458),\n",
              "      'layernorm': np.float64(0.11639226341247558),\n",
              "      'output_layer': np.float64(0.19812208938598633)},\n",
              "     'num_tokens': 11}},\n",
              "   {'prompt': 'Write a function to calculate the sum of the negative numbers of a given list of numbers using lambda function.',\n",
              "    'ground_truth_code': 'def sum_negativenum(nums):\\r\\n  sum_negativenum = list(filter(lambda nums:nums<0,nums))\\r\\n  return sum(sum_negativenum)',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability of all digits numbers in an given array.\\n integers.\\n the functions and Do',\n",
              "    'test_cases': ['assert sum_negativenum([2, 4, -6, -9, 11, -12, 14, -5, 17])==-32',\n",
              "     'assert sum_negativenum([10,15,-14,13,-18,12,-20])==-52',\n",
              "     'assert sum_negativenum([19, -65, 57, 39, 152,-639, 121, 44, 90, -190])==-894'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.374638134012,\n",
              "     'tokenization_energy': 0.11463813400268553,\n",
              "     'inference_energy': 22.260000000009313,\n",
              "     'energy_per_token': 1.0170290060914544,\n",
              "     'time': 0.5591344833374023,\n",
              "     'components': {'embeddings': np.float64(0.11506095123291014),\n",
              "      'attention': np.float64(12.846711552151362),\n",
              "      'ffn': np.float64(17.18270719027624),\n",
              "      'layernorm': np.float64(0.12057798433303832),\n",
              "      'output_layer': np.float64(0.2169513530731201)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a python function to check whether the last element of given array is even or odd after performing an operation p times.',\n",
              "    'ground_truth_code': 'def check_last (arr,n,p): \\r\\n    _sum = 0\\r\\n    for i in range(n): \\r\\n        _sum = _sum + arr[i] \\r\\n    if p == 1: \\r\\n        if _sum % 2 == 0: \\r\\n            return \"ODD\"\\r\\n        else: \\r\\n            return \"EVEN\"\\r\\n    return \"EVEN\"\\r\\n      ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given digit of a\\n is even or not.\\n performing the operation on times.\\n\\n The',\n",
              "    'test_cases': ['assert check_last([5,7,10],3,1) == \"ODD\"',\n",
              "     'assert check_last([2,3],2,3) == \"EVEN\"',\n",
              "     'assert check_last([1,2,3],3,1) == \"ODD\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.942438212623355,\n",
              "     'tokenization_energy': 0.11543821263313293,\n",
              "     'inference_energy': 26.82699999999022,\n",
              "     'energy_per_token': 1.0776975285049342,\n",
              "     'time': 0.5654072761535645,\n",
              "     'components': {'embeddings': np.float64(0.11547000503540039),\n",
              "      'attention': np.float64(8.625709975472883),\n",
              "      'ffn': np.float64(12.971078700769928),\n",
              "      'layernorm': np.float64(0.13123936915397644),\n",
              "      'output_layer': np.float64(4.4210000000020955)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a function to find the nth hexagonal number.',\n",
              "    'ground_truth_code': 'def hexagonal_num(n): \\r\\n\\treturn n*(2*n - 1) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum rootagonal number.\\n The',\n",
              "    'test_cases': ['assert hexagonal_num(10) == 190',\n",
              "     'assert hexagonal_num(5) == 45',\n",
              "     'assert hexagonal_num(7) == 91'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.71456583548605,\n",
              "     'tokenization_energy': 0.20056583547592163,\n",
              "     'inference_energy': 22.514000000010128,\n",
              "     'energy_per_token': 1.892880486290504,\n",
              "     'time': 0.5589861869812012,\n",
              "     'components': {'embeddings': np.float64(0.11518126177787781),\n",
              "      'attention': np.float64(12.995388258231921),\n",
              "      'ffn': np.float64(12.631439106223873),\n",
              "      'layernorm': np.float64(0.1181147928237915),\n",
              "      'output_layer': np.float64(0.2588232536315918)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to calculate electricity bill.',\n",
              "    'ground_truth_code': 'def cal_electbill(units):\\r\\n if(units < 50):\\r\\n    amount = units * 2.60\\r\\n    surcharge = 25\\r\\n elif(units <= 100):\\r\\n    amount = 130 + ((units - 50) * 3.25)\\r\\n    surcharge = 35\\r\\n elif(units <= 200):\\r\\n    amount = 130 + 162.50 + ((units - 100) * 5.26)\\r\\n    surcharge = 45\\r\\n else:\\r\\n    amount = 130 + 162.50 + 526 + ((units - 200) * 8.45)\\r\\n    surcharge = 75\\r\\n total = amount + surcharge\\r\\n return total',\n",
              "    'generated_code': ')\\n\\n the function that compute the usage based The',\n",
              "    'test_cases': ['assert cal_electbill(75)==246.25',\n",
              "     'assert cal_electbill(265)==1442.75',\n",
              "     'assert cal_electbill(100)==327.5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.862401614185305,\n",
              "     'tokenization_energy': 0.11340161418914795,\n",
              "     'inference_energy': 26.74899999999616,\n",
              "     'energy_per_token': 2.984711290465034,\n",
              "     'time': 0.5603828430175781,\n",
              "     'components': {'embeddings': np.float64(0.13262419700622557),\n",
              "      'attention': np.float64(8.56156492828764),\n",
              "      'ffn': np.float64(8.16342532419844),\n",
              "      'layernorm': np.float64(0.11770136642456056),\n",
              "      'output_layer': np.float64(0.2565459327697754)},\n",
              "     'num_tokens': 9}},\n",
              "   {'prompt': 'Write a function to find the ration of zeroes in an array of integers.',\n",
              "    'ground_truth_code': 'from array import array\\r\\ndef zero_count(nums):\\r\\n    n = len(nums)\\r\\n    n1 = 0\\r\\n    for x in nums:\\r\\n        if x == 0:\\r\\n            n1 += 1\\r\\n        else:\\r\\n          None\\r\\n    return round(n1/n,2)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximumals the in a array of integers, The',\n",
              "    'test_cases': ['assert zero_count([0, 1, 2, -1, -5, 6, 0, -3, -2, 3, 4, 6, 8])==0.15',\n",
              "     'assert zero_count([2, 1, 2, -1, -5, 6, 4, -3, -2, 3, 4, 6, 8])==0.00',\n",
              "     'assert zero_count([2, 4, -6, -9, 11, -12, 14, -5, 17])==0.00'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.60370767306618,\n",
              "     'tokenization_energy': 0.20770767307281496,\n",
              "     'inference_energy': 22.395999999993364,\n",
              "     'energy_per_token': 1.4127317295666362,\n",
              "     'time': 0.5637035369873047,\n",
              "     'components': {'embeddings': np.float64(0.11374492931365968),\n",
              "      'attention': np.float64(13.222622189519113),\n",
              "      'ffn': np.float64(12.796064481255481),\n",
              "      'layernorm': np.float64(0.11996333122253418),\n",
              "      'output_layer': np.float64(0.2012565038204193)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to check whether the given number can be represented as sum of non-zero powers of 2 or not.',\n",
              "    'ground_truth_code': 'def is_Sum_Of_Powers_Of_Two(n): \\r\\n    if (n % 2 == 1): \\r\\n        return False\\r\\n    else: \\r\\n        return True',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n is be represented as the of two-con consecutive of 6, . So',\n",
              "    'test_cases': ['assert is_Sum_Of_Powers_Of_Two(10) == True',\n",
              "     'assert is_Sum_Of_Powers_Of_Two(7) == False',\n",
              "     'assert is_Sum_Of_Powers_Of_Two(14) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.53301974869217,\n",
              "     'tokenization_energy': 0.17201974868774414,\n",
              "     'inference_energy': 22.361000000004424,\n",
              "     'energy_per_token': 0.8666546057189296,\n",
              "     'time': 0.5593576431274414,\n",
              "     'components': {'embeddings': np.float64(0.11974476623535156),\n",
              "      'attention': np.float64(17.587684117316034),\n",
              "      'ffn': np.float64(12.682284202104436),\n",
              "      'layernorm': np.float64(0.12393983316421509),\n",
              "      'output_layer': np.float64(0.2267288146018982)},\n",
              "     'num_tokens': 26}},\n",
              "   {'prompt': 'Write a function to find the circumference of a circle.',\n",
              "    'ground_truth_code': 'def circle_circumference(r):\\r\\n  perimeter=2*3.1415*r\\r\\n  return perimeter',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a circle given The',\n",
              "    'test_cases': ['assert circle_circumference(10)==62.830000000000005',\n",
              "     'assert circle_circumference(5)==31.415000000000003',\n",
              "     'assert circle_circumference(4)==25.132'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.022475504389497,\n",
              "     'tokenization_energy': 0.11947550439834595,\n",
              "     'inference_energy': 26.902999999991152,\n",
              "     'energy_per_token': 2.2518729586991246,\n",
              "     'time': 0.5607776641845703,\n",
              "     'components': {'embeddings': np.float64(0.13154451084136962),\n",
              "      'attention': np.float64(13.22161016034009),\n",
              "      'ffn': np.float64(12.746101924897403),\n",
              "      'layernorm': np.float64(0.15816688776016236),\n",
              "      'output_layer': np.float64(0.21985027718544004)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to extract elements that occur singly in the given tuple list.',\n",
              "    'ground_truth_code': 'def extract_singly(test_list):\\r\\n  res = []\\r\\n  temp = set()\\r\\n  for inner in test_list:\\r\\n    for ele in inner:\\r\\n      if not ele in temp:\\r\\n        temp.add(ele)\\r\\n        res.append(ele)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the from are in in a entire matrix..\\n The',\n",
              "    'test_cases': ['assert extract_singly([(3, 4, 5), (4, 5, 7), (1, 4)]) == [3, 4, 5, 7, 1]',\n",
              "     'assert extract_singly([(1, 2, 3), (4, 2, 3), (7, 8)]) == [1, 2, 3, 4, 7, 8]',\n",
              "     'assert extract_singly([(7, 8, 9), (10, 11, 12), (10, 11)]) == [7, 8, 9, 10, 11, 12]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.41124011278746,\n",
              "     'tokenization_energy': 0.11424011278152466,\n",
              "     'inference_energy': 22.297000000005937,\n",
              "     'energy_per_token': 1.4007025070492163,\n",
              "     'time': 0.5502760410308838,\n",
              "     'components': {'embeddings': np.float64(0.1125640914440155),\n",
              "      'attention': np.float64(4.233986377239227),\n",
              "      'ffn': np.float64(4.080499613761901),\n",
              "      'layernorm': np.float64(0.11898669433593749),\n",
              "      'output_layer': np.float64(0.1990149097442627)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to sort a list of elements using pancake sort.',\n",
              "    'ground_truth_code': 'def pancake_sort(nums):\\r\\n    arr_len = len(nums)\\r\\n    while arr_len > 1:\\r\\n        mi = nums.index(max(nums[0:arr_len]))\\r\\n        nums = nums[mi::-1] + nums[mi+1:len(nums)]\\r\\n        nums = nums[arr_len-1::-1] + nums[arr_len:len(nums)]\\r\\n        arr_len -= 1\\r\\n    return nums',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix of integers in aake sort.\\n The',\n",
              "    'test_cases': ['assert pancake_sort([15, 79, 25, 38, 69]) == [15, 25, 38, 69, 79]',\n",
              "     'assert pancake_sort([98, 12, 54, 36, 85]) == [12, 36, 54, 85, 98]',\n",
              "     'assert pancake_sort([41, 42, 32, 12, 23]) == [12, 23, 32, 41, 42]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.916209621429328,\n",
              "     'tokenization_energy': 0.11320962142944335,\n",
              "     'inference_energy': 26.802999999999884,\n",
              "     'energy_per_token': 1.7944139747619552,\n",
              "     'time': 0.5605649948120117,\n",
              "     'components': {'embeddings': np.float64(0.11407093048095703),\n",
              "      'attention': np.float64(8.698055111885653),\n",
              "      'ffn': np.float64(8.343988252875512),\n",
              "      'layernorm': np.float64(0.1338368148803711),\n",
              "      'output_layer': np.float64(0.1991613006591797)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to count the same pair in three given lists.',\n",
              "    'ground_truth_code': 'def count_samepair(list1,list2,list3):\\r\\n    result = sum(m == n == o for m, n, o in zip(list1,list2,list3))\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the number number of a-dimensional arrays.\\n The',\n",
              "    'test_cases': ['assert count_samepair([1,2,3,4,5,6,7,8],[2,2,3,1,2,6,7,9],[2,1,3,1,2,6,7,9])==3',\n",
              "     'assert count_samepair([1,2,3,4,5,6,7,8],[2,2,3,1,2,6,7,8],[2,1,3,1,2,6,7,8])==4',\n",
              "     'assert count_samepair([1,2,3,4,2,6,7,8],[2,2,3,1,2,6,7,8],[2,1,3,1,2,6,7,8])==5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.58963661956298,\n",
              "     'tokenization_energy': 0.11363661956787109,\n",
              "     'inference_energy': 22.47599999999511,\n",
              "     'energy_per_token': 1.6135454728259273,\n",
              "     'time': 0.5544130802154541,\n",
              "     'components': {'embeddings': np.float64(0.1143099594116211),\n",
              "      'attention': np.float64(12.952814009907657),\n",
              "      'ffn': np.float64(17.137899823181098),\n",
              "      'layernorm': np.float64(0.12708076000213622),\n",
              "      'output_layer': np.float64(0.21129910349845887)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find number of lists present in the given tuple.',\n",
              "    'ground_truth_code': 'def find_lists(Input): \\r\\n\\tif isinstance(Input, list): \\r\\n\\t\\treturn 1\\r\\n\\telse: \\r\\n\\t\\treturn len(Input) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the of unique that in a function matrix.\\n The',\n",
              "    'test_cases': ['assert find_lists(([1, 2, 3, 4], [5, 6, 7, 8])) == 2',\n",
              "     'assert find_lists(([1, 2], [3, 4], [5, 6]))  == 3',\n",
              "     'assert find_lists(([9, 8, 7, 6, 5, 4, 3, 2, 1])) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.288280492061748,\n",
              "     'tokenization_energy': 0.11928049206733704,\n",
              "     'inference_energy': 27.168999999994412,\n",
              "     'energy_per_token': 1.8192186994707833,\n",
              "     'time': 0.5585198402404785,\n",
              "     'components': {'embeddings': np.float64(4.56600000000617),\n",
              "      'attention': np.float64(8.777032579659602),\n",
              "      'ffn': np.float64(8.438627470961888),\n",
              "      'layernorm': np.float64(0.17704151868820192),\n",
              "      'output_layer': np.float64(0.20036711931228637)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the sum of absolute differences in all pairs of the given array.',\n",
              "    'ground_truth_code': 'def sum_Pairs(arr,n): \\r\\n    sum = 0\\r\\n    for i in range(n - 1,-1,-1): \\r\\n        sum += i*arr[i] - (n-1-i) * arr[i] \\r\\n    return sum',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all differences between a possible of a function array.\\n So',\n",
              "    'test_cases': ['assert sum_Pairs([1,8,9,15,16],5) == 74',\n",
              "     'assert sum_Pairs([1,2,3,4],4) == 10',\n",
              "     'assert sum_Pairs([1,2,3,4,5,7,9,11,14],9) == 188'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.1401638050098,\n",
              "     'tokenization_energy': 0.11316380500793458,\n",
              "     'inference_energy': 27.027000000001863,\n",
              "     'energy_per_token': 1.35700819025049,\n",
              "     'time': 0.5607011318206787,\n",
              "     'components': {'embeddings': np.float64(0.11417157173156739),\n",
              "      'attention': np.float64(12.994986680261325),\n",
              "      'ffn': np.float64(17.15114176512754),\n",
              "      'layernorm': np.float64(0.1261542477607727),\n",
              "      'output_layer': np.float64(0.24361003375053406)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to find the maximum difference between any two elements in a given array.',\n",
              "    'ground_truth_code': 'def max_Abs_Diff(arr,n): \\r\\n    minEle = arr[0] \\r\\n    maxEle = arr[0] \\r\\n    for i in range(1, n): \\r\\n        minEle = min(minEle,arr[i]) \\r\\n        maxEle = max(maxEle,arr[i]) \\r\\n    return (maxEle - minEle) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number between two two elements in a given array, The',\n",
              "    'test_cases': ['assert max_Abs_Diff((2,1,5,3),4) == 4',\n",
              "     'assert max_Abs_Diff((9,3,2,5,1),5) == 8',\n",
              "     'assert max_Abs_Diff((3,2,1),3) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.41663146878185,\n",
              "     'tokenization_energy': 0.12263146877288819,\n",
              "     'inference_energy': 22.294000000008964,\n",
              "     'energy_per_token': 1.1798227088832554,\n",
              "     'time': 0.5621461868286133,\n",
              "     'components': {'embeddings': np.float64(0.20759674453735352),\n",
              "      'attention': np.float64(13.05353099990671),\n",
              "      'ffn': np.float64(12.745177497625585),\n",
              "      'layernorm': np.float64(0.12547935557365417),\n",
              "      'output_layer': np.float64(0.2404471173286438)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the ascii value of total characters in a string.',\n",
              "    'ground_truth_code': 'def ascii_value_string(str1):\\r\\n  for i in range(len(str1)):\\r\\n   return ord(str1[i])',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum sum of a characters in a string.\\n Return',\n",
              "    'test_cases': ['assert ascii_value_string(\"python\")==112',\n",
              "     'assert ascii_value_string(\"Program\")==80',\n",
              "     'assert ascii_value_string(\"Language\")==76'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.19033538412291,\n",
              "     'tokenization_energy': 0.1203353841304779,\n",
              "     'inference_energy': 27.069999999992433,\n",
              "     'energy_per_token': 1.699395961507682,\n",
              "     'time': 0.5614469051361084,\n",
              "     'components': {'embeddings': np.float64(0.12248243308067322),\n",
              "      'attention': np.float64(13.294595766539919),\n",
              "      'ffn': np.float64(12.816398714537149),\n",
              "      'layernorm': np.float64(0.1275967297554016),\n",
              "      'output_layer': np.float64(0.21311105489730833)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find the maximum total path sum in the given triangle.',\n",
              "    'ground_truth_code': 'def max_path_sum(tri, m, n): \\r\\n\\tfor i in range(m-1, -1, -1): \\r\\n\\t\\tfor j in range(i+1): \\r\\n\\t\\t\\tif (tri[i+1][j] > tri[i+1][j+1]): \\r\\n\\t\\t\\t\\ttri[i][j] += tri[i+1][j] \\r\\n\\t\\t\\telse: \\r\\n\\t\\t\\t\\ttri[i][j] += tri[i+1][j+1] \\r\\n\\treturn tri[0][0]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of in in a maximum und, The',\n",
              "    'test_cases': ['assert max_path_sum([[1, 0, 0], [4, 8, 0], [1, 5, 3]], 2, 2) == 14',\n",
              "     'assert max_path_sum([[13, 0, 0], [7, 4, 0], [2, 4, 6]], 2, 2) == 24 ',\n",
              "     'assert max_path_sum([[2, 0, 0], [11, 18, 0], [21, 25, 33]], 2, 2) == 53'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.41120813011867,\n",
              "     'tokenization_energy': 0.12020813012123108,\n",
              "     'inference_energy': 22.29099999999744,\n",
              "     'energy_per_token': 1.4007005081324169,\n",
              "     'time': 0.5635292530059814,\n",
              "     'components': {'embeddings': np.float64(0.1210515775680542),\n",
              "      'attention': np.float64(17.290873880854804),\n",
              "      'ffn': np.float64(12.644536657100776),\n",
              "      'layernorm': np.float64(0.11971728801727295),\n",
              "      'output_layer': np.float64(0.26910483837127686)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to divide a number into two parts such that the sum of digits is maximum.',\n",
              "    'ground_truth_code': 'def sum_digits_single(x) : \\r\\n    ans = 0\\r\\n    while x : \\r\\n        ans += x % 10\\r\\n        x //= 10  \\r\\n    return ans \\r\\ndef closest(x) : \\r\\n    ans = 0\\r\\n    while (ans * 10 + 9 <= x) : \\r\\n        ans = ans * 10 + 9  \\r\\n    return ans   \\r\\ndef sum_digits_twoparts(N) : \\r\\n    A = closest(N)  \\r\\n    return sum_digits_single(A) + sum_digits_single(N - A) ',\n",
              "    'generated_code': ')\\n\\n the function that compute a given by two parts, that the sum of the of equal. How',\n",
              "    'test_cases': ['assert sum_digits_twoparts(35)==17',\n",
              "     'assert sum_digits_twoparts(7)==7',\n",
              "     'assert sum_digits_twoparts(100)==19'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 26.7560000000085,\n",
              "     'tokenization_energy': 4.470000000001164,\n",
              "     'inference_energy': 22.286000000007334,\n",
              "     'energy_per_token': 1.3378000000004249,\n",
              "     'time': 0.5675537586212158,\n",
              "     'components': {'embeddings': np.float64(0.11473722338676452),\n",
              "      'attention': np.float64(8.873743434429285),\n",
              "      'ffn': np.float64(8.464705424300394),\n",
              "      'layernorm': np.float64(0.11867663264274597),\n",
              "      'output_layer': np.float64(0.21802364206314087)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find the longest subsequence such that the difference between adjacents is one for the given array.',\n",
              "    'ground_truth_code': 'def longest_subseq_with_diff_one(arr, n): \\r\\n\\tdp = [1 for i in range(n)] \\r\\n\\tfor i in range(n): \\r\\n\\t\\tfor j in range(i): \\r\\n\\t\\t\\tif ((arr[i] == arr[j]+1) or (arr[i] == arr[j]-1)): \\r\\n\\t\\t\\t\\tdp[i] = max(dp[i], dp[j]+1) \\r\\n\\tresult = 1\\r\\n\\tfor i in range(n): \\r\\n\\t\\tif (result < dp[i]): \\r\\n\\t\\t\\tresult = dp[i] \\r\\n\\treturn result',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum substringsequence in that the sum between theacents is .\\n the longest array of The',\n",
              "    'test_cases': ['assert longest_subseq_with_diff_one([1, 2, 3, 4, 5, 3, 2], 7) == 6',\n",
              "     'assert longest_subseq_with_diff_one([10, 9, 4, 5, 4, 8, 6], 7) == 3',\n",
              "     'assert longest_subseq_with_diff_one([1, 2, 3, 2, 3, 7, 2, 1], 8) == 7'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.06332426714222,\n",
              "     'tokenization_energy': 0.11432426714897156,\n",
              "     'inference_energy': 26.948999999993248,\n",
              "     'energy_per_token': 1.0825329706856888,\n",
              "     'time': 0.5644686222076416,\n",
              "     'components': {'embeddings': np.float64(0.1148256425857544),\n",
              "      'attention': np.float64(8.655430738453635),\n",
              "      'ffn': np.float64(12.884577798832671),\n",
              "      'layernorm': np.float64(0.24690284729003906),\n",
              "      'output_layer': np.float64(0.21648088932037354)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a python function to find whether the given number is present in the infinite sequence or not.',\n",
              "    'ground_truth_code': 'def does_Contain_B(a,b,c): \\r\\n    if (a == b): \\r\\n        return True\\r\\n    if ((b - a) * c > 0 and (b - a) % c == 0): \\r\\n        return True\\r\\n    return False',\n",
              "    'generated_code': ')\\n\\n the function function that compute the a given \\n is a in the given sequence of not.\\n\\n The',\n",
              "    'test_cases': ['assert does_Contain_B(1,7,3) == True',\n",
              "     'assert does_Contain_B(1,-3,5) == False',\n",
              "     'assert does_Contain_B(3,2,5) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.586205795286222,\n",
              "     'tokenization_energy': 0.11320579528808594,\n",
              "     'inference_energy': 22.472999999998137,\n",
              "     'energy_per_token': 1.129310289764311,\n",
              "     'time': 0.5613296031951904,\n",
              "     'components': {'embeddings': np.float64(0.17273751497268677),\n",
              "      'attention': np.float64(8.918926769259501),\n",
              "      'ffn': np.float64(12.976204303980454),\n",
              "      'layernorm': np.float64(0.11747415161132811),\n",
              "      'output_layer': np.float64(0.2137201862335205)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to check whether the given number is co-prime or not.',\n",
              "    'ground_truth_code': 'def gcd(p,q):\\r\\n    while q != 0:\\r\\n        p, q = q,p%q\\r\\n    return p\\r\\ndef is_coprime(x,y):\\r\\n    return gcd(x,y) == 1',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n is a-prime with not.\\n Write',\n",
              "    'test_cases': ['assert is_coprime(17,13) == True',\n",
              "     'assert is_coprime(15,21) == False',\n",
              "     'assert is_coprime(25,45) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.658415412907953,\n",
              "     'tokenization_energy': 0.11541541290283203,\n",
              "     'inference_energy': 22.543000000005122,\n",
              "     'energy_per_token': 1.258800856272664,\n",
              "     'time': 0.5598313808441162,\n",
              "     'components': {'embeddings': np.float64(0.12781003832817078),\n",
              "      'attention': np.float64(13.145189777377178),\n",
              "      'ffn': np.float64(17.297983805658646),\n",
              "      'layernorm': np.float64(0.12661213159561158),\n",
              "      'output_layer': np.float64(0.23074933862686156)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to sort the given array by using merge sort.',\n",
              "    'ground_truth_code': 'def merge(a,b):\\r\\n    c = []\\r\\n    while len(a) != 0 and len(b) != 0:\\r\\n        if a[0] < b[0]:\\r\\n            c.append(a[0])\\r\\n            a.remove(a[0])\\r\\n        else:\\r\\n            c.append(b[0])\\r\\n            b.remove(b[0])\\r\\n    if len(a) == 0:\\r\\n        c += b\\r\\n    else:\\r\\n        c += a\\r\\n    return c\\r\\ndef merge_sort(x):\\r\\n    if len(x) == 0 or len(x) == 1:\\r\\n        return x\\r\\n    else:\\r\\n        middle = len(x)//2\\r\\n        a = merge_sort(x[:middle])\\r\\n        b = merge_sort(x[middle:])\\r\\n        return merge(a,b)\\r\\n',\n",
              "    'generated_code': ')\\n\\n the function that compute a sorted matrix in the the sort, The',\n",
              "    'test_cases': ['assert merge_sort([3, 4, 2, 6, 5, 7, 1, 9]) == [1, 2, 3, 4, 5, 6, 7, 9]',\n",
              "     'assert merge_sort([7, 25, 45, 78, 11, 33, 19]) == [7, 11, 19, 25, 33, 45, 78]',\n",
              "     'assert merge_sort([3, 1, 4, 9, 8]) == [1, 3, 4, 8, 9]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.200843696115307,\n",
              "     'tokenization_energy': 0.12184369611740112,\n",
              "     'inference_energy': 27.078999999997905,\n",
              "     'energy_per_token': 1.942917406865379,\n",
              "     'time': 0.5624947547912598,\n",
              "     'components': {'embeddings': np.float64(0.12335784387588501),\n",
              "      'attention': np.float64(12.877552625410372),\n",
              "      'ffn': np.float64(8.708413378715749),\n",
              "      'layernorm': np.float64(0.12028947544097901),\n",
              "      'output_layer': np.float64(4.548000000009779)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find the vertex of a parabola.',\n",
              "    'ground_truth_code': 'def parabola_vertex(a, b, c): \\r\\n  vertex=(((-b / (2 * a)),(((4 * a * c) - (b * b)) / (4 * a))))\\r\\n  return vertex',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a quadraticabola given The',\n",
              "    'test_cases': ['assert parabola_vertex(5,3,2)==(-0.3, 1.55)',\n",
              "     'assert parabola_vertex(9,8,4)==(-0.4444444444444444, 2.2222222222222223)',\n",
              "     'assert parabola_vertex(2,4,6)==(-1.0, 4.0)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.51645554924174,\n",
              "     'tokenization_energy': 0.1334555492401123,\n",
              "     'inference_energy': 22.38300000000163,\n",
              "     'energy_per_token': 1.608318253517267,\n",
              "     'time': 0.559044361114502,\n",
              "     'components': {'embeddings': np.float64(0.1346336088180542),\n",
              "      'attention': np.float64(8.879343850619277),\n",
              "      'ffn': np.float64(4.385527806997299),\n",
              "      'layernorm': np.float64(0.11884938240051271),\n",
              "      'output_layer': np.float64(0.20119585990905764)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to extract every specified element from a given two dimensional list.',\n",
              "    'ground_truth_code': 'def specified_element(nums, N):\\r\\n    result = [i[N] for i in nums]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the\\n\\n from a given matrix-dimensional array.\\n The',\n",
              "    'test_cases': ['assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],0)==[1, 4, 7]',\n",
              "     'assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],2)==[3, 6, 9]',\n",
              "     'assert specified_element([[1, 2, 3, 2], [4, 5, 6, 2], [7, 1, 9, 5]],3)==[2,2,5]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.359871231078287,\n",
              "     'tokenization_energy': 0.11387123107910158,\n",
              "     'inference_energy': 27.245999999999185,\n",
              "     'energy_per_token': 1.709991951942393,\n",
              "     'time': 0.5619621276855469,\n",
              "     'components': {'embeddings': np.float64(0.11835050582885744),\n",
              "      'attention': np.float64(8.961638120171385),\n",
              "      'ffn': np.float64(4.316140597343445),\n",
              "      'layernorm': np.float64(0.11997404861450195),\n",
              "      'output_layer': np.float64(0.28620669555664063)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to toggle all even bits of a given number.',\n",
              "    'ground_truth_code': 'def even_bit_toggle_number(n) : \\r\\n    res = 0; count = 0; temp = n \\r\\n    while (temp > 0) :     \\r\\n        if (count % 2 == 1) : \\r\\n            res = res | (1 << count)      \\r\\n        count = count + 1\\r\\n        temp >>= 1 \\r\\n    return n ^ res ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the the numbers in a number integer.\\n So',\n",
              "    'test_cases': ['assert even_bit_toggle_number(10) == 0',\n",
              "     'assert even_bit_toggle_number(20) == 30',\n",
              "     'assert even_bit_toggle_number(30) == 20'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.291117229450844,\n",
              "     'tokenization_energy': 0.11211722946166991,\n",
              "     'inference_energy': 27.178999999989173,\n",
              "     'energy_per_token': 1.819407815296723,\n",
              "     'time': 0.5695886611938477,\n",
              "     'components': {'embeddings': np.float64(0.11445956993103026),\n",
              "      'attention': np.float64(13.232100548735122),\n",
              "      'ffn': np.float64(8.75912018084654),\n",
              "      'layernorm': np.float64(0.12260176467895507),\n",
              "      'output_layer': np.float64(0.20109188890457153)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to convert a tuple of string values to a tuple of integer values.',\n",
              "    'ground_truth_code': 'def tuple_int_str(tuple_str):\\r\\n    result = tuple((int(x[0]), int(x[1])) for x in tuple_str)\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute a given of integers and into a tuple of integer values.\\n The',\n",
              "    'test_cases': [\"assert tuple_int_str((('333', '33'), ('1416', '55')))==((333, 33), (1416, 55))\",\n",
              "     \"assert tuple_int_str((('999', '99'), ('1000', '500')))==((999, 99), (1000, 500))\",\n",
              "     \"assert tuple_int_str((('666', '66'), ('1500', '555')))==((666, 66), (1500, 555))\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.725490262276608,\n",
              "     'tokenization_energy': 0.12149026226997375,\n",
              "     'inference_energy': 22.604000000006636,\n",
              "     'energy_per_token': 1.2625272367931448,\n",
              "     'time': 0.5627083778381348,\n",
              "     'components': {'embeddings': np.float64(0.12223359751701354),\n",
              "      'attention': np.float64(8.874289670228025),\n",
              "      'ffn': np.float64(12.874547103163437),\n",
              "      'layernorm': np.float64(0.12458827590942383),\n",
              "      'output_layer': np.float64(0.22491023826599119)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to reflect the run-length encoding from a list.',\n",
              "    'ground_truth_code': 'from itertools import groupby\\r\\ndef encode_list(list1):\\r\\n    return [[len(list(group)), key] for key, group in groupby(list1)]',\n",
              "    'generated_code': ')\\n\\n the function that compute a points time encoding of a string of The',\n",
              "    'test_cases': ['assert encode_list([1,1,2,3,4,4.3,5,1])==[[2, 1], [1, 2], [1, 3], [1, 4], [1, 4.3], [1, 5], [1, 1]]',\n",
              "     \"assert encode_list('automatically')==[[1, 'a'], [1, 'u'], [1, 't'], [1, 'o'], [1, 'm'], [1, 'a'], [1, 't'], [1, 'i'], [1, 'c'], [1, 'a'], [2, 'l'], [1, 'y']]\",\n",
              "     \"assert encode_list('python')==[[1, 'p'], [1, 'y'], [1, 't'], [1, 'h'], [1, 'o'], [1, 'n']]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.21915161704528,\n",
              "     'tokenization_energy': 0.1181516170501709,\n",
              "     'inference_energy': 27.10099999999511,\n",
              "     'energy_per_token': 1.9442251155032344,\n",
              "     'time': 0.5698554515838623,\n",
              "     'components': {'embeddings': np.float64(0.1804457550048828),\n",
              "      'attention': np.float64(13.0693793470799),\n",
              "      'ffn': np.float64(17.43472088432696),\n",
              "      'layernorm': np.float64(0.11780290985107422),\n",
              "      'output_layer': np.float64(0.1983091049194336)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find k number of operations required to make all elements equal.',\n",
              "    'ground_truth_code': 'def min_Ops(arr,n,k): \\r\\n    max1 = max(arr) \\r\\n    res = 0\\r\\n    for i in range(0,n):  \\r\\n        if ((max1 - arr[i]) % k != 0): \\r\\n            return -1 \\r\\n        else: \\r\\n            res += (max1 - arr[i]) / k \\r\\n    return int(res) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the such of k to to reach the the in to The',\n",
              "    'test_cases': ['assert min_Ops([2,2,2,2],4,3) == 0',\n",
              "     'assert min_Ops([4,2,6,8],4,3) == -1',\n",
              "     'assert min_Ops([21,33,9,45,63],5,6) == 24'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.19952374268661,\n",
              "     'tokenization_energy': 0.12852374267578126,\n",
              "     'inference_energy': 27.071000000010827,\n",
              "     'energy_per_token': 1.5110846523714783,\n",
              "     'time': 0.5686547756195068,\n",
              "     'components': {'embeddings': np.float64(0.11366818237304688),\n",
              "      'attention': np.float64(13.001672107236109),\n",
              "      'ffn': np.float64(12.945634297853335),\n",
              "      'layernorm': np.float64(0.12173964142799377),\n",
              "      'output_layer': np.float64(0.2203708462715149)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to print the season for the given month and day.',\n",
              "    'ground_truth_code': \"def month_season(month,days):\\r\\n if month in ('January', 'February', 'March'):\\r\\n\\t season = 'winter'\\r\\n elif month in ('April', 'May', 'June'):\\r\\n\\t season = 'spring'\\r\\n elif month in ('July', 'August', 'September'):\\r\\n\\t season = 'summer'\\r\\n else:\\r\\n\\t season = 'autumn'\\r\\n if (month == 'March') and (days > 19):\\r\\n\\t season = 'spring'\\r\\n elif (month == 'June') and (days > 20):\\r\\n\\t season = 'summer'\\r\\n elif (month == 'September') and (days > 21):\\r\\n\\t season = 'autumn'\\r\\n elif (month == 'October') and (days > 21):\\r\\n\\t season = 'autumn'\\r\\n elif (month == 'November') and (days > 21):\\r\\n\\t season = 'autumn'\\r\\n elif (month == 'December') and (days > 20):\\r\\n\\t season = 'winter'\\r\\n return season\",\n",
              "    'generated_code': ')\\n\\n the function that compute the number(s a given year and year.\\n\\n The',\n",
              "    'test_cases': [\"assert month_season('January',4)==('winter')\",\n",
              "     \"assert month_season('October',28)==('autumn')\",\n",
              "     \"assert month_season('June',6)==('spring')\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.657393060679198,\n",
              "     'tokenization_energy': 0.12839306068420409,\n",
              "     'inference_energy': 22.528999999994994,\n",
              "     'energy_per_token': 1.5104928707119465,\n",
              "     'time': 0.5686461925506592,\n",
              "     'components': {'embeddings': np.float64(0.22111415672302245),\n",
              "      'attention': np.float64(17.50843432736432),\n",
              "      'ffn': np.float64(12.825261006349931),\n",
              "      'layernorm': np.float64(0.11927666854858399),\n",
              "      'output_layer': np.float64(0.2736710834503174)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find x and y that satisfies ax + by = n.',\n",
              "    'ground_truth_code': 'def solution (a, b, n): \\r\\n\\ti = 0\\r\\n\\twhile i * a <= n: \\r\\n\\t\\tif (n - (i * a)) % b == 0: \\r\\n\\t\\t\\treturn (\"x = \",i ,\", y = \", \\r\\n\\t\\t\\tint((n - (i * a)) / b)) \\r\\n\\t\\t\\treturn 0\\r\\n\\t\\ti = i + 1\\r\\n\\treturn (\"No solution\") ',\n",
              "    'generated_code': ')\\n\\n the function that compute the such y such satisfy the + by = c, The',\n",
              "    'test_cases': [\"assert solution(2, 3, 7) == ('x = ', 2, ', y = ', 1)\",\n",
              "     \"assert solution(4, 2, 7) == 'No solution'\",\n",
              "     \"assert solution(1, 13, 17) == ('x = ', 4, ', y = ', 1)\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.25775635146734,\n",
              "     'tokenization_energy': 0.11475635147094727,\n",
              "     'inference_energy': 27.14299999999639,\n",
              "     'energy_per_token': 1.6033974324392553,\n",
              "     'time': 0.5721001625061035,\n",
              "     'components': {'embeddings': np.float64(0.11543866348266602),\n",
              "      'attention': np.float64(13.153833649635313),\n",
              "      'ffn': np.float64(13.235767306568686),\n",
              "      'layernorm': np.float64(0.12247602844238281),\n",
              "      'output_layer': np.float64(0.22116221618652343)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to remove all elements from a given list present in another list.',\n",
              "    'ground_truth_code': 'def remove_elements(list1, list2):\\r\\n    result = [x for x in list1 if x not in list2]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the the from a given matrix that in a list.\\n So',\n",
              "    'test_cases': ['assert remove_elements([1,2,3,4,5,6,7,8,9,10],[2,4,6,8])==[1, 3, 5, 7, 9, 10]',\n",
              "     'assert remove_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],[1, 3, 5, 7])==[2, 4, 6, 8, 9, 10]',\n",
              "     'assert remove_elements([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],[5,7])==[1, 2, 3, 4, 6, 8, 9, 10]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.207887573246378,\n",
              "     'tokenization_energy': 0.1158875732421875,\n",
              "     'inference_energy': 27.09200000000419,\n",
              "     'energy_per_token': 1.6004639748968457,\n",
              "     'time': 0.5639009475708008,\n",
              "     'components': {'embeddings': np.float64(0.17862394714355467),\n",
              "      'attention': np.float64(13.136578323125956),\n",
              "      'ffn': np.float64(17.39426844477642),\n",
              "      'layernorm': np.float64(0.12323650360107422),\n",
              "      'output_layer': np.float64(4.467000000004191)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to calculate the sum of the positive integers of n+(n-2)+(n-4)... (until n-x =< 0).',\n",
              "    'ground_truth_code': 'def sum_series(n):\\r\\n  if n < 1:\\r\\n    return 0\\r\\n  else:\\r\\n    return n + sum_series(n - 2)',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability of all digits integers in a,n-1)+n-4)+ untiln the is is 00). So',\n",
              "    'test_cases': ['assert sum_series(6)==12',\n",
              "     'assert sum_series(10)==30',\n",
              "     'assert sum_series(9)==25'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.7375976929717,\n",
              "     'tokenization_energy': 0.12259769296646118,\n",
              "     'inference_energy': 22.61500000000524,\n",
              "     'energy_per_token': 0.7105499279053656,\n",
              "     'time': 0.5686740875244141,\n",
              "     'components': {'embeddings': np.float64(0.12075045466423034),\n",
              "      'attention': np.float64(12.967572509773422),\n",
              "      'ffn': np.float64(13.156124710556119),\n",
              "      'layernorm': np.float64(0.1201337242126465),\n",
              "      'output_layer': np.float64(0.2797317695617676)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a function to calculate the area of a regular polygon.',\n",
              "    'ground_truth_code': 'from math import tan, pi\\r\\ndef area_polygon(s,l):\\r\\n  area = s * (l ** 2) / (4 * tan(pi / s))\\r\\n  return area',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability of a triangle polygon given The',\n",
              "    'test_cases': ['assert area_polygon(4,20)==400.00000000000006',\n",
              "     'assert area_polygon(10,15)==1731.1969896610804',\n",
              "     'assert area_polygon(9,7)==302.90938549487214'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.250360267632058,\n",
              "     'tokenization_energy': 0.14236026763916015,\n",
              "     'inference_energy': 27.1079999999929,\n",
              "     'energy_per_token': 2.09618155904862,\n",
              "     'time': 0.559502363204956,\n",
              "     'components': {'embeddings': np.float64(4.6159999999945285),\n",
              "      'attention': np.float64(8.87854876184906),\n",
              "      'ffn': np.float64(8.542928837053712),\n",
              "      'layernorm': np.float64(0.11953085994720458),\n",
              "      'output_layer': np.float64(0.19898913383483885)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to check whether the sum of divisors are same or not.',\n",
              "    'ground_truth_code': 'import math \\r\\ndef divSum(n): \\r\\n    sum = 1; \\r\\n    i = 2; \\r\\n    while(i * i <= n): \\r\\n        if (n % i == 0): \\r\\n            sum = (sum + i +math.floor(n / i)); \\r\\n        i += 1; \\r\\n    return sum; \\r\\ndef areEquivalent(num1,num2): \\r\\n    return divSum(num1) == divSum(num2); ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given of allisors of equal as not for The',\n",
              "    'test_cases': ['assert areEquivalent(36,57) == False',\n",
              "     'assert areEquivalent(2,4) == False',\n",
              "     'assert areEquivalent(23,47) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.230567985539906,\n",
              "     'tokenization_energy': 0.11556798553466796,\n",
              "     'inference_energy': 27.11500000000524,\n",
              "     'energy_per_token': 1.5128093325299947,\n",
              "     'time': 0.5604338645935059,\n",
              "     'components': {'embeddings': np.float64(0.11421532440185546),\n",
              "      'attention': np.float64(4.627051278591156),\n",
              "      'ffn': np.float64(8.704679004199802),\n",
              "      'layernorm': np.float64(0.11947741079330444),\n",
              "      'output_layer': np.float64(0.21806931018829345)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to count characters at same position in a given string (lower and uppercase characters) as in english alphabet.',\n",
              "    'ground_truth_code': \"def count_char_position(str1): \\r\\n    count_chars = 0\\r\\n    for i in range(len(str1)):\\r\\n        if ((i == ord(str1[i]) - ord('A')) or \\r\\n            (i == ord(str1[i]) - ord('a'))): \\r\\n            count_chars += 1\\r\\n    return count_chars \",\n",
              "    'generated_code': ')\\n\\n the function function that compute the in each level in a string string,icase upper) only and per the alphabet.\\n So',\n",
              "    'test_cases': ['assert count_char_position(\"xbcefg\") == 2',\n",
              "     'assert count_char_position(\"ABcED\") == 3',\n",
              "     'assert count_char_position(\"AbgdeF\") == 5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.82182873439335,\n",
              "     'tokenization_energy': 0.12982873439788817,\n",
              "     'inference_energy': 22.69199999999546,\n",
              "     'energy_per_token': 0.8777626436305135,\n",
              "     'time': 0.5564694404602051,\n",
              "     'components': {'embeddings': np.float64(0.1267030110359192),\n",
              "      'attention': np.float64(9.141463400596288),\n",
              "      'ffn': np.float64(4.322936318397521),\n",
              "      'layernorm': np.float64(0.12647920989990233),\n",
              "      'output_layer': np.float64(0.23023394393920896)},\n",
              "     'num_tokens': 26}},\n",
              "   {'prompt': 'Write a python function to count the pairs with xor as an even number.',\n",
              "    'ground_truth_code': 'def find_even_Pair(A,N): \\r\\n    evenPair = 0\\r\\n    for i in range(0,N): \\r\\n        for j in range(i+1,N): \\r\\n            if ((A[i] ^ A[j]) % 2 == 0): \\r\\n                evenPair+=1\\r\\n    return evenPair; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of the equal  even number.\\n The',\n",
              "    'test_cases': ['assert find_even_Pair([5,4,7,2,1],5) == 4',\n",
              "     'assert find_even_Pair([7,2,8,1,0,5,11],7) == 9',\n",
              "     'assert find_even_Pair([1,2,3],3) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.223834304808523,\n",
              "     'tokenization_energy': 0.1218343048095703,\n",
              "     'inference_energy': 27.101999999998952,\n",
              "     'energy_per_token': 1.7014896440505327,\n",
              "     'time': 0.5602879524230957,\n",
              "     'components': {'embeddings': np.float64(0.12018969726562499),\n",
              "      'attention': np.float64(8.85688801717537),\n",
              "      'ffn': np.float64(8.588154265877325),\n",
              "      'layernorm': np.float64(4.434999999997672),\n",
              "      'output_layer': np.float64(0.19970446395874022)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find smallest power of 2 greater than or equal to n.',\n",
              "    'ground_truth_code': 'def next_Power_Of_2(n): \\r\\n    count = 0; \\r\\n    if (n and not(n & (n - 1))): \\r\\n        return n   \\r\\n    while( n != 0): \\r\\n        n >>= 1\\r\\n        count += 1\\r\\n    return 1 << count; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of x2 that than or equal to a.\\n\\n Return',\n",
              "    'test_cases': ['assert next_Power_Of_2(0) == 1',\n",
              "     'assert next_Power_Of_2(5) == 8',\n",
              "     'assert next_Power_Of_2(17) == 32'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.943338022709824,\n",
              "     'tokenization_energy': 0.11733802270889282,\n",
              "     'inference_energy': 22.82600000000093,\n",
              "     'energy_per_token': 1.2075441064584118,\n",
              "     'time': 0.5590496063232422,\n",
              "     'components': {'embeddings': np.float64(0.11480676651000976),\n",
              "      'attention': np.float64(13.38059620858019),\n",
              "      'ffn': np.float64(8.602622743841026),\n",
              "      'layernorm': np.float64(0.13248737096786498),\n",
              "      'output_layer': np.float64(0.230764075756073)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to find the frequency of a number in a given array.',\n",
              "    'ground_truth_code': 'def frequency(a,x): \\r\\n    count = 0  \\r\\n    for i in a: \\r\\n        if i == x: count += 1\\r\\n    return count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of each given in a matrix matrix.\\n The',\n",
              "    'test_cases': ['assert frequency([1,2,3],4) == 0',\n",
              "     'assert frequency([1,2,2,3,3,3,4],3) == 3',\n",
              "     'assert frequency([0,1,2,3,1,2],1) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.175341974265177,\n",
              "     'tokenization_energy': 0.12434197425842285,\n",
              "     'inference_energy': 27.051000000006752,\n",
              "     'energy_per_token': 1.5985495278979516,\n",
              "     'time': 0.570817232131958,\n",
              "     'components': {'embeddings': np.float64(0.13989969825744628),\n",
              "      'attention': np.float64(13.417878268733853),\n",
              "      'ffn': np.float64(17.33888006304321),\n",
              "      'layernorm': np.float64(0.12389256477355957),\n",
              "      'output_layer': np.float64(0.2969115128517151)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to calculate the nth pell number.',\n",
              "    'ground_truth_code': 'def get_pell(n): \\r\\n\\tif (n <= 2): \\r\\n\\t\\treturn n \\r\\n\\ta = 1\\r\\n\\tb = 2\\r\\n\\tfor i in range(3, n+1): \\r\\n\\t\\tc = 2 * b + a \\r\\n\\t\\ta = b \\r\\n\\t\\tb = c \\r\\n\\treturn b ',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability Fibonaccienta number, The',\n",
              "    'test_cases': ['assert get_pell(4) == 12',\n",
              "     'assert get_pell(7) == 169',\n",
              "     'assert get_pell(8) == 408'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.174530928127933,\n",
              "     'tokenization_energy': 0.11953092813491821,\n",
              "     'inference_energy': 27.054999999993015,\n",
              "     'energy_per_token': 2.264544244010661,\n",
              "     'time': 0.5563936233520508,\n",
              "     'components': {'embeddings': np.float64(0.11976281261444092),\n",
              "      'attention': np.float64(4.493008577585219),\n",
              "      'ffn': np.float64(4.304951034545899),\n",
              "      'layernorm': np.float64(0.12045135831832886),\n",
              "      'output_layer': np.float64(0.24829457473754885)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find sum of the numbers in a list between the indices of a specified range.',\n",
              "    'ground_truth_code': 'def sum_range_list(list1, m, n):                                                                                                                                                                                                \\r\\n    sum_range = 0                                                                                                                                                                                                         \\r\\n    for i in range(m, n+1, 1):                                                                                                                                                                                        \\r\\n        sum_range += list1[i]                                                                                                                                                                                                  \\r\\n    return sum_range   ',\n",
              "    'generated_code': ')\\n\\n the function that compute the of all digits in a matrix.\\n two first a the given range, The',\n",
              "    'test_cases': ['assert sum_range_list( [2,1,5,6,8,3,4,9,10,11,8,12],8,10)==29',\n",
              "     'assert sum_range_list( [2,1,5,6,8,3,4,9,10,11,8,12],5,7)==16',\n",
              "     'assert sum_range_list( [2,1,5,6,8,3,4,9,10,11,8,12],7,10)==38'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.39944680786098,\n",
              "     'tokenization_energy': 0.11544680786132813,\n",
              "     'inference_energy': 27.28399999999965,\n",
              "     'energy_per_token': 1.3047355622790942,\n",
              "     'time': 0.648146390914917,\n",
              "     'components': {'embeddings': np.float64(0.11727622222900391),\n",
              "      'attention': np.float64(22.540431107049805),\n",
              "      'ffn': np.float64(13.562077406638885),\n",
              "      'layernorm': np.float64(0.12132360458374024),\n",
              "      'output_layer': np.float64(0.2798118915557861)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function to find the perimeter of a pentagon.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef perimeter_pentagon(a):\\r\\n  perimeter=(5*a)\\r\\n  return perimeter',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a triangleagon given The',\n",
              "    'test_cases': ['assert perimeter_pentagon(5)==25',\n",
              "     'assert perimeter_pentagon(10)==50',\n",
              "     'assert perimeter_pentagon(15)==75'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 31.77563788128318,\n",
              "     'tokenization_energy': 0.1836378812789917,\n",
              "     'inference_energy': 31.59200000000419,\n",
              "     'energy_per_token': 2.4442798370217833,\n",
              "     'time': 0.6589016914367676,\n",
              "     'components': {'embeddings': np.float64(0.2288623743057251),\n",
              "      'attention': np.float64(9.767275558468533),\n",
              "      'ffn': np.float64(9.039387594691945),\n",
              "      'layernorm': np.float64(0.12388037014007568),\n",
              "      'output_layer': np.float64(4.551000000006752)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': \"Write a function to find the occurence of characters 'std' in the given string 1. list item 1. list item 1. list item 2. list item 2. list item 2. list item\",\n",
              "    'ground_truth_code': \"def count_occurance(s):\\r\\n  count=0\\r\\n  for i in range(len(s)):\\r\\n    if (s[i]== 's' and s[i+1]=='t' and s[i+2]== 'd'):\\r\\n      count = count + 1\\r\\n  return count\",\n",
              "    'generated_code': \")\\n\\n the function that compute the maximumurence of a ina' in a string string, $, If the\\n1.2 item\\n1. list item\",\n",
              "    'test_cases': ['assert count_occurance(\"letstdlenstdporstd\") == 3',\n",
              "     'assert count_occurance(\"truststdsolensporsd\") == 1',\n",
              "     'assert count_occurance(\"makestdsostdworthit\") == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.859856189490763,\n",
              "     'tokenization_energy': 0.12085618948936462,\n",
              "     'inference_energy': 22.739000000001397,\n",
              "     'energy_per_token': 0.7143705059215864,\n",
              "     'time': 0.5757050514221191,\n",
              "     'components': {'embeddings': np.float64(0.12186622357368469),\n",
              "      'attention': np.float64(13.419543690692983),\n",
              "      'ffn': np.float64(13.538203766576132),\n",
              "      'layernorm': np.float64(0.12862581396102904),\n",
              "      'output_layer': np.float64(0.23479909229278564)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a function to remove everything except alphanumeric characters from a string.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef remove_splchar(text): \\r\\n pattern = re.compile('[\\\\W_]+')\\r\\n return (pattern.sub('', text))\",\n",
              "    'generated_code': ')\\n\\n the function that compute the from the characters from a string, If',\n",
              "    'test_cases': [\"assert remove_splchar('python  @#&^%$*program123')==('pythonprogram123')\",\n",
              "     \"assert remove_splchar('python %^$@!^&*()  programming24%$^^()    language')==('pythonprogramming24language')\",\n",
              "     \"assert remove_splchar('python   ^%&^()(+_)(_^&67)                  program')==('python67program')\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.700457036503824,\n",
              "     'tokenization_energy': 0.12245703649520874,\n",
              "     'inference_energy': 22.578000000008615,\n",
              "     'energy_per_token': 1.6214612168931304,\n",
              "     'time': 0.5690462589263916,\n",
              "     'components': {'embeddings': np.float64(0.17655139565467834),\n",
              "      'attention': np.float64(8.902431485411595),\n",
              "      'ffn': np.float64(12.917470385319437),\n",
              "      'layernorm': np.float64(0.11974221324920654),\n",
              "      'output_layer': np.float64(0.25625531101226806)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to group a sequence of key-value pairs into a dictionary of lists.',\n",
              "    'ground_truth_code': 'def group_keyvalue(l):\\r\\n    result = {}\\r\\n    for k, v in l:\\r\\n         result.setdefault(k, []).append(v)\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the given of numbers-value pairs into a group, key, The',\n",
              "    'test_cases': [\"assert group_keyvalue([('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)])=={'yellow': [1, 3], 'blue': [2, 4], 'red': [1]}\",\n",
              "     \"assert group_keyvalue([('python', 1), ('python', 2), ('python', 3), ('python', 4), ('python', 5)])=={'python': [1,2,3,4,5]}\",\n",
              "     \"assert group_keyvalue([('yellow',100), ('blue', 200), ('yellow', 300), ('blue', 400), ('red', 100)])=={'yellow': [100, 300], 'blue': [200, 400], 'red': [100]}\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.40123645972868,\n",
              "     'tokenization_energy': 0.11423645973205566,\n",
              "     'inference_energy': 27.286999999996624,\n",
              "     'energy_per_token': 1.522290914429371,\n",
              "     'time': 0.5699820518493652,\n",
              "     'components': {'embeddings': np.float64(0.12961241245269775),\n",
              "      'attention': np.float64(8.906905733828548),\n",
              "      'ffn': np.float64(17.516567360862858),\n",
              "      'layernorm': np.float64(0.18015180587768553),\n",
              "      'output_layer': np.float64(0.21755363845825196)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to verify validity of a string of parentheses.',\n",
              "    'ground_truth_code': 'def is_valid_parenthese( str1):\\r\\n        stack, pchar = [], {\"(\": \")\", \"{\": \"}\", \"[\": \"]\"}\\r\\n        for parenthese in str1:\\r\\n            if parenthese in pchar:\\r\\n                stack.append(parenthese)\\r\\n            elif len(stack) == 0 or pchar[stack.pop()] != parenthese:\\r\\n                return False\\r\\n        return len(stack) == 0',\n",
              "    'generated_code': ')\\n\\n the function that compute whether of a valid in digits, The',\n",
              "    'test_cases': ['assert is_valid_parenthese(\"(){}[]\")==True',\n",
              "     'assert is_valid_parenthese(\"()[{)}\")==False',\n",
              "     'assert is_valid_parenthese(\"()\")==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.293576335910707,\n",
              "     'tokenization_energy': 0.11457633590698242,\n",
              "     'inference_energy': 27.179000000003725,\n",
              "     'energy_per_token': 2.099505871993131,\n",
              "     'time': 0.5776374340057373,\n",
              "     'components': {'embeddings': np.float64(0.11619233322143555),\n",
              "      'attention': np.float64(9.142672906636843),\n",
              "      'ffn': np.float64(13.000162695647797),\n",
              "      'layernorm': np.float64(0.12273729658126832),\n",
              "      'output_layer': np.float64(0.20316024398803711)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the perimeter of a triangle.',\n",
              "    'ground_truth_code': 'def perimeter_triangle(a,b,c):\\r\\n  perimeter=a+b+c\\r\\n  return perimeter',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a triangle given The',\n",
              "    'test_cases': ['assert perimeter_triangle(10,20,30)==60',\n",
              "     'assert perimeter_triangle(3,4,5)==12',\n",
              "     'assert perimeter_triangle(25,35,45)==105'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.681595292807323,\n",
              "     'tokenization_energy': 0.12459529280662536,\n",
              "     'inference_energy': 22.5570000000007,\n",
              "     'energy_per_token': 1.890132941067277,\n",
              "     'time': 0.5648090839385986,\n",
              "     'components': {'embeddings': np.float64(0.12473457026481628),\n",
              "      'attention': np.float64(17.66231008910376),\n",
              "      'ffn': np.float64(13.213188971766153),\n",
              "      'layernorm': np.float64(0.11817235922813416),\n",
              "      'output_layer': np.float64(0.20063125324249267)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to find two distinct numbers such that their lcm lies within the given range.',\n",
              "    'ground_truth_code': 'def answer(L,R): \\r\\n    if (2 * L <= R): \\r\\n        return (L ,2*L)\\r\\n    else: \\r\\n        return (-1) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the numbers integers in that the sum is in a range range. The',\n",
              "    'test_cases': ['assert answer(3,8) == (3,6)',\n",
              "     'assert answer(2,6) == (2,4)',\n",
              "     'assert answer(1,3) == (1,2)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.303668435575908,\n",
              "     'tokenization_energy': 0.11366843557357788,\n",
              "     'inference_energy': 27.19000000000233,\n",
              "     'energy_per_token': 1.3651834217787955,\n",
              "     'time': 0.5678887367248535,\n",
              "     'components': {'embeddings': np.float64(0.18756457591056822),\n",
              "      'attention': np.float64(17.785395548822827),\n",
              "      'ffn': np.float64(13.059038530583027),\n",
              "      'layernorm': np.float64(0.12476534080505372),\n",
              "      'output_layer': np.float64(0.28985931777954105)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to search some literals strings in a string.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef string_literals(patterns,text):\\r\\n  for pattern in patterns:\\r\\n     if re.search(pattern,  text):\\r\\n       return ('Matched!')\\r\\n     else:\\r\\n       return ('Not Matched!')\",\n",
              "    'generated_code': ')\\n\\n the function that compute for\\n in in a given, The',\n",
              "    'test_cases': [\"assert string_literals(['language'],'python language')==('Matched!')\",\n",
              "     \"assert string_literals(['program'],'python language')==('Not Matched!')\",\n",
              "     \"assert string_literals(['python'],'programming language')==('Not Matched!')\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.65899481772457,\n",
              "     'tokenization_energy': 0.22199481773376464,\n",
              "     'inference_energy': 27.436999999990803,\n",
              "     'energy_per_token': 2.127614985978813,\n",
              "     'time': 0.5696473121643066,\n",
              "     'components': {'embeddings': np.float64(0.11743787002563477),\n",
              "      'attention': np.float64(9.015607950450269),\n",
              "      'ffn': np.float64(8.726982187518386),\n",
              "      'layernorm': np.float64(0.23378839492797854),\n",
              "      'output_layer': np.float64(4.584999999991851)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find if the given number is a keith number or not.',\n",
              "    'ground_truth_code': 'def is_num_keith(x): \\r\\n\\tterms = [] \\r\\n\\ttemp = x \\r\\n\\tn = 0 \\r\\n\\twhile (temp > 0): \\r\\n\\t\\tterms.append(temp % 10) \\r\\n\\t\\ttemp = int(temp / 10) \\r\\n\\t\\tn+=1 \\r\\n\\tterms.reverse() \\r\\n\\tnext_term = 0 \\r\\n\\ti = n \\r\\n\\twhile (next_term < x): \\r\\n\\t\\tnext_term = 0 \\r\\n\\t\\tfor j in range(1,n+1): \\r\\n\\t\\t\\tnext_term += terms[i - j] \\r\\n\\t\\tterms.append(next_term) \\r\\n\\t\\ti+=1 \\r\\n\\treturn (next_term == x) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the a given matrix is a perfecti number.\\n not.\\n The',\n",
              "    'test_cases': ['assert is_num_keith(14) == True',\n",
              "     'assert is_num_keith(12) == False',\n",
              "     'assert is_num_keith(197) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.78931838489312,\n",
              "     'tokenization_energy': 0.12831838488578795,\n",
              "     'inference_energy': 22.661000000007334,\n",
              "     'energy_per_token': 1.2660732436051734,\n",
              "     'time': 0.5652766227722168,\n",
              "     'components': {'embeddings': np.float64(0.12814008235931396),\n",
              "      'attention': np.float64(9.132309460643679),\n",
              "      'ffn': np.float64(13.023331074229558),\n",
              "      'layernorm': np.float64(0.12521626377105713),\n",
              "      'output_layer': np.float64(0.21583399200439451)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to calculate distance between two points using latitude and longitude.',\n",
              "    'ground_truth_code': 'from math import radians, sin, cos, acos\\r\\ndef distance_lat_long(slat,slon,elat,elon):\\r\\n dist = 6371.01 * acos(sin(slat)*sin(elat) + cos(slat)*cos(elat)*cos(slon - elon))\\r\\n return dist',\n",
              "    'generated_code': ')\\n\\n the function that compute the between two points in the and longitude.\\n The',\n",
              "    'test_cases': ['assert distance_lat_long(23.5,67.5,25.5,69.5)==12179.372041317429',\n",
              "     'assert distance_lat_long(10.5,20.5,30.5,40.5)==6069.397933300514',\n",
              "     'assert distance_lat_long(10,20,30,40)==6783.751974994595'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.323158557883698,\n",
              "     'tokenization_energy': 0.1131585578918457,\n",
              "     'inference_energy': 27.20999999999185,\n",
              "     'energy_per_token': 1.8215439038589132,\n",
              "     'time': 0.5667974948883057,\n",
              "     'components': {'embeddings': np.float64(0.11338047885894775),\n",
              "      'attention': np.float64(8.933127919670545),\n",
              "      'ffn': np.float64(8.537303407906904),\n",
              "      'layernorm': np.float64(0.122303551197052),\n",
              "      'output_layer': np.float64(0.20527122545242307)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the longest common prefix in the given set of strings.',\n",
              "    'ground_truth_code': 'def common_prefix_util(str1, str2): \\r\\n\\tresult = \"\"; \\r\\n\\tn1 = len(str1) \\r\\n\\tn2 = len(str2) \\r\\n\\ti = 0\\r\\n\\tj = 0\\r\\n\\twhile i <= n1 - 1 and j <= n2 - 1: \\r\\n\\t\\tif (str1[i] != str2[j]): \\r\\n\\t\\t\\tbreak\\r\\n\\t\\tresult += str1[i] \\r\\n\\t\\ti += 1\\r\\n\\t\\tj += 1\\r\\n\\treturn (result) \\r\\ndef common_prefix (arr, n): \\r\\n\\tprefix = arr[0] \\r\\n\\tfor i in range (1, n): \\r\\n\\t\\tprefix = common_prefix_util(prefix, arr[i]) \\r\\n\\treturn (prefix) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum substring substring of a prefix string of integers. The',\n",
              "    'test_cases': ['assert common_prefix([\"tablets\", \"tables\", \"taxi\", \"tamarind\"], 4) == \\'ta\\'',\n",
              "     'assert common_prefix([\"apples\", \"ape\", \"april\"], 3) == \\'ap\\'',\n",
              "     'assert common_prefix([\"teens\", \"teenager\", \"teenmar\"], 3) == \\'teen\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.444390816692845,\n",
              "     'tokenization_energy': 0.1553908166885376,\n",
              "     'inference_energy': 27.289000000004307,\n",
              "     'energy_per_token': 1.6143759303936969,\n",
              "     'time': 0.5727207660675049,\n",
              "     'components': {'embeddings': np.float64(0.1171072232723236),\n",
              "      'attention': np.float64(9.390266390797683),\n",
              "      'ffn': np.float64(17.634153815994274),\n",
              "      'layernorm': np.float64(0.12250688552856445),\n",
              "      'output_layer': np.float64(0.24669239521026612)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find uppercase, lowercase, special character and numeric values using regex.',\n",
              "    'ground_truth_code': 'import re\\r\\ndef find_character(string):\\r\\n  uppercase_characters = re.findall(r\"[A-Z]\", string) \\r\\n  lowercase_characters = re.findall(r\"[a-z]\", string) \\r\\n  numerical_characters = re.findall(r\"[0-9]\", string) \\r\\n  special_characters = re.findall(r\"[, .!?]\", string) \\r\\n  return uppercase_characters, lowercase_characters, numerical_characters, special_characters',\n",
              "    'generated_code': ')\\n\\n the function that compute the letters lowercase, and,, number character in the in The',\n",
              "    'test_cases': ['assert find_character(\"ThisIsGeeksforGeeks\") == ([\\'T\\', \\'I\\', \\'G\\', \\'G\\'], [\\'h\\', \\'i\\', \\'s\\', \\'s\\', \\'e\\', \\'e\\', \\'k\\', \\'s\\', \\'f\\', \\'o\\', \\'r\\', \\'e\\', \\'e\\', \\'k\\', \\'s\\'], [], [])',\n",
              "     'assert find_character(\"Hithere2\") == ([\\'H\\'], [\\'i\\', \\'t\\', \\'h\\', \\'e\\', \\'r\\', \\'e\\'], [\\'2\\'], [])',\n",
              "     'assert find_character(\"HeyFolks32\") == ([\\'H\\', \\'F\\'], [\\'e\\', \\'y\\', \\'o\\', \\'l\\', \\'k\\', \\'s\\'], [\\'3\\', \\'2\\'], [])'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.074380447386414,\n",
              "     'tokenization_energy': 0.11638044738769532,\n",
              "     'inference_energy': 22.95799999999872,\n",
              "     'energy_per_token': 1.2819100248548008,\n",
              "     'time': 0.5622200965881348,\n",
              "     'components': {'embeddings': np.float64(0.1168451910018921),\n",
              "      'attention': np.float64(13.335879154670751),\n",
              "      'ffn': np.float64(13.407972816718393),\n",
              "      'layernorm': np.float64(0.12199831795692444),\n",
              "      'output_layer': np.float64(0.22151333427429198)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to count all the distinct pairs having a difference of k in any array.',\n",
              "    'ground_truth_code': 'def count_pairs(arr, n, k):\\r\\n  count=0;\\r\\n  for i in range(0,n):\\r\\n    for j in range(i+1, n):\\r\\n      if arr[i] - arr[j] == k or arr[j] - arr[i] == k:\\r\\n        count += 1\\r\\n  return count',\n",
              "    'generated_code': ')\\n\\n the function that compute the the possible prime of a positive of exactly in a order.\\n The',\n",
              "    'test_cases': ['assert count_pairs([1, 5, 3, 4, 2], 5, 3) == 2',\n",
              "     'assert count_pairs([8, 12, 16, 4, 0, 20], 6, 4) == 5',\n",
              "     'assert count_pairs([2, 4, 1, 3, 4], 5, 2) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.51328350639448,\n",
              "     'tokenization_energy': 0.11528350639343261,\n",
              "     'inference_energy': 27.398000000001048,\n",
              "     'energy_per_token': 1.4480675529681306,\n",
              "     'time': 0.5653095245361328,\n",
              "     'components': {'embeddings': np.float64(0.11534817552566529),\n",
              "      'attention': np.float64(13.334474153757096),\n",
              "      'ffn': np.float64(13.372695722810926),\n",
              "      'layernorm': np.float64(0.11927666854858399),\n",
              "      'output_layer': np.float64(0.21743364810943605)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find all the values in a list that are greater than a specified number.',\n",
              "    'ground_truth_code': 'def greater_specificnum(list,num):\\r\\n greater_specificnum=all(x >= num for x in list)\\r\\n return greater_specificnum',\n",
              "    'generated_code': ')\\n\\n the function that compute the the possible in a given that are not than the given number.\\n The',\n",
              "    'test_cases': ['assert greater_specificnum([220, 330, 500],200)==True',\n",
              "     'assert greater_specificnum([12, 17, 21],20)==False',\n",
              "     'assert greater_specificnum([1,2,3,4],10)==False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.47550913524523,\n",
              "     'tokenization_energy': 0.12350913524627685,\n",
              "     'inference_energy': 27.351999999998952,\n",
              "     'energy_per_token': 1.3737754567622615,\n",
              "     'time': 0.5618724822998047,\n",
              "     'components': {'embeddings': np.float64(0.1159930419921875),\n",
              "      'attention': np.float64(13.393013679522905),\n",
              "      'ffn': np.float64(13.299496946317142),\n",
              "      'layernorm': np.float64(0.12301863431930543),\n",
              "      'output_layer': np.float64(0.3060576152801514)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find the focus of a parabola.',\n",
              "    'ground_truth_code': 'def parabola_focus(a, b, c): \\r\\n  focus= (((-b / (2 * a)),(((4 * a * c) - (b * b) + 1) / (4 * a))))\\r\\n  return focus',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a parabola given The',\n",
              "    'test_cases': ['assert parabola_focus(5,3,2)==(-0.3, 1.6)',\n",
              "     'assert parabola_focus(9,8,4)==(-0.4444444444444444, 2.25)',\n",
              "     'assert parabola_focus(2,4,6)==(-1.0, 4.125)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.871881126405206,\n",
              "     'tokenization_energy': 0.13288112640380859,\n",
              "     'inference_energy': 22.739000000001397,\n",
              "     'energy_per_token': 1.633705794743229,\n",
              "     'time': 0.554373025894165,\n",
              "     'components': {'embeddings': np.float64(0.13023702621459962),\n",
              "      'attention': np.float64(13.295535678374696),\n",
              "      'ffn': np.float64(4.01090324664116),\n",
              "      'layernorm': np.float64(0.1224477767944336),\n",
              "      'output_layer': np.float64(0.2751041352748871)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to search some literals strings in a string by using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef check_literals(text, patterns):\\r\\n  for pattern in patterns:\\r\\n    if re.search(pattern,  text):\\r\\n        return ('Matched!')\\r\\n    else:\\r\\n        return ('Not Matched!')\",\n",
              "    'generated_code': ')\\n\\n the function that compute for\\n in in a given, using a, The',\n",
              "    'test_cases': [\"assert check_literals('The quick brown fox jumps over the lazy dog.',['fox']) == 'Matched!'\",\n",
              "     \"assert check_literals('The quick brown fox jumps over the lazy dog.',['horse']) == 'Not Matched!'\",\n",
              "     \"assert check_literals('The quick brown fox jumps over the lazy dog.',['lazy']) == 'Matched!'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.506054395920366,\n",
              "     'tokenization_energy': 0.11805439591407776,\n",
              "     'inference_energy': 27.388000000006286,\n",
              "     'energy_per_token': 1.7191283997450229,\n",
              "     'time': 0.5553288459777832,\n",
              "     'components': {'embeddings': np.float64(0.11858857870101928),\n",
              "      'attention': np.float64(4.61643018913269),\n",
              "      'ffn': np.float64(8.821989301447406),\n",
              "      'layernorm': np.float64(0.12038550329208375),\n",
              "      'output_layer': np.float64(0.23334596514701844)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find the longest common subsequence for the given two sequences.',\n",
              "    'ground_truth_code': 'def longest_common_subsequence(X, Y, m, n): \\r\\n    if m == 0 or n == 0: \\r\\n       return 0 \\r\\n    elif X[m-1] == Y[n-1]: \\r\\n       return 1 + longest_common_subsequence(X, Y, m-1, n-1) \\r\\n    else: \\r\\n       return max(longest_common_subsequence(X, Y, m, n-1), longest_common_subsequence(X, Y, m-1, n))',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum substring substringsequence ( two two\\n sequences.\\n The',\n",
              "    'test_cases': ['assert longest_common_subsequence(\"AGGTAB\" , \"GXTXAYB\", 6, 7) == 4',\n",
              "     'assert longest_common_subsequence(\"ABCDGH\" , \"AEDFHR\", 6, 6) == 3',\n",
              "     'assert longest_common_subsequence(\"AXYT\" , \"AYZX\", 4, 4) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.898073496333673,\n",
              "     'tokenization_energy': 0.11607349634170532,\n",
              "     'inference_energy': 22.781999999991967,\n",
              "     'energy_per_token': 1.3469454997843338,\n",
              "     'time': 0.5586152076721191,\n",
              "     'components': {'embeddings': np.float64(0.11691601753234863),\n",
              "      'attention': np.float64(13.238017666829515),\n",
              "      'ffn': np.float64(8.974587407581158),\n",
              "      'layernorm': np.float64(0.12393673324584961),\n",
              "      'output_layer': np.float64(0.22391207027435303)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to check whether the given number can be represented by product of two squares or not.',\n",
              "    'ground_truth_code': 'def prod_Square(n):\\r\\n    for i in range(2,(n) + 1):\\r\\n        if (i*i < (n+1)):\\r\\n            for j in range(2,n + 1):\\r\\n                if ((i*i*j*j) == n):\\r\\n                    return True;\\r\\n    return False;',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n is be represented as the of two integers, not. \\n',\n",
              "    'test_cases': ['assert prod_Square(25) == False',\n",
              "     'assert prod_Square(30) == False',\n",
              "     'assert prod_Square(16) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.612757979875894,\n",
              "     'tokenization_energy': 0.11875797986984253,\n",
              "     'inference_energy': 27.494000000006054,\n",
              "     'energy_per_token': 1.2551253627216317,\n",
              "     'time': 0.5610873699188232,\n",
              "     'components': {'embeddings': np.float64(0.11837150573730469),\n",
              "      'attention': np.float64(17.85107728720433),\n",
              "      'ffn': np.float64(8.675836791988228),\n",
              "      'layernorm': np.float64(0.12565494394302368),\n",
              "      'output_layer': np.float64(0.22290596532821655)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a python function to find the first missing positive number.',\n",
              "    'ground_truth_code': 'def first_Missing_Positive(arr,n): \\r\\n    ptr = 0\\r\\n    for i in range(n):\\r\\n        if arr[i] == 1:\\r\\n            ptr = 1\\r\\n            break\\r\\n    if ptr == 0:\\r\\n        return(1)\\r\\n    for i in range(n):\\r\\n        if arr[i] <= 0 or arr[i] > n:\\r\\n            arr[i] = 1\\r\\n    for i in range(n):\\r\\n        arr[(arr[i] - 1) % n] += n\\r\\n    for i in range(n):\\r\\n        if arr[i] <= n:\\r\\n            return(i + 1)\\r\\n    return(n + 1)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence positive integer in The',\n",
              "    'test_cases': ['assert first_Missing_Positive([1,2,3,-1,5],5) == 4',\n",
              "     'assert first_Missing_Positive([0,-1,-2,1,5,8],6) == 2',\n",
              "     'assert first_Missing_Positive([0,1,2,5,-8],5) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.91521112346172,\n",
              "     'tokenization_energy': 0.1172111234664917,\n",
              "     'inference_energy': 22.797999999995227,\n",
              "     'energy_per_token': 1.7627085479585938,\n",
              "     'time': 0.5587997436523438,\n",
              "     'components': {'embeddings': np.float64(0.12063223266601562),\n",
              "      'attention': np.float64(8.995908602233511),\n",
              "      'ffn': np.float64(4.241530717134476),\n",
              "      'layernorm': np.float64(0.12871964311599732),\n",
              "      'output_layer': np.float64(0.21950004506111145)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to count the number of integral co-ordinates that lie inside a square.',\n",
              "    'ground_truth_code': 'def count_Intgral_Points(x1,y1,x2,y2): \\r\\n    return ((y2 - y1 - 1) * (x2 - x1 - 1)) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of integers solutions...\\n...\\n ( lie on a triangle, The',\n",
              "    'test_cases': ['assert count_Intgral_Points(1,1,4,4) == 4',\n",
              "     'assert count_Intgral_Points(1,2,1,2) == 1',\n",
              "     'assert count_Intgral_Points(4,2,6,4) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.958834084988105,\n",
              "     'tokenization_energy': 0.17083408498764038,\n",
              "     'inference_energy': 22.788000000000466,\n",
              "     'energy_per_token': 1.1479417042494053,\n",
              "     'time': 0.5643129348754883,\n",
              "     'components': {'embeddings': np.float64(0.12167383909225464),\n",
              "      'attention': np.float64(13.501901937479618),\n",
              "      'ffn': np.float64(13.014873083828366),\n",
              "      'layernorm': np.float64(0.12529529094696046),\n",
              "      'output_layer': np.float64(0.2939105248451233)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to check whether the given month name contains 30 days or not.',\n",
              "    'ground_truth_code': 'def check_monthnumber(monthname3):\\r\\n  if monthname3 ==\"April\" or monthname3== \"June\" or monthname3== \"September\" or monthname3== \"November\":\\r\\n    return True\\r\\n  else:\\r\\n    return False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given\\n and is a1 letters days.\\n not. The',\n",
              "    'test_cases': ['assert check_monthnumber(\"February\")==False',\n",
              "     'assert check_monthnumber(\"June\")==True',\n",
              "     'assert check_monthnumber(\"April\")==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.74945220612106,\n",
              "     'tokenization_energy': 0.12045220613479614,\n",
              "     'inference_energy': 27.628999999986263,\n",
              "     'energy_per_token': 1.4604974845326872,\n",
              "     'time': 0.5607705116271973,\n",
              "     'components': {'embeddings': np.float64(0.12155696511268616),\n",
              "      'attention': np.float64(13.755882546414737),\n",
              "      'ffn': np.float64(17.776393637184054),\n",
              "      'layernorm': np.float64(4.588999999992666),\n",
              "      'output_layer': np.float64(0.29050942420959475)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to check whether a string has atleast one letter and one number.',\n",
              "    'ground_truth_code': 'def check_String(str): \\r\\n    flag_l = False\\r\\n    flag_n = False\\r\\n    for i in str: \\r\\n        if i.isalpha(): \\r\\n            flag_l = True  \\r\\n        if i.isdigit(): \\r\\n            flag_n = True\\r\\n    return flag_l and flag_n ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given is a one\\n\\n one number.\\n \\n',\n",
              "    'test_cases': [\"assert check_String('thishasboth29') == True\",\n",
              "     \"assert check_String('python') == False\",\n",
              "     \"assert check_String ('string') == False\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.887828756341825,\n",
              "     'tokenization_energy': 0.18082875633239748,\n",
              "     'inference_energy': 22.70700000000943,\n",
              "     'energy_per_token': 1.2715460420189904,\n",
              "     'time': 0.5598013401031494,\n",
              "     'components': {'embeddings': np.float64(0.12109609603881837),\n",
              "      'attention': np.float64(9.023977558616666),\n",
              "      'ffn': np.float64(8.546861519578378),\n",
              "      'layernorm': np.float64(0.11866654300689697),\n",
              "      'output_layer': np.float64(0.2762746801376343)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to remove the duplicates from the given tuple.',\n",
              "    'ground_truth_code': 'def remove_tuple(test_tup):\\r\\n  res = tuple(set(test_tup))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the top from the function array.\\n The',\n",
              "    'test_cases': ['assert remove_tuple((1, 3, 5, 2, 3, 5, 1, 1, 3)) == (1, 2, 3, 5)',\n",
              "     'assert remove_tuple((2, 3, 4, 4, 5, 6, 6, 7, 8, 8)) == (2, 3, 4, 5, 6, 7, 8)',\n",
              "     'assert remove_tuple((11, 12, 13, 11, 11, 12, 14, 13)) == (11, 12, 13, 14)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.544848161687494,\n",
              "     'tokenization_energy': 0.1648481616973877,\n",
              "     'inference_energy': 27.379999999990105,\n",
              "     'energy_per_token': 2.1188344739759613,\n",
              "     'time': 0.5573177337646484,\n",
              "     'components': {'embeddings': np.float64(4.611000000004424),\n",
              "      'attention': np.float64(13.272376649367041),\n",
              "      'ffn': np.float64(8.516621728659258),\n",
              "      'layernorm': np.float64(0.12060443115234375),\n",
              "      'output_layer': np.float64(0.2635245094299316)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to convert octal number to decimal number.',\n",
              "    'ground_truth_code': 'def octal_To_Decimal(n):  \\r\\n    num = n; \\r\\n    dec_value = 0; \\r\\n    base = 1; \\r\\n    temp = num; \\r\\n    while (temp): \\r\\n        last_digit = temp % 10; \\r\\n        temp = int(temp / 10); \\r\\n        dec_value += last_digit*base; \\r\\n        base = base * 8; \\r\\n    return dec_value; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute aal numbers to binary number.\\n The',\n",
              "    'test_cases': ['assert octal_To_Decimal(25) == 21',\n",
              "     'assert octal_To_Decimal(30) == 24',\n",
              "     'assert octal_To_Decimal(40) == 32'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.76706602097128,\n",
              "     'tokenization_energy': 0.11406602096557616,\n",
              "     'inference_energy': 27.653000000005704,\n",
              "     'energy_per_token': 1.9833618586408057,\n",
              "     'time': 0.5615193843841553,\n",
              "     'components': {'embeddings': np.float64(0.1142892837524414),\n",
              "      'attention': np.float64(8.939606197349379),\n",
              "      'ffn': np.float64(8.690403658149997),\n",
              "      'layernorm': np.float64(0.12352022171020507),\n",
              "      'output_layer': np.float64(0.27170041275024415)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the first position of an element in a sorted array.',\n",
              "    'ground_truth_code': 'def first(arr,x,n): \\r\\n    low = 0\\r\\n    high = n - 1\\r\\n    res = -1  \\r\\n    while (low <= high):\\r\\n        mid = (low + high) // 2 \\r\\n        if arr[mid] > x:\\r\\n            high = mid - 1\\r\\n        elif arr[mid] < x:\\r\\n            low = mid + 1\\r\\n        else:\\r\\n            res = mid\\r\\n            high = mid - 1\\r\\n    return res',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence of a integer in a matrix array that The',\n",
              "    'test_cases': ['assert first([1,2,3,4,5,6,6],6,6) == 5',\n",
              "     'assert first([1,2,2,2,3,2,2,4,2],2,9) == 1',\n",
              "     'assert first([1,2,3],1,3) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.090269908909104,\n",
              "     'tokenization_energy': 0.1952699089050293,\n",
              "     'inference_energy': 22.895000000004075,\n",
              "     'energy_per_token': 1.2827927727171724,\n",
              "     'time': 0.5557293891906738,\n",
              "     'components': {'embeddings': np.float64(0.12673813152313232),\n",
              "      'attention': np.float64(13.451455291280638),\n",
              "      'ffn': np.float64(8.780428436516203),\n",
              "      'layernorm': np.float64(0.12441514873504637),\n",
              "      'output_layer': np.float64(0.2227383403778076)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to remove all the tuples with length k.',\n",
              "    'ground_truth_code': 'def remove_tuples(test_list, K):\\r\\n  res = [ele for ele in test_list if len(ele) != K]\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the the all from the greater from So',\n",
              "    'test_cases': ['assert remove_tuples([(4, 5), (4, ), (8, 6, 7), (1, ), (3, 4, 6, 7)] , 1) == [(4, 5), (8, 6, 7), (3, 4, 6, 7)]',\n",
              "     'assert remove_tuples([(4, 5), (4,5), (6, 7), (1, 2, 3), (3, 4, 6, 7)] ,2) == [(1, 2, 3), (3, 4, 6, 7)]',\n",
              "     'assert remove_tuples([(1, 4, 4), (4, 3), (8, 6, 7), (1, ), (3, 6, 7)] , 3) == [(4, 3), (1,)]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.51166385483765,\n",
              "     'tokenization_energy': 0.11766385483741759,\n",
              "     'inference_energy': 27.394000000000233,\n",
              "     'energy_per_token': 2.1162818349875114,\n",
              "     'time': 0.5652382373809814,\n",
              "     'components': {'embeddings': np.float64(0.11790303111076354),\n",
              "      'attention': np.float64(4.685004554510117),\n",
              "      'ffn': np.float64(8.658515714158654),\n",
              "      'layernorm': np.float64(0.15013753509521482),\n",
              "      'output_layer': np.float64(0.2067735538482666)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to perform the exponentiation of the given two tuples.',\n",
              "    'ground_truth_code': 'def find_exponentio(test_tup1, test_tup2):\\r\\n  res = tuple(ele1 ** ele2 for ele1, ele2 in zip(test_tup1, test_tup2))\\r\\n  return (res)\\r\\n',\n",
              "    'generated_code': ')\\n\\n the function that compute the followingiation of a matrix matrix integers.\\n The',\n",
              "    'test_cases': ['assert find_exponentio((10, 4, 5, 6), (5, 6, 7, 5)) == (100000, 4096, 78125, 7776)',\n",
              "     'assert find_exponentio((11, 5, 6, 7), (6, 7, 8, 6)) == (1771561, 78125, 1679616, 117649)',\n",
              "     'assert find_exponentio((12, 6, 7, 8), (7, 8, 9, 7)) == (35831808, 1679616, 40353607, 2097152)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.098750404360704,\n",
              "     'tokenization_energy': 0.12075040435791015,\n",
              "     'inference_energy': 22.978000000002794,\n",
              "     'energy_per_token': 1.539916693624047,\n",
              "     'time': 0.5601694583892822,\n",
              "     'components': {'embeddings': np.float64(0.11902884483337402),\n",
              "      'attention': np.float64(13.386163910159262),\n",
              "      'ffn': np.float64(8.738696990008),\n",
              "      'layernorm': np.float64(0.12042807006835937),\n",
              "      'output_layer': np.float64(0.2025080728530884)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the largest triangle that can be inscribed in an ellipse.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef largest_triangle(a,b): \\r\\n    if (a < 0 or b < 0): \\r\\n        return -1 \\r\\n    area = (3 * math.sqrt(3) * pow(a, 2)) / (4 * b);  \\r\\n    return area ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum prime number can be formedcribed in a n.\\n The',\n",
              "    'test_cases': ['assert largest_triangle(4,2)==10.392304845413264',\n",
              "     'assert largest_triangle(5,7)==4.639421805988064',\n",
              "     'assert largest_triangle(9,1)==105.2220865598093'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.610453616129934,\n",
              "     'tokenization_energy': 0.11745361614227295,\n",
              "     'inference_energy': 27.49299999998766,\n",
              "     'energy_per_token': 1.5339140897849963,\n",
              "     'time': 0.5685243606567383,\n",
              "     'components': {'embeddings': np.float64(0.1827298843860626),\n",
              "      'attention': np.float64(13.430729620698376),\n",
              "      'ffn': np.float64(8.678748788116037),\n",
              "      'layernorm': np.float64(0.12246230578422546),\n",
              "      'output_layer': np.float64(0.2216726861000061)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to find highest power of 2 less than or equal to given number.',\n",
              "    'ground_truth_code': 'def highest_Power_of_2(n): \\r\\n    res = 0; \\r\\n    for i in range(n, 0, -1):  \\r\\n        if ((i & (i - 1)) == 0): \\r\\n            res = i; \\r\\n            break;      \\r\\n    return res; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the weight of 2 in than or equal to a number n So',\n",
              "    'test_cases': ['assert highest_Power_of_2(10) == 8',\n",
              "     'assert highest_Power_of_2(19) == 16',\n",
              "     'assert highest_Power_of_2(32) == 32'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.628064778807225,\n",
              "     'tokenization_energy': 0.11606477880477906,\n",
              "     'inference_energy': 27.512000000002445,\n",
              "     'energy_per_token': 1.3814032389403612,\n",
              "     'time': 0.5722424983978271,\n",
              "     'components': {'embeddings': np.float64(0.1773121690750122),\n",
              "      'attention': np.float64(13.716709773317213),\n",
              "      'ffn': np.float64(13.087839961996885),\n",
              "      'layernorm': np.float64(0.12434523010253906),\n",
              "      'output_layer': np.float64(0.23121754455566407)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find all index positions of the maximum values in a given list.',\n",
              "    'ground_truth_code': 'def position_max(list1):\\r\\n    max_val = max(list1)\\r\\n    max_result = [i for i, j in enumerate(list1) if j == max_val]\\r\\n    return max_result',\n",
              "    'generated_code': ')\\n\\n the function that compute the the pairs of the two value in a  matrix of If',\n",
              "    'test_cases': ['assert position_max([12,33,23,10,67,89,45,667,23,12,11,10,54])==[7]',\n",
              "     'assert position_max([1,2,2,2,4,4,4,5,5,5,5])==[7,8,9,10]',\n",
              "     'assert position_max([2,1,5,6,8,3,4,9,10,11,8,12])==[11]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.005891818998034,\n",
              "     'tokenization_energy': 0.12389181900024414,\n",
              "     'inference_energy': 22.881999999997788,\n",
              "     'energy_per_token': 1.2781051010554463,\n",
              "     'time': 0.5562658309936523,\n",
              "     'components': {'embeddings': np.float64(0.1221113510131836),\n",
              "      'attention': np.float64(13.493863085752238),\n",
              "      'ffn': np.float64(17.507838752738895),\n",
              "      'layernorm': np.float64(0.12660735368728637),\n",
              "      'output_layer': np.float64(0.33296656751632686)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to check whether the elements in a list are same or not.',\n",
              "    'ground_truth_code': 'def chkList(lst): \\r\\n    return len(set(lst)) == 1',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given in a given are all as not.\\n The',\n",
              "    'test_cases': [\"assert chkList(['one','one','one']) == True\",\n",
              "     \"assert chkList(['one','Two','Three']) == False\",\n",
              "     \"assert chkList(['bigdata','python','Django']) == False\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.72724184942967,\n",
              "     'tokenization_energy': 0.13824184942245482,\n",
              "     'inference_energy': 27.589000000007218,\n",
              "     'energy_per_token': 1.540402324968315,\n",
              "     'time': 0.5603973865509033,\n",
              "     'components': {'embeddings': np.float64(4.70700000000943),\n",
              "      'attention': np.float64(13.56830710624927),\n",
              "      'ffn': np.float64(8.76917252851068),\n",
              "      'layernorm': np.float64(0.12407147836685181),\n",
              "      'output_layer': np.float64(0.22571893787384034)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to remove even characters in a string.',\n",
              "    'ground_truth_code': \"def remove_even(str1):\\r\\n str2 = ''\\r\\n for i in range(1, len(str1) + 1):\\r\\n    if(i % 2 != 0):\\r\\n        str2 = str2 + str1[i - 1]\\r\\n return str2\",\n",
              "    'generated_code': ')\\n\\n the function that compute the numbers from a matrix.\\n So',\n",
              "    'test_cases': ['assert remove_even(\"python\")==(\"pto\")',\n",
              "     'assert remove_even(\"program\")==(\"porm\")',\n",
              "     'assert remove_even(\"language\")==(\"lnug\")'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.024257440572722,\n",
              "     'tokenization_energy': 0.12125744056701661,\n",
              "     'inference_energy': 22.903000000005704,\n",
              "     'energy_per_token': 1.9186881200477268,\n",
              "     'time': 0.553318977355957,\n",
              "     'components': {'embeddings': np.float64(0.11988904571533203),\n",
              "      'attention': np.float64(13.460116314891959),\n",
              "      'ffn': np.float64(17.383895653964835),\n",
              "      'layernorm': np.float64(0.1227859570980072),\n",
              "      'output_layer': np.float64(0.20310767316818237)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to find the hamming distance between given two integers.',\n",
              "    'ground_truth_code': 'def hamming_Distance(n1,n2) : \\r\\n    x = n1 ^ n2  \\r\\n    setBits = 0\\r\\n    while (x > 0) : \\r\\n        setBits += x & 1\\r\\n        x >>= 1\\r\\n    return setBits  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the numberming distance between two two integers.\\n The',\n",
              "    'test_cases': ['assert hamming_Distance(4,8) == 2',\n",
              "     'assert hamming_Distance(2,4) == 2',\n",
              "     'assert hamming_Distance(1,2) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 22.996951832759777,\n",
              "     'tokenization_energy': 0.12495183277130127,\n",
              "     'inference_energy': 22.871999999988475,\n",
              "     'energy_per_token': 1.437309489547486,\n",
              "     'time': 0.5626258850097656,\n",
              "     'components': {'embeddings': np.float64(0.1266439733505249),\n",
              "      'attention': np.float64(17.687207517136237),\n",
              "      'ffn': np.float64(13.313868087767856),\n",
              "      'layernorm': np.float64(0.12344824051856995),\n",
              "      'output_layer': np.float64(0.27433560252189637)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to count the occurrence of a given character in a string.',\n",
              "    'ground_truth_code': 'def count(s,c) : \\r\\n    res = 0 \\r\\n    for i in range(len(s)) : \\r\\n        if (s[i] == c): \\r\\n            res = res + 1\\r\\n    return res ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of each given\\n in a given, The',\n",
              "    'test_cases': ['assert count(\"abcc\",\"c\") == 2',\n",
              "     'assert count(\"ababca\",\"a\") == 3',\n",
              "     'assert count(\"mnmm0pm\",\"m\") == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.77777782703482,\n",
              "     'tokenization_energy': 0.11977782702445985,\n",
              "     'inference_energy': 27.65800000001036,\n",
              "     'energy_per_token': 1.6339869310020483,\n",
              "     'time': 0.5565588474273682,\n",
              "     'components': {'embeddings': np.float64(0.12104578804969789),\n",
              "      'attention': np.float64(13.31626893281273),\n",
              "      'ffn': np.float64(17.891894309526425),\n",
              "      'layernorm': np.float64(4.609000000011292),\n",
              "      'output_layer': np.float64(0.22220364332199094)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the inversions of tuple elements in the given tuple list.',\n",
              "    'ground_truth_code': 'def inversion_elements(test_tup):\\r\\n  res = tuple(list(map(lambda x: ~x, list(test_tup))))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximumolution in a arrays in a array array.\\n\\n.\\n The',\n",
              "    'test_cases': ['assert inversion_elements((7, 8, 9, 1, 10, 7)) == (-8, -9, -10, -2, -11, -8)',\n",
              "     'assert inversion_elements((2, 4, 5, 6, 1, 7)) == (-3, -5, -6, -7, -2, -8)',\n",
              "     'assert inversion_elements((8, 9, 11, 14, 12, 13)) == (-9, -10, -12, -15, -13, -14)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.105829187390743,\n",
              "     'tokenization_energy': 0.11782918739318847,\n",
              "     'inference_energy': 22.987999999997555,\n",
              "     'energy_per_token': 1.2836571770772636,\n",
              "     'time': 0.5673472881317139,\n",
              "     'components': {'embeddings': np.float64(0.1263942461013794),\n",
              "      'attention': np.float64(4.726668576240539),\n",
              "      'ffn': np.float64(8.810685466047026),\n",
              "      'layernorm': np.float64(0.12367200803756714),\n",
              "      'output_layer': np.float64(0.2230802893638611)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to perform the adjacent element concatenation in the given tuples.',\n",
              "    'ground_truth_code': 'def concatenate_elements(test_tup):\\r\\n  res = tuple(i + j for i, j in zip(test_tup, test_tup[1:]))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the following swaps multiplicationation in a adjacent matrix, Given',\n",
              "    'test_cases': ['assert concatenate_elements((\"DSP \", \"IS \", \"BEST \", \"FOR \", \"ALL \", \"UTS\")) == (\\'DSP IS \\', \\'IS BEST \\', \\'BEST FOR \\', \\'FOR ALL \\', \\'ALL UTS\\')',\n",
              "     'assert concatenate_elements((\"RES \", \"IS \", \"BEST \", \"FOR \", \"ALL \", \"QESR\")) == (\\'RES IS \\', \\'IS BEST \\', \\'BEST FOR \\', \\'FOR ALL \\', \\'ALL QESR\\')',\n",
              "     'assert concatenate_elements((\"MSAM\", \"IS \", \"BEST \", \"FOR \", \"ALL \", \"SKD\")) == (\\'MSAMIS \\', \\'IS BEST \\', \\'BEST FOR \\', \\'FOR ALL \\', \\'ALL SKD\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.01471939468407,\n",
              "     'tokenization_energy': 0.1207193946838379,\n",
              "     'inference_energy': 22.894000000000233,\n",
              "     'energy_per_token': 1.4384199621677545,\n",
              "     'time': 0.5576164722442627,\n",
              "     'components': {'embeddings': np.float64(0.11962419509887695),\n",
              "      'attention': np.float64(13.423060884475362),\n",
              "      'ffn': np.float64(17.450650263548482),\n",
              "      'layernorm': np.float64(0.12301592445373535),\n",
              "      'output_layer': np.float64(0.20709093093872072)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to count the longest repeating subsequences such that the two subsequences don’t have same string characters at same positions.',\n",
              "    'ground_truth_code': 'def find_longest_repeating_subseq(str): \\r\\n\\tn = len(str) \\r\\n\\tdp = [[0 for k in range(n+1)] for l in range(n+1)] \\r\\n\\tfor i in range(1, n+1): \\r\\n\\t\\tfor j in range(1, n+1): \\r\\n\\t\\t\\tif (str[i-1] == str[j-1] and i != j): \\r\\n\\t\\t\\t\\tdp[i][j] = 1 + dp[i-1][j-1] \\r\\n\\t\\t\\telse: \\r\\n\\t\\t\\t\\tdp[i][j] = max(dp[i][j-1], dp[i-1][j]) \\r\\n\\treturn dp[n][n]',\n",
              "    'generated_code': \")\\n\\n the function that compute the number substring substringences in that the length charactersences are't overlap any characters length. the positions. So\",\n",
              "    'test_cases': ['assert find_longest_repeating_subseq(\"AABEBCDD\") == 3',\n",
              "     'assert find_longest_repeating_subseq(\"aabb\") == 2',\n",
              "     'assert find_longest_repeating_subseq(\"aab\") == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.995017526630427,\n",
              "     'tokenization_energy': 0.11901752662658692,\n",
              "     'inference_energy': 27.87600000000384,\n",
              "     'energy_per_token': 1.036852500986312,\n",
              "     'time': 0.5606105327606201,\n",
              "     'components': {'embeddings': np.float64(0.118007061958313),\n",
              "      'attention': np.float64(9.185604358431767),\n",
              "      'ffn': np.float64(8.768485082630416),\n",
              "      'layernorm': np.float64(0.12843711280822753),\n",
              "      'output_layer': np.float64(4.688000000009197)},\n",
              "     'num_tokens': 27}},\n",
              "   {'prompt': 'Write a function to check the given decimal with a precision of 2 by using regex.',\n",
              "    'ground_truth_code': 'import re\\r\\ndef is_decimal(num):\\r\\n  num_fetch = re.compile(r\"\"\"^[0-9]+(\\\\.[0-9]{1,2})?$\"\"\")\\r\\n  result = num_fetch.search(num)\\r\\n  return bool(result)',\n",
              "    'generated_code': ')\\n\\n the function that compute whether following matrix number the given of 1 decimal using a.\\n The',\n",
              "    'test_cases': [\"assert is_decimal('123.11') == True\",\n",
              "     \"assert is_decimal('0.21') == True\",\n",
              "     \"assert is_decimal('123.1214') == False\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.163190947042313,\n",
              "     'tokenization_energy': 0.14019094705581667,\n",
              "     'inference_energy': 23.022999999986496,\n",
              "     'energy_per_token': 1.219115313002227,\n",
              "     'time': 0.5559573173522949,\n",
              "     'components': {'embeddings': np.float64(0.13840686082839967),\n",
              "      'attention': np.float64(8.977308572285578),\n",
              "      'ffn': np.float64(13.204153094998329),\n",
              "      'layernorm': np.float64(0.1253162784576416),\n",
              "      'output_layer': np.float64(0.2884599361419678)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to delete the smallest element from the given heap and then insert a new item.',\n",
              "    'ground_truth_code': 'import heapq as hq\\r\\ndef heap_replace(heap,a):\\r\\n  hq.heapify(heap)\\r\\n  hq.heapreplace(heap, a)\\r\\n  return heap',\n",
              "    'generated_code': ')\\n\\n the function that compute the delete number in a smallest array.\\n return return the new element into The',\n",
              "    'test_cases': ['assert heap_replace( [25, 44, 68, 21, 39, 23, 89],21)==[21, 25, 23, 44, 39, 68, 89]',\n",
              "     'assert heap_replace([25, 44, 68, 21, 39, 23, 89],110)== [23, 25, 68, 44, 39, 110, 89]',\n",
              "     'assert heap_replace([25, 44, 68, 21, 39, 23, 89],500)==[23, 25, 68, 44, 39, 500, 89]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.968284011850717,\n",
              "     'tokenization_energy': 0.2232840118408203,\n",
              "     'inference_energy': 27.745000000009895,\n",
              "     'energy_per_token': 1.3984142005925357,\n",
              "     'time': 0.5553398132324219,\n",
              "     'components': {'embeddings': np.float64(0.11935513305664062),\n",
              "      'attention': np.float64(13.416731849913603),\n",
              "      'ffn': np.float64(17.99738288284198),\n",
              "      'layernorm': np.float64(4.536999999996624),\n",
              "      'output_layer': np.float64(0.22456532478332522)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to check that the given string contains only a certain set of characters(in this case a-z, a-z and 0-9) by using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef is_allowed_specific_char(string):\\r\\n    get_char = re.compile(r'[^a-zA-Z0-9.]')\\r\\n    string = get_char.search(string)\\r\\n    return not bool(string)\",\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given\\n is exactly digits single number of characters.\\ncluding case,-z, lowercase-z only accents certain-9, and using',\n",
              "    'test_cases': ['assert is_allowed_specific_char(\"ABCDEFabcdef123450\") == True',\n",
              "     'assert is_allowed_specific_char(\"*&%@#!}{\") == False',\n",
              "     'assert is_allowed_specific_char(\"HELLOhowareyou98765\") == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.2259198718,\n",
              "     'tokenization_energy': 0.1179198718070984,\n",
              "     'inference_energy': 23.1079999999929,\n",
              "     'energy_per_token': 0.72580999599375,\n",
              "     'time': 0.5586850643157959,\n",
              "     'components': {'embeddings': np.float64(0.11895281076431276),\n",
              "      'attention': np.float64(13.844552459242754),\n",
              "      'ffn': np.float64(17.84194348596537),\n",
              "      'layernorm': np.float64(0.12858404159545897),\n",
              "      'output_layer': np.float64(0.23546469688415525)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a python function to count numbers whose oth and nth bits are set.',\n",
              "    'ground_truth_code': 'def count_Num(n): \\r\\n    if (n == 1): \\r\\n        return 1\\r\\n    count = pow(2,n - 2) \\r\\n    return count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the in digits...\\no first digits are both in So',\n",
              "    'test_cases': ['assert count_Num(2) == 1',\n",
              "     'assert count_Num(3) == 2',\n",
              "     'assert count_Num(1) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.928163556098006,\n",
              "     'tokenization_energy': 0.12916355609893798,\n",
              "     'inference_energy': 27.79899999999907,\n",
              "     'energy_per_token': 1.6428331503587064,\n",
              "     'time': 0.5636446475982666,\n",
              "     'components': {'embeddings': np.float64(4.75800000000163),\n",
              "      'attention': np.float64(9.209537363047941),\n",
              "      'ffn': np.float64(8.640592525476125),\n",
              "      'layernorm': np.float64(0.12214674234390259),\n",
              "      'output_layer': np.float64(0.2899244418144226)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find the sum of fourth power of n natural numbers.',\n",
              "    'ground_truth_code': 'import math  \\r\\ndef fourth_Power_Sum(n): \\r\\n    sum = 0\\r\\n    for i in range(1,n+1) : \\r\\n        sum = sum + (i*i*i*i) \\r\\n    return sum',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all powers of all-th numbers.\\n\\n So',\n",
              "    'test_cases': ['assert fourth_Power_Sum(2) == 17',\n",
              "     'assert fourth_Power_Sum(4) == 354',\n",
              "     'assert fourth_Power_Sum(6) == 2275'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.62030658435903,\n",
              "     'tokenization_energy': 0.11630658435821532,\n",
              "     'inference_energy': 27.504000000000815,\n",
              "     'energy_per_token': 1.6247239167270018,\n",
              "     'time': 0.5677344799041748,\n",
              "     'components': {'embeddings': np.float64(0.11637135505676269),\n",
              "      'attention': np.float64(13.290024261222454),\n",
              "      'ffn': np.float64(13.105258492243358),\n",
              "      'layernorm': np.float64(0.12335604572296142),\n",
              "      'output_layer': np.float64(4.645999999993364)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to perform the concatenation of two string tuples.',\n",
              "    'ground_truth_code': 'def concatenate_strings(test_tup1, test_tup2):\\r\\n  res = tuple(ele1 + ele2 for ele1, ele2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the followingation of two arrays arrays in The',\n",
              "    'test_cases': ['assert concatenate_strings((\"Manjeet\", \"Nikhil\", \"Akshat\"), (\" Singh\", \" Meherwal\", \" Garg\")) == (\\'Manjeet Singh\\', \\'Nikhil Meherwal\\', \\'Akshat Garg\\')',\n",
              "     'assert concatenate_strings((\"Shaik\", \"Ayesha\", \"Sanya\"), (\" Dawood\", \" Begum\", \" Singh\")) == (\\'Shaik Dawood\\', \\'Ayesha Begum\\', \\'Sanya Singh\\')',\n",
              "     'assert concatenate_strings((\"Harpreet\", \"Priyanka\", \"Muskan\"), (\"Kour\", \" Agarwal\", \"Sethi\")) == (\\'HarpreetKour\\', \\'Priyanka Agarwal\\', \\'MuskanSethi\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.050110610257253,\n",
              "     'tokenization_energy': 0.12311061024665833,\n",
              "     'inference_energy': 22.927000000010594,\n",
              "     'energy_per_token': 1.6464364721612323,\n",
              "     'time': 0.5660130977630615,\n",
              "     'components': {'embeddings': np.float64(0.12421377229690551),\n",
              "      'attention': np.float64(13.606891393186874),\n",
              "      'ffn': np.float64(12.964124171741773),\n",
              "      'layernorm': np.float64(0.12842268753051758),\n",
              "      'output_layer': np.float64(0.21538599252700807)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to convert radians to degrees.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef degree_radian(radian):\\r\\n degree = radian*(180/math.pi)\\r\\n return degree',\n",
              "    'generated_code': ')\\n\\n the function that compute a to degrees.\\n The',\n",
              "    'test_cases': ['assert degree_radian(90)==5156.620156177409',\n",
              "     'assert degree_radian(60)==3437.746770784939',\n",
              "     'assert degree_radian(120)==6875.493541569878'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.754158056729125,\n",
              "     'tokenization_energy': 0.12715805673599243,\n",
              "     'inference_energy': 27.62699999999313,\n",
              "     'energy_per_token': 2.7754158056729126,\n",
              "     'time': 0.5643055438995361,\n",
              "     'components': {'embeddings': np.float64(4.663000000000466),\n",
              "      'attention': np.float64(13.394220492115247),\n",
              "      'ffn': np.float64(13.158321929932805),\n",
              "      'layernorm': np.float64(0.12292114019393921),\n",
              "      'output_layer': np.float64(0.2771687150001526)},\n",
              "     'num_tokens': 10}},\n",
              "   {'prompt': 'Write a function to decode a run-length encoded given list.',\n",
              "    'ground_truth_code': 'def decode_list(alist):\\r\\n    def aux(g):\\r\\n        if isinstance(g, list):\\r\\n            return [(g[1], range(g[0]))]\\r\\n        else:\\r\\n            return [(g, [0])]\\r\\n    return [x for g in alist for x, R in aux(g) for i in R]',\n",
              "    'generated_code': ')\\n\\n the function that compute a function-length encoded string string of The',\n",
              "    'test_cases': ['assert decode_list([[2, 1], 2, 3, [2, 4], 5,1])==[1,1,2,3,4,4,5,1]',\n",
              "     \"assert decode_list(['a', 'u', 't', 'o', 'm', 'a', 't', 'i', 'c', 'a', [2, 'l'], 'y'])==['a', 'u', 't', 'o', 'm', 'a', 't', 'i', 'c', 'a', 'l', 'l', 'y']\",\n",
              "     \"assert decode_list(['p', 'y', 't', 'h', 'o', 'n'])==['p', 'y', 't', 'h', 'o', 'n']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.74071640063019,\n",
              "     'tokenization_energy': 0.11771640062332153,\n",
              "     'inference_energy': 27.62300000000687,\n",
              "     'energy_per_token': 2.1339012615869377,\n",
              "     'time': 0.5754663944244385,\n",
              "     'components': {'embeddings': np.float64(0.11777084350585938),\n",
              "      'attention': np.float64(8.90605031322839),\n",
              "      'ffn': np.float64(13.554319173826022),\n",
              "      'layernorm': np.float64(0.12337846040725708),\n",
              "      'output_layer': np.float64(0.2342370958328247)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to check if a nested list is a subset of another nested list.',\n",
              "    'ground_truth_code': 'def check_subset_list(list1, list2): \\r\\n    l1, l2 = list1[0], list2[0] \\r\\n    exist = True\\r\\n    for i in list2: \\r\\n        if i not in list1: \\r\\n            exist = False\\r\\n    return exist ',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number array contains a palindrome of a list list. The',\n",
              "    'test_cases': ['assert check_subset_list([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],[[12, 18, 23, 25, 45], [7, 11, 19, 24, 28], [1, 5, 8, 18, 15, 16]])==False',\n",
              "     'assert check_subset_list([[2, 3, 1], [4, 5], [6, 8]],[[4, 5], [6, 8]])==True',\n",
              "     \"assert check_subset_list([['a', 'b'], ['e'], ['c', 'd']],[['g']])==False\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.28810216997808,\n",
              "     'tokenization_energy': 0.11710216999053955,\n",
              "     'inference_energy': 23.170999999987544,\n",
              "     'energy_per_token': 1.2937834538876711,\n",
              "     'time': 0.5572056770324707,\n",
              "     'components': {'embeddings': np.float64(0.11843424129486084),\n",
              "      'attention': np.float64(18.059585003604766),\n",
              "      'ffn': np.float64(13.438794974562711),\n",
              "      'layernorm': np.float64(0.122412034034729),\n",
              "      'output_layer': np.float64(0.2215111062526703)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to find the first repeated character in a given string.',\n",
              "    'ground_truth_code': \"def first_Repeated_Char(str): \\r\\n    h = {}\\r\\n    for ch in str:\\r\\n        if ch in h: \\r\\n            return ch;\\r\\n        else: \\r\\n            h[ch] = 0\\r\\n    return '\\\\0'\",\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence character in a string string. If',\n",
              "    'test_cases': ['assert first_Repeated_Char(\"Google\") == \"o\"',\n",
              "     'assert first_Repeated_Char(\"data\") == \"a\"',\n",
              "     'assert first_Repeated_Char(\"python\") == \\'\\\\0\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.74342124391871,\n",
              "     'tokenization_energy': 0.1454212439060211,\n",
              "     'inference_energy': 27.59800000001269,\n",
              "     'energy_per_token': 1.7339638277449194,\n",
              "     'time': 0.5600643157958984,\n",
              "     'components': {'embeddings': np.float64(4.644000000000233),\n",
              "      'attention': np.float64(17.703916066656006),\n",
              "      'ffn': np.float64(13.011611397030993),\n",
              "      'layernorm': np.float64(0.1233373634815216),\n",
              "      'output_layer': np.float64(0.20954006695747376)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find the minimum operations required to make two numbers equal.',\n",
              "    'ground_truth_code': 'import math   \\r\\ndef min_Operations(A,B):  \\r\\n    if (A > B): \\r\\n        swap(A,B)  \\r\\n    B = B // math.gcd(A,B);  \\r\\n    return B - 1',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number to to make the numbers... using The',\n",
              "    'test_cases': ['assert min_Operations(2,4) == 1',\n",
              "     'assert min_Operations(4,10) == 4',\n",
              "     'assert min_Operations(1,4) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.343793413391918,\n",
              "     'tokenization_energy': 0.11879341340065003,\n",
              "     'inference_energy': 23.22499999999127,\n",
              "     'energy_per_token': 1.3731643184348188,\n",
              "     'time': 0.5588147640228271,\n",
              "     'components': {'embeddings': np.float64(0.12144037461280822),\n",
              "      'attention': np.float64(4.622077592849731),\n",
              "      'ffn': np.float64(8.896903523678425),\n",
              "      'layernorm': np.float64(0.12393983316421509),\n",
              "      'output_layer': np.float64(0.22788866472244262)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to extract maximum and minimum k elements in the given tuple.',\n",
              "    'ground_truth_code': '\\r\\ndef extract_min_max(test_tup, K):\\r\\n  res = []\\r\\n  test_tup = list(test_tup)\\r\\n  temp = sorted(test_tup)\\r\\n  for idx, val in enumerate(temp):\\r\\n    if idx < K or idx >= len(temp) - K:\\r\\n      res.append(val)\\r\\n  res = tuple(res)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the number minimum values values from a function matrix of The',\n",
              "    'test_cases': ['assert extract_min_max((5, 20, 3, 7, 6, 8), 2) == (3, 5, 8, 20)',\n",
              "     'assert extract_min_max((4, 5, 6, 1, 2, 7), 3) == (1, 2, 4, 5, 6, 7)',\n",
              "     'assert extract_min_max((2, 3, 4, 8, 9, 11, 7), 4) == (2, 3, 4, 7, 8, 9, 11)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.26587980700249,\n",
              "     'tokenization_energy': 0.12387980699539185,\n",
              "     'inference_energy': 23.1420000000071,\n",
              "     'energy_per_token': 1.4541174879376557,\n",
              "     'time': 0.5613114833831787,\n",
              "     'components': {'embeddings': np.float64(0.12669024229049683),\n",
              "      'attention': np.float64(13.53959372330166),\n",
              "      'ffn': np.float64(8.78644544600393),\n",
              "      'layernorm': np.float64(0.12371056985855101),\n",
              "      'output_layer': np.float64(0.21066092014312743)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to replace maximum n occurrences of spaces, commas, or dots with a colon.',\n",
              "    'ground_truth_code': 'import re\\r\\ndef replace_max_specialchar(text,n):\\r\\n return (re.sub(\"[ ,.]\", \":\", text, n))',\n",
              "    'generated_code': ')\\n\\n the function that compute alls of of a in but, or periods in a single, The',\n",
              "    'test_cases': [\"assert replace_max_specialchar('Python language, Programming language.',2)==('Python:language: Programming language.')\",\n",
              "     \"assert replace_max_specialchar('a b c,d e f',3)==('a:b:c:d e f')\",\n",
              "     \"assert replace_max_specialchar('ram reshma,ram rahim',1)==('ram:reshma,ram rahim')\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.77557060550456,\n",
              "     'tokenization_energy': 0.11957060551643371,\n",
              "     'inference_energy': 27.655999999988126,\n",
              "     'energy_per_token': 1.388778530275228,\n",
              "     'time': 0.5607259273529053,\n",
              "     'components': {'embeddings': np.float64(0.12076930832862853),\n",
              "      'attention': np.float64(9.005950073013548),\n",
              "      'ffn': np.float64(17.85251209734089),\n",
              "      'layernorm': np.float64(0.18899830532073975),\n",
              "      'output_layer': np.float64(0.2292147614955902)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to find the first even number in a given list of numbers.',\n",
              "    'ground_truth_code': 'def first_even(nums):\\r\\n    first_even = next((el for el in nums if el%2==0),-1)\\r\\n    return first_even',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence number in a list string of numbers.\\n If',\n",
              "    'test_cases': ['assert first_even ([1, 3, 5, 7, 4, 1, 6, 8]) == 4',\n",
              "     'assert first_even([2, 3, 4]) == 2',\n",
              "     'assert first_even([5, 6, 7]) == 6'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.367974146369146,\n",
              "     'tokenization_energy': 0.12097414636611938,\n",
              "     'inference_energy': 23.247000000003027,\n",
              "     'energy_per_token': 1.298220785909397,\n",
              "     'time': 0.5588607788085938,\n",
              "     'components': {'embeddings': np.float64(0.1204141845703125),\n",
              "      'attention': np.float64(13.567334059718533),\n",
              "      'ffn': np.float64(13.370567496299511),\n",
              "      'layernorm': np.float64(0.12021991682052613),\n",
              "      'output_layer': np.float64(0.22108220672607423)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to check if all the elements in tuple have same data type or not.',\n",
              "    'ground_truth_code': 'def check_type(test_tuple):\\r\\n  res = True\\r\\n  for ele in test_tuple:\\r\\n    if not isinstance(ele, type(test_tuple[0])):\\r\\n      res = False\\r\\n      break\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a the digits in a t the frequency type.\\n not. The',\n",
              "    'test_cases': ['assert check_type((5, 6, 7, 3, 5, 6) ) == True',\n",
              "     'assert check_type((1, 2, \"4\") ) == False',\n",
              "     'assert check_type((3, 2, 1, 4, 5) ) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.921681007381295,\n",
              "     'tokenization_energy': 0.1196810073852539,\n",
              "     'inference_energy': 27.801999999996042,\n",
              "     'energy_per_token': 1.4695621582832261,\n",
              "     'time': 0.556476354598999,\n",
              "     'components': {'embeddings': np.float64(4.736000000004424),\n",
              "      'attention': np.float64(17.860675329426307),\n",
              "      'ffn': np.float64(13.199204647791571),\n",
              "      'layernorm': np.float64(0.12248442554473878),\n",
              "      'output_layer': np.float64(0.22336356592178344)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to check for majority element in the given sorted array.',\n",
              "    'ground_truth_code': 'def is_majority(arr, n, x):\\r\\n\\ti = binary_search(arr, 0, n-1, x)\\r\\n\\tif i == -1:\\r\\n\\t\\treturn False\\r\\n\\tif ((i + n//2) <= (n -1)) and arr[i + n//2] == x:\\r\\n\\t\\treturn True\\r\\n\\telse:\\r\\n\\t\\treturn False\\r\\ndef binary_search(arr, low, high, x):\\r\\n\\tif high >= low:\\r\\n\\t\\tmid = (low + high)//2 \\r\\n\\t\\tif (mid == 0 or x > arr[mid-1]) and (arr[mid] == x):\\r\\n\\t\\t\\treturn mid\\r\\n\\t\\telif x > arr[mid]:\\r\\n\\t\\t\\treturn binary_search(arr, (mid + 1), high, x)\\r\\n\\t\\telse:\\r\\n\\t\\t\\treturn binary_search(arr, low, (mid -1), x)\\r\\n\\treturn -1',\n",
              "    'generated_code': ')\\n\\n the function that compute whether the of in a array array array.\\n The',\n",
              "    'test_cases': ['assert is_majority([1, 2, 3, 3, 3, 3, 10], 7, 3) == True',\n",
              "     'assert is_majority([1, 1, 2, 4, 4, 4, 6, 6], 8, 4) == False',\n",
              "     'assert is_majority([1, 1, 1, 2, 2], 5, 1) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.092366020204615,\n",
              "     'tokenization_energy': 0.11836602020263672,\n",
              "     'inference_energy': 22.97400000000198,\n",
              "     'energy_per_token': 1.539491068013641,\n",
              "     'time': 0.5597918033599854,\n",
              "     'components': {'embeddings': np.float64(0.17752723979949953),\n",
              "      'attention': np.float64(13.299101825720863),\n",
              "      'ffn': np.float64(8.727367987155215),\n",
              "      'layernorm': np.float64(0.12200001525878906),\n",
              "      'output_layer': np.float64(0.21035455322265623)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to count set bits of a given number.',\n",
              "    'ground_truth_code': 'def count_Set_Bits(n): \\r\\n    count = 0\\r\\n    while (n): \\r\\n        count += n & 1\\r\\n        n >>= 1\\r\\n    return count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the bits in a number integer.\\n The',\n",
              "    'test_cases': ['assert count_Set_Bits(2) == 1',\n",
              "     'assert count_Set_Bits(4) == 1',\n",
              "     'assert count_Set_Bits(6) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.184867136479937,\n",
              "     'tokenization_energy': 0.12386713647842408,\n",
              "     'inference_energy': 23.061000000001513,\n",
              "     'energy_per_token': 1.6560619383199955,\n",
              "     'time': 0.5581483840942383,\n",
              "     'components': {'embeddings': np.float64(0.18808511590957644),\n",
              "      'attention': np.float64(17.903356399786425),\n",
              "      'ffn': np.float64(13.09078995798982),\n",
              "      'layernorm': np.float64(0.1254254174232483),\n",
              "      'output_layer': np.float64(0.2134124050140381)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the minimum element in a sorted and rotated array.',\n",
              "    'ground_truth_code': 'def find_Min(arr,low,high): \\r\\n    while (low < high): \\r\\n        mid = low + (high - low) // 2;   \\r\\n        if (arr[mid] == arr[high]): \\r\\n            high -= 1; \\r\\n        elif (arr[mid] > arr[high]): \\r\\n            low = mid + 1; \\r\\n        else: \\r\\n            high = mid; \\r\\n    return arr[high]; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number in a matrix matrix strictly array. The',\n",
              "    'test_cases': ['assert find_Min([1,2,3,4,5],0,4) == 1',\n",
              "     'assert find_Min([4,6,8],0,2) == 4',\n",
              "     'assert find_Min([2,3,5,7,9],0,4) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.86537278747093,\n",
              "     'tokenization_energy': 0.12037278747558594,\n",
              "     'inference_energy': 27.744999999995343,\n",
              "     'energy_per_token': 1.639139575733584,\n",
              "     'time': 0.5532627105712891,\n",
              "     'components': {'embeddings': np.float64(0.1827071053981781),\n",
              "      'attention': np.float64(18.127353921174777),\n",
              "      'ffn': np.float64(13.180944100855383),\n",
              "      'layernorm': np.float64(0.12450077867507935),\n",
              "      'output_layer': np.float64(4.627999999996973)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to remove the characters which have odd index values of a given string.',\n",
              "    'ground_truth_code': 'def odd_values_string(str):\\r\\n  result = \"\" \\r\\n  for i in range(len(str)):\\r\\n    if i % 2 == 0:\\r\\n      result = result + str[i]\\r\\n  return result',\n",
              "    'generated_code': ')\\n\\n the function function that compute all duplicate from are the numbers in in a given string.\\n So',\n",
              "    'test_cases': [\"assert odd_values_string('abcdef') == 'ace'\",\n",
              "     \"assert odd_values_string('python') == 'pto'\",\n",
              "     \"assert odd_values_string('data') == 'dt'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.296211026193806,\n",
              "     'tokenization_energy': 0.12521102619171143,\n",
              "     'inference_energy': 23.171000000002095,\n",
              "     'energy_per_token': 1.226116369799674,\n",
              "     'time': 0.5551743507385254,\n",
              "     'components': {'embeddings': np.float64(0.12366845560073852),\n",
              "      'attention': np.float64(13.710112890008718),\n",
              "      'ffn': np.float64(13.526023006206495),\n",
              "      'layernorm': np.float64(0.12175511360168458),\n",
              "      'output_layer': np.float64(0.2841024661064148)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find minimum of three numbers.',\n",
              "    'ground_truth_code': 'def min_of_three(a,b,c): \\r\\n      if (a <= b) and (a <= c): \\r\\n        smallest = a \\r\\n      elif (b <= a) and (b <= c): \\r\\n        smallest = b \\r\\n      else: \\r\\n        smallest = c \\r\\n      return smallest ',\n",
              "    'generated_code': ')\\n\\n the function that compute the of a numbers.\\n But',\n",
              "    'test_cases': ['assert min_of_three(10,20,0)==0',\n",
              "     'assert min_of_three(19,15,18)==15',\n",
              "     'assert min_of_three(-10,-20,-30)==-30'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.905381268748897,\n",
              "     'tokenization_energy': 0.21738126873970032,\n",
              "     'inference_energy': 27.688000000009197,\n",
              "     'energy_per_token': 2.536852842613536,\n",
              "     'time': 0.5588319301605225,\n",
              "     'components': {'embeddings': np.float64(0.12103140950202942),\n",
              "      'attention': np.float64(13.288932526100426),\n",
              "      'ffn': np.float64(13.047958838477848),\n",
              "      'layernorm': np.float64(0.12381364631652832),\n",
              "      'output_layer': np.float64(0.26279348373413086)},\n",
              "     'num_tokens': 11}},\n",
              "   {'prompt': 'Write a python function to check whether all the bits are unset in the given range or not.',\n",
              "    'ground_truth_code': 'def all_Bits_Set_In_The_Given_Range(n,l,r):  \\r\\n    num = (((1 << r) - 1) ^ ((1 << (l - 1)) - 1)) \\r\\n    new_num = n & num\\r\\n    if (new_num == 0): \\r\\n        return True\\r\\n    return False',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a the elements in set in a array integer of not. So',\n",
              "    'test_cases': ['assert all_Bits_Set_In_The_Given_Range(4,1,2) == True',\n",
              "     'assert all_Bits_Set_In_The_Given_Range(17,2,4) == True',\n",
              "     'assert all_Bits_Set_In_The_Given_Range(39,4,6) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.310404874790226,\n",
              "     'tokenization_energy': 0.11640487480163575,\n",
              "     'inference_energy': 23.19399999998859,\n",
              "     'energy_per_token': 1.1655202437395114,\n",
              "     'time': 0.5678768157958984,\n",
              "     'components': {'embeddings': np.float64(0.11618696975708008),\n",
              "      'attention': np.float64(13.729523547408869),\n",
              "      'ffn': np.float64(13.280032886254018),\n",
              "      'layernorm': np.float64(0.1292685785293579),\n",
              "      'output_layer': np.float64(0.22992387342453002)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to re-arrange the elements of the given array so that all negative elements appear before positive ones.',\n",
              "    'ground_truth_code': 'def re_arrange_array(arr, n):\\r\\n  j=0\\r\\n  for i in range(0, n):\\r\\n    if (arr[i] < 0):\\r\\n      temp = arr[i]\\r\\n      arr[i] = arr[j]\\r\\n      arr[j] = temp\\r\\n      j = j + 1\\r\\n  return arr',\n",
              "    'generated_code': ')\\n\\n the function that computeorganconvertange the digits of the elements matrix in that the the elements are before all elements. The',\n",
              "    'test_cases': ['assert re_arrange_array([-1, 2, -3, 4, 5, 6, -7, 8, 9], 9) == [-1, -3, -7, 4, 5, 6, 2, 8, 9]',\n",
              "     'assert re_arrange_array([12, -14, -26, 13, 15], 5) == [-14, -26, 12, 13, 15]',\n",
              "     'assert re_arrange_array([10, 24, 36, -42, -39, -78, 85], 7) == [-42, -39, -78, 10, 24, 36, 85]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.27051164889976,\n",
              "     'tokenization_energy': 0.18551164889335633,\n",
              "     'inference_energy': 23.085000000006403,\n",
              "     'energy_per_token': 0.9308204659559904,\n",
              "     'time': 0.5951426029205322,\n",
              "     'components': {'embeddings': np.float64(0.12485783123970032),\n",
              "      'attention': np.float64(18.589030598643237),\n",
              "      'ffn': np.float64(4.148156290531158),\n",
              "      'layernorm': np.float64(0.12839417219161986),\n",
              "      'output_layer': np.float64(0.2272609462738037)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a function to replace blank spaces with any character in a string.',\n",
              "    'ground_truth_code': \"def replace_blank(str1,char):\\r\\n str2 = str1.replace(' ', char)\\r\\n return str2\",\n",
              "    'generated_code': ')\\n\\n the function that compute all spaces in their integer in a binary. But',\n",
              "    'test_cases': ['assert replace_blank(\"hello people\",\\'@\\')==(\"hello@people\")',\n",
              "     'assert replace_blank(\"python program language\",\\'$\\')==(\"python$program$language\")',\n",
              "     'assert replace_blank(\"blank space\",\"-\")==(\"blank-space\")'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.75100000000384,\n",
              "     'tokenization_energy': 4.760999999998603,\n",
              "     'inference_energy': 22.99000000000524,\n",
              "     'energy_per_token': 1.8500666666669228,\n",
              "     'time': 0.5924966335296631,\n",
              "     'components': {'embeddings': np.float64(0.12387846684455872),\n",
              "      'attention': np.float64(9.74161156892276),\n",
              "      'ffn': np.float64(18.35475510311767),\n",
              "      'layernorm': np.float64(0.13771844148635864),\n",
              "      'output_layer': np.float64(0.22081634855270388)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the maximum sum in the given right triangle of numbers.',\n",
              "    'ground_truth_code': 'def max_sum(tri, n): \\r\\n\\tif n > 1: \\r\\n\\t\\ttri[1][1] = tri[1][1]+tri[0][0] \\r\\n\\t\\ttri[1][0] = tri[1][0]+tri[0][0] \\r\\n\\tfor i in range(2, n): \\r\\n\\t\\ttri[i][0] = tri[i][0] + tri[i-1][0] \\r\\n\\t\\ttri[i][i] = tri[i][i] + tri[i-1][i-1] \\r\\n\\t\\tfor j in range(1, i): \\r\\n\\t\\t\\tif tri[i][j]+tri[i-1][j-1] >= tri[i][j]+tri[i-1][j]: \\r\\n\\t\\t\\t\\ttri[i][j] = tri[i][j] + tri[i-1][j-1] \\r\\n\\t\\t\\telse: \\r\\n\\t\\t\\t\\ttri[i][j] = tri[i][j]+tri[i-1][j] \\r\\n\\treturn (max(tri[n-1]))',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of a matrix matrix...\\n array integers, Each',\n",
              "    'test_cases': ['assert max_sum([[1], [2,1], [3,3,2]], 3) == 6',\n",
              "     'assert max_sum([[1], [1, 2], [4, 1, 12]], 3) == 15 ',\n",
              "     'assert max_sum([[2], [3,2], [13,23,12]], 3) == 28'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.0651003136551,\n",
              "     'tokenization_energy': 0.12410031366348268,\n",
              "     'inference_energy': 22.940999999991618,\n",
              "     'energy_per_token': 1.3567706066855942,\n",
              "     'time': 0.6085362434387207,\n",
              "     'components': {'embeddings': np.float64(0.13545148372650145),\n",
              "      'attention': np.float64(28.805178069583143),\n",
              "      'ffn': np.float64(4.066261194705962),\n",
              "      'layernorm': np.float64(0.12654010772705077),\n",
              "      'output_layer': np.float64(0.22827659988403318)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to get the n largest items from a dataset.',\n",
              "    'ground_truth_code': 'import heapq\\r\\ndef larg_nnum(list1,n):\\r\\n largest=heapq.nlargest(n,list1)\\r\\n return largest',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-th\\n in a list, The',\n",
              "    'test_cases': ['assert larg_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, 80, 100],2)==[100,90]',\n",
              "     'assert larg_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, 80, 100],5)==[100,90,80,70,60]',\n",
              "     'assert larg_nnum([10, 20, 50, 70, 90, 20, 50, 40, 60, 80, 100],3)==[100,90,80]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.07657790899067,\n",
              "     'tokenization_energy': 0.12257790899276734,\n",
              "     'inference_energy': 22.953999999997905,\n",
              "     'energy_per_token': 1.6483269934993336,\n",
              "     'time': 0.6005859375,\n",
              "     'components': {'embeddings': np.float64(0.23057456588745118),\n",
              "      'attention': np.float64(13.935888590102318),\n",
              "      'ffn': np.float64(13.661330181831264),\n",
              "      'layernorm': np.float64(0.18413230085372925),\n",
              "      'output_layer': np.float64(0.21230755472183227)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find the lateral surface area of a cylinder.',\n",
              "    'ground_truth_code': 'def lateralsuface_cylinder(r,h):\\r\\n  lateralsurface= 2*3.1415*r*h\\r\\n  return lateralsurface',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum surface area of a cube.\\n The',\n",
              "    'test_cases': ['assert lateralsuface_cylinder(10,5)==314.15000000000003',\n",
              "     'assert lateralsuface_cylinder(4,5)==125.66000000000001',\n",
              "     'assert lateralsuface_cylinder(4,10)==251.32000000000002'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.16472897624469,\n",
              "     'tokenization_energy': 0.13572897624969482,\n",
              "     'inference_energy': 23.028999999994994,\n",
              "     'energy_per_token': 1.654623498303192,\n",
              "     'time': 0.5987555980682373,\n",
              "     'components': {'embeddings': np.float64(0.189990128993988),\n",
              "      'attention': np.float64(9.69275104974408),\n",
              "      'ffn': np.float64(9.022979393959627),\n",
              "      'layernorm': np.float64(0.18412328481674195),\n",
              "      'output_layer': np.float64(0.2611923706531525)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find the volume of a cube.',\n",
              "    'ground_truth_code': 'def volume_cube(l):\\r\\n  volume = l * l * l\\r\\n  return volume',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a cube.\\n The',\n",
              "    'test_cases': ['assert volume_cube(3)==27',\n",
              "     'assert volume_cube(2)==8',\n",
              "     'assert volume_cube(5)==125'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.691759346957436,\n",
              "     'tokenization_energy': 0.1247593469619751,\n",
              "     'inference_energy': 27.56699999999546,\n",
              "     'energy_per_token': 2.307646612246453,\n",
              "     'time': 0.6065680980682373,\n",
              "     'components': {'embeddings': np.float64(0.183456130027771),\n",
              "      'attention': np.float64(9.949425096752705),\n",
              "      'ffn': np.float64(13.739196488609654),\n",
              "      'layernorm': np.float64(0.16667127394676207),\n",
              "      'output_layer': np.float64(4.649999999994179)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to set all even bits of a given number.',\n",
              "    'ground_truth_code': 'def even_bit_set_number(n): \\r\\n    count = 0;res = 0;temp = n \\r\\n    while(temp > 0): \\r\\n        if (count % 2 == 1): \\r\\n            res |= (1 << count)\\r\\n        count+=1\\r\\n        temp >>= 1\\r\\n    return (n | res) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the the numbers to a number integer to The',\n",
              "    'test_cases': ['assert even_bit_set_number(10) == 10',\n",
              "     'assert even_bit_set_number(20) == 30',\n",
              "     'assert even_bit_set_number(30) == 30'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 27.90692033577757,\n",
              "     'tokenization_energy': 0.13592033576965332,\n",
              "     'inference_energy': 27.771000000007916,\n",
              "     'energy_per_token': 1.8604613557185048,\n",
              "     'time': 0.5986435413360596,\n",
              "     'components': {'embeddings': np.float64(0.139331561088562),\n",
              "      'attention': np.float64(5.271099013328552),\n",
              "      'ffn': np.float64(18.279092554802073),\n",
              "      'layernorm': np.float64(0.2085937659740448),\n",
              "      'output_layer': np.float64(4.605000000010477)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to count the maximum number of equilateral triangles that can be formed within a given equilateral triangle.',\n",
              "    'ground_truth_code': 'def No_of_Triangle(N,K):\\r\\n    if (N < K):\\r\\n        return -1;\\r\\n    else:\\r\\n        Tri_up = 0;\\r\\n        Tri_up = ((N - K + 1) *(N - K + 2)) // 2;\\r\\n        Tri_down = 0;\\r\\n        Tri_down = ((N - 2 * K + 1) *(N - 2 * K + 2)) // 2;\\r\\n        return Tri_up + Tri_down;',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number of consecutiveilateral triangles in can be formed by a given nilateral triangle, The',\n",
              "    'test_cases': ['assert No_of_Triangle(4,2) == 7',\n",
              "     'assert No_of_Triangle(4,3) == 3',\n",
              "     'assert No_of_Triangle(1,3) == -1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.32212651276053,\n",
              "     'tokenization_energy': 0.13412651276588441,\n",
              "     'inference_energy': 23.187999999994645,\n",
              "     'energy_per_token': 0.9328850605104212,\n",
              "     'time': 0.5868263244628906,\n",
              "     'components': {'embeddings': np.float64(0.1528916072845459),\n",
              "      'attention': np.float64(9.680257513046849),\n",
              "      'ffn': np.float64(13.62147489977232),\n",
              "      'layernorm': np.float64(0.12467655515670777),\n",
              "      'output_layer': np.float64(0.22732408475875854)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a function to check the occurrences of records which occur similar times in the given tuples.',\n",
              "    'ground_truth_code': 'from collections import Counter \\r\\ndef check_occurences(test_list):\\r\\n  res = dict(Counter(tuple(ele) for ele in map(sorted, test_list)))\\r\\n  return  (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute whether following of a in are exactly to in a records array. The',\n",
              "    'test_cases': ['assert check_occurences([(3, 1), (1, 3), (2, 5), (5, 2), (6, 3)] ) == {(1, 3): 2, (2, 5): 2, (3, 6): 1}',\n",
              "     'assert check_occurences([(4, 2), (2, 4), (3, 6), (6, 3), (7, 4)] ) == {(2, 4): 2, (3, 6): 2, (4, 7): 1}',\n",
              "     'assert check_occurences([(13, 2), (11, 23), (12, 25), (25, 12), (16, 23)] ) == {(2, 13): 1, (11, 23): 1, (12, 25): 2, (16, 23): 1}'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.36496744966379,\n",
              "     'tokenization_energy': 0.1569674496650696,\n",
              "     'inference_energy': 23.20799999999872,\n",
              "     'energy_per_token': 1.2297351289296732,\n",
              "     'time': 0.559607744216919,\n",
              "     'components': {'embeddings': np.float64(0.1237702329158783),\n",
              "      'attention': np.float64(18.02914104677504),\n",
              "      'ffn': np.float64(13.219905464873767),\n",
              "      'layernorm': np.float64(0.12890930557250976),\n",
              "      'output_layer': np.float64(0.23262187671661375)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to count number of non-empty substrings of a given string.',\n",
              "    'ground_truth_code': 'def number_of_substrings(str): \\r\\n\\tstr_len = len(str); \\r\\n\\treturn int(str_len * (str_len + 1) / 2); ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the of valid-over subsetsings of a given string s The',\n",
              "    'test_cases': ['assert number_of_substrings(\"abc\") == 6',\n",
              "     'assert number_of_substrings(\"abcd\") == 10',\n",
              "     'assert number_of_substrings(\"abcde\") == 15'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.18363847112807,\n",
              "     'tokenization_energy': 0.12263847112655639,\n",
              "     'inference_energy': 28.061000000001513,\n",
              "     'energy_per_token': 1.5657576928404484,\n",
              "     'time': 0.5599980354309082,\n",
              "     'components': {'embeddings': np.float64(0.1228766040802002),\n",
              "      'attention': np.float64(13.753063073641504),\n",
              "      'ffn': np.float64(17.688325475443975),\n",
              "      'layernorm': np.float64(0.12976765727996825),\n",
              "      'output_layer': np.float64(0.2556935021877289)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the number of possible sequences of length n such that each of the next element is greater than or equal to twice of the previous element but less than or equal to m.',\n",
              "    'ground_truth_code': 'def get_total_number_of_sequences(m,n): \\r\\n\\tT=[[0 for i in range(n+1)] for i in range(m+1)] \\r\\n\\tfor i in range(m+1): \\r\\n\\t\\tfor j in range(n+1): \\r\\n\\t\\t\\tif i==0 or j==0: \\r\\n\\t\\t\\t\\tT[i][j]=0\\r\\n\\t\\t\\telif i<j: \\r\\n\\t\\t\\t\\tT[i][j]=0\\r\\n\\t\\t\\telif j==1: \\r\\n\\t\\t\\t\\tT[i][j]=i \\r\\n\\t\\t\\telse: \\r\\n\\t\\t\\t\\tT[i][j]=T[i-1][j]+T[i//2][j-1] \\r\\n\\treturn T[m][n]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of unique triangles of length n, that each element the...\\n...\\n is either than the equal to the the the previous element.',\n",
              "    'test_cases': ['assert get_total_number_of_sequences(10, 4) == 4',\n",
              "     'assert get_total_number_of_sequences(5, 2) == 6',\n",
              "     'assert get_total_number_of_sequences(16, 3) == 84'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.43693404817127,\n",
              "     'tokenization_energy': 0.11993404817581177,\n",
              "     'inference_energy': 23.31699999999546,\n",
              "     'energy_per_token': 0.7324041890053522,\n",
              "     'time': 0.5590384006500244,\n",
              "     'components': {'embeddings': np.float64(0.12099353623390198),\n",
              "      'attention': np.float64(18.076531960230554),\n",
              "      'ffn': np.float64(13.306471303476837),\n",
              "      'layernorm': np.float64(0.1271367073059082),\n",
              "      'output_layer': np.float64(0.23113936185836792)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a function to replace the last element of the list with another list.',\n",
              "    'ground_truth_code': 'def replace_list(list1,list2):\\r\\n list1[-1:] = list2\\r\\n replace_list=list1\\r\\n return replace_list\\r\\n',\n",
              "    'generated_code': ')\\n\\n the function that compute all digits digit of a last with the element.\\n The',\n",
              "    'test_cases': ['assert replace_list([1, 3, 5, 7, 9, 10],[2, 4, 6, 8])==[1, 3, 5, 7, 9, 2, 4, 6, 8]',\n",
              "     'assert replace_list([1,2,3,4,5],[5,6,7,8])==[1,2,3,4,5,6,7,8]',\n",
              "     'assert replace_list([\"red\",\"blue\",\"green\"],[\"yellow\"])==[\"red\",\"blue\",\"yellow\"]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.05428637933801,\n",
              "     'tokenization_energy': 0.12228637933731079,\n",
              "     'inference_energy': 27.9320000000007,\n",
              "     'energy_per_token': 1.7533928987086256,\n",
              "     'time': 0.5647232532501221,\n",
              "     'components': {'embeddings': np.float64(0.12021884322166443),\n",
              "      'attention': np.float64(9.300653574696975),\n",
              "      'ffn': np.float64(8.688809993746226),\n",
              "      'layernorm': np.float64(0.1279194715023041),\n",
              "      'output_layer': np.float64(0.21459684228897097)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': \"Write a function to generate a 3d array having each element as '*'.\",\n",
              "    'ground_truth_code': \"def array_3d(m,n,o):\\r\\n array_3d = [[ ['*' for col in range(m)] for col in range(n)] for row in range(o)]\\r\\n return array_3d\",\n",
              "    'generated_code': \")\\n\\n the function that compute a matrix {x array of the element in a'. The\",\n",
              "    'test_cases': [\"assert array_3d(6,4,3)==[[['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*']], [['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*']], [['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*', '*']]]\",\n",
              "     \"assert array_3d(5,3,4)==[[['*', '*', '*', '*', '*'], ['*', '*', '*', '*','*'], ['*', '*', '*', '*', '*']], [['*', '*', '*', '*', '*'],['*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*']], [['*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*']], [['*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*'], ['*', '*', '*', '*', '*']]]\",\n",
              "     \"assert array_3d(1,2,3)==[[['*'],['*']],[['*'],['*']],[['*'],['*']]]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.191812216292718,\n",
              "     'tokenization_energy': 0.12081221628189087,\n",
              "     'inference_energy': 28.071000000010827,\n",
              "     'energy_per_token': 1.6583418950760422,\n",
              "     'time': 0.5618414878845215,\n",
              "     'components': {'embeddings': np.float64(0.18117383456230166),\n",
              "      'attention': np.float64(13.516389891389526),\n",
              "      'ffn': np.float64(13.333032671198714),\n",
              "      'layernorm': np.float64(0.1433688132762909),\n",
              "      'output_layer': np.float64(0.22776503920555116)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to count total characters in a string.',\n",
              "    'ground_truth_code': 'def count_charac(str1):\\r\\n total = 0\\r\\n for i in str1:\\r\\n    total = total + 1\\r\\n return total',\n",
              "    'generated_code': ')\\n\\n the function that compute the number in a string, But',\n",
              "    'test_cases': ['assert count_charac(\"python programming\")==18',\n",
              "     'assert count_charac(\"language\")==8',\n",
              "     'assert count_charac(\"words\")==5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.412732949252707,\n",
              "     'tokenization_energy': 0.129732949256897,\n",
              "     'inference_energy': 23.28299999999581,\n",
              "     'energy_per_token': 1.9510610791043923,\n",
              "     'time': 0.561265230178833,\n",
              "     'components': {'embeddings': np.float64(0.1310679225921631),\n",
              "      'attention': np.float64(13.801393478638376),\n",
              "      'ffn': np.float64(8.785508760448893),\n",
              "      'layernorm': np.float64(0.12605151891708374),\n",
              "      'output_layer': np.float64(0.21511503219604494)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to sort the given list based on the occurrence of first element of tuples.',\n",
              "    'ground_truth_code': 'def sort_on_occurence(lst): \\r\\n\\tdct = {} \\r\\n\\tfor i, j in lst: \\r\\n\\t\\tdct.setdefault(i, []).append(j) \\r\\n\\treturn ([(i, *dict.fromkeys(j), len(j)) \\r\\n\\t\\t\\t\\tfor i, j in dct.items()]) ',\n",
              "    'generated_code': ')\\n\\n the function that compute a sorted matrix of on the given of the\\n in each in So',\n",
              "    'test_cases': [\"assert sort_on_occurence([(1, 'Jake'), (2, 'Bob'), (1, 'Cara')]) == [(1, 'Jake', 'Cara', 2), (2, 'Bob', 1)]\",\n",
              "     \"assert sort_on_occurence([('b', 'ball'), ('a', 'arm'), ('b', 'b'), ('a', 'ant')]) == [('b', 'ball', 'b', 2), ('a', 'arm', 'ant', 2)]\",\n",
              "     \"assert sort_on_occurence([(2, 'Mark'), (3, 'Maze'), (2, 'Sara')]) == [(2, 'Mark', 'Sara', 2), (3, 'Maze', 1)]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.111645126821823,\n",
              "     'tokenization_energy': 0.1186451268196106,\n",
              "     'inference_energy': 27.993000000002212,\n",
              "     'energy_per_token': 1.4795602698327275,\n",
              "     'time': 0.5638108253479004,\n",
              "     'components': {'embeddings': np.float64(0.13784240722656252),\n",
              "      'attention': np.float64(13.68782943391276),\n",
              "      'ffn': np.float64(13.270431122787064),\n",
              "      'layernorm': np.float64(0.12768180656433106),\n",
              "      'output_layer': np.float64(0.23283286094665526)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to find the next perfect square greater than a given number.',\n",
              "    'ground_truth_code': 'import math  \\r\\ndef next_Perfect_Square(N): \\r\\n    nextN = math.floor(math.sqrt(N)) + 1\\r\\n    return nextN * nextN ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number prime square after than or given integer n The',\n",
              "    'test_cases': ['assert next_Perfect_Square(35) == 36',\n",
              "     'assert next_Perfect_Square(6) == 9',\n",
              "     'assert next_Perfect_Square(9) == 16'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.620710676193703,\n",
              "     'tokenization_energy': 0.2077106761932373,\n",
              "     'inference_energy': 23.413000000000466,\n",
              "     'energy_per_token': 1.389453569187865,\n",
              "     'time': 0.556088924407959,\n",
              "     'components': {'embeddings': np.float64(0.12248762512207031),\n",
              "      'attention': np.float64(4.597202942371369),\n",
              "      'ffn': np.float64(4.410467098712921),\n",
              "      'layernorm': np.float64(0.12777366614341737),\n",
              "      'output_layer': np.float64(0.22736834764480593)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the maximum sum of bi-tonic sub-sequence for the given array.',\n",
              "    'ground_truth_code': 'def max_sum(arr, n): \\r\\n\\tMSIBS = arr[:] \\r\\n\\tfor i in range(n): \\r\\n\\t\\tfor j in range(0, i): \\r\\n\\t\\t\\tif arr[i] > arr[j] and MSIBS[i] < MSIBS[j] + arr[i]: \\r\\n\\t\\t\\t\\tMSIBS[i] = MSIBS[j] + arr[i] \\r\\n\\tMSDBS = arr[:] \\r\\n\\tfor i in range(1, n + 1): \\r\\n\\t\\tfor j in range(1, i): \\r\\n\\t\\t\\tif arr[-i] > arr[-j] and MSDBS[-i] < MSDBS[-j] + arr[-i]: \\r\\n\\t\\t\\t\\tMSDBS[-i] = MSDBS[-j] + arr[-i] \\r\\n\\tmax_sum = float(\"-Inf\") \\r\\n\\tfor i, j, k in zip(MSIBS, MSDBS, arr): \\r\\n\\t\\tmax_sum = max(max_sum, i + j - k) \\r\\n\\treturn max_sum',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of a...ic subsequencequence in a given array.\\n\\n A',\n",
              "    'test_cases': ['assert max_sum([1, 15, 51, 45, 33, 100, 12, 18, 9], 9) == 194',\n",
              "     'assert max_sum([80, 60, 30, 40, 20, 10], 6) == 210',\n",
              "     'assert max_sum([2, 3 ,14, 16, 21, 23, 29, 30], 8) == 138'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.36069390989258,\n",
              "     'tokenization_energy': 0.11969390988349915,\n",
              "     'inference_energy': 23.24100000000908,\n",
              "     'energy_per_token': 1.1124139957091703,\n",
              "     'time': 0.5661242008209229,\n",
              "     'components': {'embeddings': np.float64(0.1193213872909546),\n",
              "      'attention': np.float64(8.90820177340845),\n",
              "      'ffn': np.float64(8.87685439300735),\n",
              "      'layernorm': np.float64(0.12565542697906493),\n",
              "      'output_layer': np.float64(0.22970752787590026)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function for computing square roots using the babylonian method.',\n",
              "    'ground_truth_code': 'def babylonian_squareroot(number):\\r\\n    if(number == 0):\\r\\n        return 0;\\r\\n    g = number/2.0;\\r\\n    g2 = g + 1;\\r\\n    while(g != g2):\\r\\n        n = number/ g;\\r\\n        g2 = g;\\r\\n        g = (g + n)/2;\\r\\n    return g;',\n",
              "    'generated_code': ')\\n\\n the function that the the roots of the squareblingian method.\\n The',\n",
              "    'test_cases': ['assert babylonian_squareroot(10)==3.162277660168379',\n",
              "     'assert babylonian_squareroot(2)==1.414213562373095',\n",
              "     'assert babylonian_squareroot(9)==3.0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.347658694980666,\n",
              "     'tokenization_energy': 0.12465869498252868,\n",
              "     'inference_energy': 28.222999999998137,\n",
              "     'energy_per_token': 1.889843912998711,\n",
              "     'time': 0.5605847835540771,\n",
              "     'components': {'embeddings': np.float64(0.13705624914169312),\n",
              "      'attention': np.float64(9.29642995642789),\n",
              "      'ffn': np.float64(8.87803815437574),\n",
              "      'layernorm': np.float64(0.1272783193588257),\n",
              "      'output_layer': np.float64(0.23245147132873534)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the longest palindromic subsequence in the given string.',\n",
              "    'ground_truth_code': 'def lps(str): \\r\\n\\tn = len(str) \\r\\n\\tL = [[0 for x in range(n)] for x in range(n)] \\r\\n\\tfor i in range(n): \\r\\n\\t\\tL[i][i] = 1\\r\\n\\tfor cl in range(2, n+1): \\r\\n\\t\\tfor i in range(n-cl+1): \\r\\n\\t\\t\\tj = i+cl-1\\r\\n\\t\\t\\tif str[i] == str[j] and cl == 2: \\r\\n\\t\\t\\t\\tL[i][j] = 2\\r\\n\\t\\t\\telif str[i] == str[j]: \\r\\n\\t\\t\\t\\tL[i][j] = L[i+1][j-1] + 2\\r\\n\\t\\t\\telse: \\r\\n\\t\\t\\t\\tL[i][j] = max(L[i][j-1], L[i+1][j]); \\r\\n\\treturn L[0][n-1]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum substringindromic substringsequence of a given string. The',\n",
              "    'test_cases': ['assert lps(\"TENS FOR TENS\") == 5 ',\n",
              "     'assert lps(\"CARDIO FOR CARDS\") == 7',\n",
              "     'assert lps(\"PART OF THE JOURNEY IS PART\") == 9 '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.515919846061966,\n",
              "     'tokenization_energy': 0.12091984605789184,\n",
              "     'inference_energy': 23.395000000004075,\n",
              "     'energy_per_token': 1.2376799918979982,\n",
              "     'time': 0.5651946067810059,\n",
              "     'components': {'embeddings': np.float64(0.11958492422103881),\n",
              "      'attention': np.float64(13.84347231603146),\n",
              "      'ffn': np.float64(13.201905474662663),\n",
              "      'layernorm': np.float64(0.1901778862476349),\n",
              "      'output_layer': np.float64(0.23038698887825013)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to calculate the harmonic sum of n-1.',\n",
              "    'ground_truth_code': 'def harmonic_sum(n):\\r\\n  if n < 2:\\r\\n    return 1\\r\\n  else:\\r\\n    return 1 / n + (harmonic_sum(n - 1)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability mean of a termsary elements The',\n",
              "    'test_cases': ['assert harmonic_sum(7) == 2.5928571428571425',\n",
              "     'assert harmonic_sum(4) == 2.083333333333333',\n",
              "     'assert harmonic_sum(19) == 3.547739657143682'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.224368988266797,\n",
              "     'tokenization_energy': 0.12436898827552796,\n",
              "     'inference_energy': 28.09999999999127,\n",
              "     'energy_per_token': 2.016026356304771,\n",
              "     'time': 0.5641677379608154,\n",
              "     'components': {'embeddings': np.float64(4.7519999999931315),\n",
              "      'attention': np.float64(13.635503995181061),\n",
              "      'ffn': np.float64(13.295049891235655),\n",
              "      'layernorm': np.float64(0.12543056774139405),\n",
              "      'output_layer': np.float64(0.21118888306617736)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find the intersection of two arrays using lambda function.',\n",
              "    'ground_truth_code': 'def intersection_array(array_nums1,array_nums2):\\r\\n result = list(filter(lambda x: x in array_nums1, array_nums2)) \\r\\n return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum point two sets of the expressions and Do',\n",
              "    'test_cases': ['assert intersection_array([1, 2, 3, 5, 7, 8, 9, 10],[1, 2, 4, 8, 9])==[1, 2, 8, 9]',\n",
              "     'assert intersection_array([1, 2, 3, 5, 7, 8, 9, 10],[3,5,7,9])==[3,5,7,9]',\n",
              "     'assert intersection_array([1, 2, 3, 5, 7, 8, 9, 10],[10,20,30,40])==[10]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.113317304613417,\n",
              "     'tokenization_energy': 0.12031730461120604,\n",
              "     'inference_energy': 27.993000000002212,\n",
              "     'energy_per_token': 1.8742211536408946,\n",
              "     'time': 0.5639801025390625,\n",
              "     'components': {'embeddings': np.float64(0.12045069408416748),\n",
              "      'attention': np.float64(18.21287006091338),\n",
              "      'ffn': np.float64(13.394791363486323),\n",
              "      'layernorm': np.float64(0.1243944251537323),\n",
              "      'output_layer': np.float64(4.701000000000931)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to count the occcurences of an element in a tuple.',\n",
              "    'ground_truth_code': 'def count_X(tup, x): \\r\\n    count = 0\\r\\n    for ele in tup: \\r\\n        if (ele == x): \\r\\n            count = count + 1\\r\\n    return count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the numberureurrencences of each integer in a matrix.\\n The',\n",
              "    'test_cases': ['assert count_X((10, 8, 5, 2, 10, 15, 10, 8, 5, 8, 8, 2),4) == 0',\n",
              "     'assert count_X((10, 8, 5, 2, 10, 15, 10, 8, 5, 8, 8, 2),10) == 3',\n",
              "     'assert count_X((10, 8, 5, 2, 10, 15, 10, 8, 5, 8, 8, 2),8) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.417961284161894,\n",
              "     'tokenization_energy': 0.125961284160614,\n",
              "     'inference_energy': 23.29200000000128,\n",
              "     'energy_per_token': 1.232524278113784,\n",
              "     'time': 0.5605859756469727,\n",
              "     'components': {'embeddings': np.float64(0.12597298407554627),\n",
              "      'attention': np.float64(9.067561959035112),\n",
              "      'ffn': np.float64(13.545044414988368),\n",
              "      'layernorm': np.float64(0.12455734443664551),\n",
              "      'output_layer': np.float64(0.2902368643283844)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to insert an element before each element of a list.',\n",
              "    'ground_truth_code': 'def insert_element(list,element):\\r\\n list = [v for elt in list for v in (element, elt)]\\r\\n return list',\n",
              "    'generated_code': ')\\n\\n the function that compute a element into each occurrence in a given, The',\n",
              "    'test_cases': [\"assert insert_element(['Red', 'Green', 'Black'] ,'c')==['c', 'Red', 'c', 'Green', 'c', 'Black'] \",\n",
              "     \"assert insert_element(['python', 'java'] ,'program')==['program', 'python', 'program', 'java'] \",\n",
              "     \"assert insert_element(['happy', 'sad'] ,'laugh')==['laugh', 'happy', 'laugh', 'sad'] \"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.51848704815458,\n",
              "     'tokenization_energy': 0.2594870481491089,\n",
              "     'inference_energy': 28.25900000000547,\n",
              "     'energy_per_token': 1.901232469876972,\n",
              "     'time': 0.5667080879211426,\n",
              "     'components': {'embeddings': np.float64(0.12017246294021607),\n",
              "      'attention': np.float64(18.225008587131043),\n",
              "      'ffn': np.float64(8.884011014941033),\n",
              "      'layernorm': np.float64(0.13010349464416504),\n",
              "      'output_layer': np.float64(0.21488521003723143)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to convert complex numbers to polar coordinates.',\n",
              "    'ground_truth_code': 'import cmath  \\r\\ndef convert(numbers):    \\r\\n  num = cmath.polar(numbers)  \\r\\n  return (num) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute a numbers into complex form.\\n The',\n",
              "    'test_cases': ['assert convert(1) == (1.0, 0.0)',\n",
              "     'assert convert(4) == (4.0,0.0)',\n",
              "     'assert convert(5) == (5.0,0.0)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.14898970794864,\n",
              "     'tokenization_energy': 0.12198970794677734,\n",
              "     'inference_energy': 28.027000000001863,\n",
              "     'energy_per_token': 2.165306900611434,\n",
              "     'time': 0.5650737285614014,\n",
              "     'components': {'embeddings': np.float64(0.14205350685119628),\n",
              "      'attention': np.float64(13.47749949955614),\n",
              "      'ffn': np.float64(13.35924042653176),\n",
              "      'layernorm': np.float64(0.12614278507232665),\n",
              "      'output_layer': np.float64(0.20743189048767088)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to count integers from a given list.',\n",
              "    'ground_truth_code': 'def count_integer(list1):\\r\\n    ctr = 0\\r\\n    for i in list1:\\r\\n        if isinstance(i, int):\\r\\n            ctr = ctr + 1\\r\\n    return ctr',\n",
              "    'generated_code': ')\\n\\n the function function that compute the in a given string that The',\n",
              "    'test_cases': [\"assert count_integer([1,2,'abc',1.2]) == 2\",\n",
              "     'assert count_integer([1,2,3]) == 3',\n",
              "     'assert count_integer([1,1.2,4,5.1]) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.41711271953245,\n",
              "     'tokenization_energy': 0.13011271953582762,\n",
              "     'inference_energy': 23.286999999996624,\n",
              "     'energy_per_token': 1.8013163630409577,\n",
              "     'time': 0.5586671829223633,\n",
              "     'components': {'embeddings': np.float64(0.12846269607543945),\n",
              "      'attention': np.float64(8.889570186134428),\n",
              "      'ffn': np.float64(8.937281417372054),\n",
              "      'layernorm': np.float64(0.12924186730384826),\n",
              "      'output_layer': np.float64(0.21781426906585694)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': \"Write a function to find all words starting with 'a' or 'e' in a given string.\",\n",
              "    'ground_truth_code': 'import re\\r\\ndef words_ae(text):\\r\\n list = re.findall(\"[ae]\\\\w+\", text)\\r\\n return list',\n",
              "    'generated_code': \")\\n\\n the function that compute the the in with au' in 'A' in a given string. The\",\n",
              "    'test_cases': ['assert words_ae(\"python programe\")==[\\'ame\\']',\n",
              "     'assert words_ae(\"python programe language\")==[\\'ame\\',\\'anguage\\']',\n",
              "     'assert words_ae(\"assert statement\")==[\\'assert\\', \\'atement\\']'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.22680919647112,\n",
              "     'tokenization_energy': 0.12480919647216797,\n",
              "     'inference_energy': 28.101999999998952,\n",
              "     'energy_per_token': 1.2830367816577781,\n",
              "     'time': 0.5594754219055176,\n",
              "     'components': {'embeddings': np.float64(0.1900493152141571),\n",
              "      'attention': np.float64(13.691802580831803),\n",
              "      'ffn': np.float64(17.916116312497763),\n",
              "      'layernorm': np.float64(0.15658569717407228),\n",
              "      'output_layer': np.float64(0.23422952127456667)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to choose specified number of colours from three different colours and generate all the combinations with repetitions.',\n",
              "    'ground_truth_code': 'from itertools import combinations_with_replacement \\r\\ndef combinations_colors(l, n):\\r\\n    return list(combinations_with_replacement(l,n))\\r',\n",
              "    'generated_code': ')\\n\\n the function that compute the\\n of elements from a colours\\n, return a possible possible.\\n the allowed How',\n",
              "    'test_cases': ['assert combinations_colors( [\"Red\",\"Green\",\"Blue\"],1)==[(\\'Red\\',), (\\'Green\\',), (\\'Blue\\',)]',\n",
              "     'assert combinations_colors( [\"Red\",\"Green\",\"Blue\"],2)==[(\\'Red\\', \\'Red\\'), (\\'Red\\', \\'Green\\'), (\\'Red\\', \\'Blue\\'), (\\'Green\\', \\'Green\\'), (\\'Green\\', \\'Blue\\'), (\\'Blue\\', \\'Blue\\')]',\n",
              "     'assert combinations_colors( [\"Red\",\"Green\",\"Blue\"],3)==[(\\'Red\\', \\'Red\\', \\'Red\\'), (\\'Red\\', \\'Red\\', \\'Green\\'), (\\'Red\\', \\'Red\\', \\'Blue\\'), (\\'Red\\', \\'Green\\', \\'Green\\'), (\\'Red\\', \\'Green\\', \\'Blue\\'), (\\'Red\\', \\'Blue\\', \\'Blue\\'), (\\'Green\\', \\'Green\\', \\'Green\\'), (\\'Green\\', \\'Green\\', \\'Blue\\'), (\\'Green\\', \\'Blue\\', \\'Blue\\'), (\\'Blue\\', \\'Blue\\', \\'Blue\\')]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.661644857883918,\n",
              "     'tokenization_energy': 0.12364485788345338,\n",
              "     'inference_energy': 23.538000000000466,\n",
              "     'energy_per_token': 1.0755293117219962,\n",
              "     'time': 0.5553224086761475,\n",
              "     'components': {'embeddings': np.float64(0.1839927487373352),\n",
              "      'attention': np.float64(4.5580635387897495),\n",
              "      'ffn': np.float64(4.417944719076156),\n",
              "      'layernorm': np.float64(0.13022057461738587),\n",
              "      'output_layer': np.float64(0.23343630695343018)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a python function to count the number of prime numbers less than a given non-negative number.',\n",
              "    'ground_truth_code': 'def count_Primes_nums(n):\\r\\n    ctr = 0\\r\\n    for num in range(n):\\r\\n        if num <= 1:\\r\\n            continue\\r\\n        for i in range(2,num):\\r\\n            if (num % i) == 0:\\r\\n                break\\r\\n        else:\\r\\n            ctr += 1\\r\\n    return ctr',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of integers numbers in than or given integer-negative integer n The',\n",
              "    'test_cases': ['assert count_Primes_nums(5) == 2',\n",
              "     'assert count_Primes_nums(10) == 4',\n",
              "     'assert count_Primes_nums(100) == 25'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.300404258007998,\n",
              "     'tokenization_energy': 0.1274042580127716,\n",
              "     'inference_energy': 28.172999999995227,\n",
              "     'energy_per_token': 1.4150202129004,\n",
              "     'time': 0.5625636577606201,\n",
              "     'components': {'embeddings': np.float64(4.6929999999993015),\n",
              "      'attention': np.float64(9.13866762924404),\n",
              "      'ffn': np.float64(8.994417264457445),\n",
              "      'layernorm': np.float64(0.1234847002029419),\n",
              "      'output_layer': np.float64(0.2233245623111725)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to swap two numbers.',\n",
              "    'ground_truth_code': 'def swap_numbers(a,b):\\r\\n temp = a\\r\\n a = b\\r\\n b = temp\\r\\n return (a,b)',\n",
              "    'generated_code': ')\\n\\n the function that compute the elements using The',\n",
              "    'test_cases': ['assert swap_numbers(10,20)==(20,10)',\n",
              "     'assert swap_numbers(15,17)==(17,15)',\n",
              "     'assert swap_numbers(100,200)==(200,100)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.13164090395218,\n",
              "     'tokenization_energy': 0.11964090394973756,\n",
              "     'inference_energy': 28.012000000002445,\n",
              "     'energy_per_token': 3.125737878216909,\n",
              "     'time': 0.5589039325714111,\n",
              "     'components': {'embeddings': np.float64(0.17887929534912111),\n",
              "      'attention': np.float64(13.613848995448091),\n",
              "      'ffn': np.float64(17.550770022149315),\n",
              "      'layernorm': np.float64(0.2511170151233673),\n",
              "      'output_layer': np.float64(0.21138818788528443)},\n",
              "     'num_tokens': 9}},\n",
              "   {'prompt': 'Write a function to find number of odd elements in the given list using lambda function.',\n",
              "    'ground_truth_code': 'def count_odd(array_nums):\\r\\n   count_odd = len(list(filter(lambda x: (x%2 != 0) , array_nums)))\\r\\n   return count_odd',\n",
              "    'generated_code': ')\\n\\n the function that compute the of unique numbers in a matrix matrix.\\n only functions in Note',\n",
              "    'test_cases': ['assert count_odd([1, 2, 3, 5, 7, 8, 10])==4',\n",
              "     'assert count_odd([10,15,14,13,-18,12,-20])==2',\n",
              "     'assert count_odd([1, 2, 4, 8, 9])==2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.541044172283613,\n",
              "     'tokenization_energy': 0.1290441722869873,\n",
              "     'inference_energy': 23.411999999996624,\n",
              "     'energy_per_token': 1.3078357873490896,\n",
              "     'time': 0.5620148181915283,\n",
              "     'components': {'embeddings': np.float64(0.2235572578907013),\n",
              "      'attention': np.float64(13.643586307048565),\n",
              "      'ffn': np.float64(13.300275898212917),\n",
              "      'layernorm': np.float64(0.12445420956611633),\n",
              "      'output_layer': np.float64(0.2268212099075317)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to maximize the given two tuples.',\n",
              "    'ground_truth_code': 'def maximize_elements(test_tup1, test_tup2):\\r\\n  res = tuple(tuple(max(a, b) for a, b in zip(tup1, tup2))\\r\\n   for tup1, tup2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum array-dimensional, So',\n",
              "    'test_cases': ['assert maximize_elements(((1, 3), (4, 5), (2, 9), (1, 10)), ((6, 7), (3, 9), (1, 1), (7, 3))) == ((6, 7), (4, 9), (2, 9), (7, 10))',\n",
              "     'assert maximize_elements(((2, 4), (5, 6), (3, 10), (2, 11)), ((7, 8), (4, 10), (2, 2), (8, 4))) == ((7, 8), (5, 10), (3, 10), (8, 11))',\n",
              "     'assert maximize_elements(((3, 5), (6, 7), (4, 11), (3, 12)), ((8, 9), (5, 11), (3, 3), (9, 5))) == ((8, 9), (6, 11), (4, 11), (9, 12))'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.200048947816715,\n",
              "     'tokenization_energy': 0.1190489478111267,\n",
              "     'inference_energy': 28.081000000005588,\n",
              "     'energy_per_token': 2.563640813437883,\n",
              "     'time': 0.5558147430419922,\n",
              "     'components': {'embeddings': np.float64(0.1256196150779724),\n",
              "      'attention': np.float64(13.527010377403931),\n",
              "      'ffn': np.float64(17.81171250796621),\n",
              "      'layernorm': np.float64(4.653000000005704),\n",
              "      'output_layer': np.float64(0.21241561961174013)},\n",
              "     'num_tokens': 11}},\n",
              "   {'prompt': 'Write a function to find the nth newman–shanks–williams prime number.',\n",
              "    'ground_truth_code': 'def newman_prime(n): \\r\\n\\tif n == 0 or n == 1: \\r\\n\\t\\treturn 1\\r\\n\\treturn 2 * newman_prime(n - 1) + newman_prime(n - 2)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum root number-le...\\nanks–coriams number number, The',\n",
              "    'test_cases': ['assert newman_prime(3) == 7 ',\n",
              "     'assert newman_prime(4) == 17',\n",
              "     'assert newman_prime(5) == 41'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.55170580410643,\n",
              "     'tokenization_energy': 0.12070580410957338,\n",
              "     'inference_energy': 23.430999999996857,\n",
              "     'energy_per_token': 1.2395634633740227,\n",
              "     'time': 0.5615556240081787,\n",
              "     'components': {'embeddings': np.float64(0.30449732303619387),\n",
              "      'attention': np.float64(8.91759632801218),\n",
              "      'ffn': np.float64(13.311989336976083),\n",
              "      'layernorm': np.float64(0.18822547745704651),\n",
              "      'output_layer': np.float64(0.2300125789642334)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to perform mathematical division operation across the given tuples.',\n",
              "    'ground_truth_code': 'def division_elements(test_tup1, test_tup2):\\r\\n  res = tuple(ele1 // ele2 for ele1, ele2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the operations of on multiple two two in The',\n",
              "    'test_cases': ['assert division_elements((10, 4, 6, 9),(5, 2, 3, 3)) == (2, 2, 2, 3)',\n",
              "     'assert division_elements((12, 6, 8, 16),(6, 3, 4, 4)) == (2, 2, 2, 4)',\n",
              "     'assert division_elements((20, 14, 36, 18),(5, 7, 6, 9)) == (4, 2, 6, 2)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.517482629772392,\n",
              "     'tokenization_energy': 0.12448262977600098,\n",
              "     'inference_energy': 28.39299999999639,\n",
              "     'energy_per_token': 2.036963044983742,\n",
              "     'time': 0.5638182163238525,\n",
              "     'components': {'embeddings': np.float64(4.8179999999993015),\n",
              "      'attention': np.float64(4.724936074256896),\n",
              "      'ffn': np.float64(8.825714372161542),\n",
              "      'layernorm': np.float64(0.12757995986938475),\n",
              "      'output_layer': np.float64(0.2133575096130371)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to split a given list into two parts where the length of the first part of the list is given.',\n",
              "    'ground_truth_code': 'def split_two_parts(list1, L):\\r\\n    return list1[:L], list1[L:]',\n",
              "    'generated_code': ')\\n\\n the function that compute a number integer of two parts, the first of the parts part is the first is equal by The',\n",
              "    'test_cases': ['assert split_two_parts([1,1,2,3,4,4,5,1],3)==([1, 1, 2], [3, 4, 4, 5, 1])',\n",
              "     \"assert split_two_parts(['a', 'b', 'c', 'd'],2)==(['a', 'b'], ['c', 'd'])\",\n",
              "     \"assert split_two_parts(['p', 'y', 't', 'h', 'o', 'n'],4)==(['p', 'y', 't', 'h'], ['o', 'n'])\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.450921810148053,\n",
              "     'tokenization_energy': 0.12192181015014648,\n",
              "     'inference_energy': 28.328999999997905,\n",
              "     'energy_per_token': 1.1380368724059222,\n",
              "     'time': 0.5587625503540039,\n",
              "     'components': {'embeddings': np.float64(0.12097124099731445),\n",
              "      'attention': np.float64(4.542293790340424),\n",
              "      'ffn': np.float64(4.545119060754776),\n",
              "      'layernorm': np.float64(0.14768227100372316),\n",
              "      'output_layer': np.float64(0.22528231263160708)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a function to merge two dictionaries.',\n",
              "    'ground_truth_code': 'def merge_dict(d1,d2):\\r\\n d = d1.copy()\\r\\n d.update(d2)\\r\\n return d',\n",
              "    'generated_code': ')\\n\\n the function that compute two arrays, The',\n",
              "    'test_cases': [\"assert merge_dict({'a': 100, 'b': 200},{'x': 300, 'y': 200})=={'x': 300, 'y': 200, 'a': 100, 'b': 200}\",\n",
              "     \"assert merge_dict({'a':900,'b':900,'d':900},{'a':900,'b':900,'d':900})=={'a':900,'b':900,'d':900,'a':900,'b':900,'d':900}\",\n",
              "     \"assert merge_dict({'a':10,'b':20},{'x':30,'y':40})=={'x':30,'y':40,'a':10,'b':20}\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.459058729172686,\n",
              "     'tokenization_energy': 0.13305872917175293,\n",
              "     'inference_energy': 23.32600000000093,\n",
              "     'energy_per_token': 2.606562081019187,\n",
              "     'time': 0.5529129505157471,\n",
              "     'components': {'embeddings': np.float64(0.1341871862411499),\n",
              "      'attention': np.float64(4.710376443386077),\n",
              "      'ffn': np.float64(4.2383693194389345),\n",
              "      'layernorm': np.float64(0.12333526611328126),\n",
              "      'output_layer': np.float64(0.207456524848938)},\n",
              "     'num_tokens': 9}},\n",
              "   {'prompt': \"Write a function to calculate a dog's age in dog's years.\",\n",
              "    'ground_truth_code': 'def dog_age(h_age):\\r\\n if h_age < 0:\\r\\n \\texit()\\r\\n elif h_age <= 2:\\r\\n\\t d_age = h_age * 10.5\\r\\n else:\\r\\n\\t d_age = 21 + (h_age - 2)*4\\r\\n return d_age',\n",
              "    'generated_code': \")\\n\\n the function that compute the 's age in years years years based The\",\n",
              "    'test_cases': ['assert dog_age(12)==61',\n",
              "     'assert dog_age(15)==73',\n",
              "     'assert dog_age(24)==109'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.250752142907817,\n",
              "     'tokenization_energy': 0.11775214290618898,\n",
              "     'inference_energy': 28.13300000000163,\n",
              "     'energy_per_token': 1.8833834761938546,\n",
              "     'time': 0.5563468933105469,\n",
              "     'components': {'embeddings': np.float64(0.1195801477432251),\n",
              "      'attention': np.float64(4.856561223745346),\n",
              "      'ffn': np.float64(4.322089242696762),\n",
              "      'layernorm': np.float64(4.650999999998021),\n",
              "      'output_layer': np.float64(0.21015036153793334)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to split a list for every nth element.',\n",
              "    'ground_truth_code': 'def list_split(S, step):\\r\\n    return [S[i::step] for i in range(step)]',\n",
              "    'generated_code': ')\\n\\n the function that compute a number of a n element, So',\n",
              "    'test_cases': [\"assert list_split(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n'],3)==[['a', 'd', 'g', 'j', 'm'], ['b', 'e', 'h', 'k', 'n'], ['c', 'f', 'i', 'l']] \",\n",
              "     'assert list_split([1,2,3,4,5,6,7,8,9,10,11,12,13,14],3)==[[1,4,7,10,13], [2,5,8,11,14], [3,6,9,12]] ',\n",
              "     \"assert list_split(['python','java','C','C++','DBMS','SQL'],2)==[['python', 'C', 'DBMS'], ['java', 'C++', 'SQL']] \"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.66375604724628,\n",
              "     'tokenization_energy': 0.12275604724884033,\n",
              "     'inference_energy': 23.54099999999744,\n",
              "     'energy_per_token': 1.8202889267112523,\n",
              "     'time': 0.5591158866882324,\n",
              "     'components': {'embeddings': np.float64(0.11870487570762633),\n",
              "      'attention': np.float64(9.353517103920227),\n",
              "      'ffn': np.float64(8.793315206281608),\n",
              "      'layernorm': np.float64(0.12346971154212952),\n",
              "      'output_layer': np.float64(0.20776439714431763)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the lateral surface area of a cube.',\n",
              "    'ground_truth_code': 'def lateralsurface_cube(l):\\r\\n  LSA = 4 * (l * l)\\r\\n  return LSA',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum surface area of a cube.\\n The',\n",
              "    'test_cases': ['assert lateralsurface_cube(5)==100',\n",
              "     'assert lateralsurface_cube(9)==324',\n",
              "     'assert lateralsurface_cube(10)==400'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.383263910534442,\n",
              "     'tokenization_energy': 0.12126391053199768,\n",
              "     'inference_energy': 28.262000000002445,\n",
              "     'energy_per_token': 2.027375993609603,\n",
              "     'time': 0.5511188507080078,\n",
              "     'components': {'embeddings': np.float64(0.1196095597743988),\n",
              "      'attention': np.float64(13.789560558327942),\n",
              "      'ffn': np.float64(18.04627523707191),\n",
              "      'layernorm': np.float64(0.12862409591674803),\n",
              "      'output_layer': np.float64(0.21657424235343933)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the sum of squares of first n odd natural numbers.',\n",
              "    'ground_truth_code': 'def square_Sum(n):  \\r\\n    return int(n*(4*n*n-1)/3) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all of the n natural numbers numbers.\\n \\n',\n",
              "    'test_cases': ['assert square_Sum(2) == 10',\n",
              "     'assert square_Sum(3) == 35',\n",
              "     'assert square_Sum(4) == 84'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.50859199070791,\n",
              "     'tokenization_energy': 0.12259199070930481,\n",
              "     'inference_energy': 23.385999999998603,\n",
              "     'energy_per_token': 1.3060328883726617,\n",
              "     'time': 0.5625007152557373,\n",
              "     'components': {'embeddings': np.float64(0.12770046544075012),\n",
              "      'attention': np.float64(13.688802073714788),\n",
              "      'ffn': np.float64(13.374506918911475),\n",
              "      'layernorm': np.float64(0.1256146128177643),\n",
              "      'output_layer': np.float64(0.22773560929298403)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': \"Write a function to find the n'th star number.\",\n",
              "    'ground_truth_code': 'def find_star_num(n): \\r\\n\\treturn (6 * n * (n - 1) + 1) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-thh smallest number in The',\n",
              "    'test_cases': ['assert find_star_num(3) == 37',\n",
              "     'assert find_star_num(4) == 73',\n",
              "     'assert find_star_num(5) == 121'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.4320000000007,\n",
              "     'tokenization_energy': 4.864000000001397,\n",
              "     'inference_energy': 23.5679999999993,\n",
              "     'energy_per_token': 2.187076923076977,\n",
              "     'time': 0.5572624206542969,\n",
              "     'components': {'embeddings': np.float64(0.12408576345443725),\n",
              "      'attention': np.float64(13.58931306171557),\n",
              "      'ffn': np.float64(18.084070835826687),\n",
              "      'layernorm': np.float64(0.13099104166030884),\n",
              "      'output_layer': np.float64(0.22034439754486085)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the ascii value of a character.',\n",
              "    'ground_truth_code': 'def ascii_value(k):\\r\\n  ch=k\\r\\n  return ord(ch)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum sum of a character.\\n The',\n",
              "    'test_cases': [\"assert ascii_value('A')==65\",\n",
              "     \"assert ascii_value('R')==82\",\n",
              "     \"assert ascii_value('S')==83\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.39508906579041,\n",
              "     'tokenization_energy': 0.1260890657901764,\n",
              "     'inference_energy': 28.269000000000233,\n",
              "     'energy_per_token': 2.184237620445416,\n",
              "     'time': 0.5603244304656982,\n",
              "     'components': {'embeddings': np.float64(0.12443566775321961),\n",
              "      'attention': np.float64(13.64205427646311),\n",
              "      'ffn': np.float64(9.032014130831813),\n",
              "      'layernorm': np.float64(0.12527861475944518),\n",
              "      'output_layer': np.float64(4.5899999999965075)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to find the sum of even numbers at even positions.',\n",
              "    'ground_truth_code': 'def sum_even_and_even_index(arr,n):  \\r\\n    i = 0\\r\\n    sum = 0\\r\\n    for i in range(0,n,2): \\r\\n        if (arr[i] % 2 == 0) : \\r\\n            sum += arr[i]  \\r\\n    return sum',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all numbers in each indices in So',\n",
              "    'test_cases': ['assert sum_even_and_even_index([5, 6, 12, 1, 18, 8],6) == 30',\n",
              "     'assert sum_even_and_even_index([3, 20, 17, 9, 2, 10, 18, 13, 6, 18],10) == 26',\n",
              "     'assert sum_even_and_even_index([5, 6, 12, 1],4) == 12'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.682279295922605,\n",
              "     'tokenization_energy': 0.14027929592132568,\n",
              "     'inference_energy': 23.54200000000128,\n",
              "     'energy_per_token': 1.4801424559951628,\n",
              "     'time': 0.5582902431488037,\n",
              "     'components': {'embeddings': np.float64(0.14171246147155764),\n",
              "      'attention': np.float64(13.817560994164436),\n",
              "      'ffn': np.float64(13.990647123089294),\n",
              "      'layernorm': np.float64(0.12645626735687254),\n",
              "      'output_layer': np.float64(0.21343142461776732)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find the sum of fifth power of first n even natural numbers.',\n",
              "    'ground_truth_code': 'def even_Power_Sum(n): \\r\\n    sum = 0; \\r\\n    for i in range(1,n+1): \\r\\n        j = 2*i; \\r\\n        sum = sum + (j*j*j*j*j); \\r\\n    return sum; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all powers of all n natural numbers numbers.\\n So',\n",
              "    'test_cases': ['assert even_Power_Sum(2) == 1056',\n",
              "     'assert even_Power_Sum(3) == 8832',\n",
              "     'assert even_Power_Sum(1) == 32'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.627580904491477,\n",
              "     'tokenization_energy': 0.12558090448379516,\n",
              "     'inference_energy': 28.502000000007683,\n",
              "     'energy_per_token': 1.5067147844469198,\n",
              "     'time': 0.5590050220489502,\n",
              "     'components': {'embeddings': np.float64(0.12014916563034057),\n",
              "      'attention': np.float64(18.43571251941356),\n",
              "      'ffn': np.float64(18.366021389724224),\n",
              "      'layernorm': np.float64(0.12650442051887512),\n",
              "      'output_layer': np.float64(0.22978065991401672)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to perfom the rear element extraction from list of tuples records.',\n",
              "    'ground_truth_code': 'def rear_extract(test_list):\\r\\n  res = [lis[-1] for lis in test_list]\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that computeom the following...\\n diagonal in a of elements.\\n.\\n The',\n",
              "    'test_cases': [\"assert rear_extract([(1, 'Rash', 21), (2, 'Varsha', 20), (3, 'Kil', 19)]) == [21, 20, 19]\",\n",
              "     \"assert rear_extract([(1, 'Sai', 36), (2, 'Ayesha', 25), (3, 'Salman', 45)]) == [36, 25, 45]\",\n",
              "     \"assert rear_extract([(1, 'Sudeep', 14), (2, 'Vandana', 36), (3, 'Dawood', 56)]) == [14, 36, 56]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.781201070539886,\n",
              "     'tokenization_energy': 0.12020107054710388,\n",
              "     'inference_energy': 23.660999999992782,\n",
              "     'energy_per_token': 1.3988941806199933,\n",
              "     'time': 0.5620527267456055,\n",
              "     'components': {'embeddings': np.float64(0.12808586597442626),\n",
              "      'attention': np.float64(13.902749751552474),\n",
              "      'ffn': np.float64(9.219537480122058),\n",
              "      'layernorm': np.float64(0.12875761532783508),\n",
              "      'output_layer': np.float64(0.2297747232913971)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to substract the contents of one tuple with corresponding index of other tuple.',\n",
              "    'ground_truth_code': 'def substract_elements(test_tup1, test_tup2):\\r\\n  res = tuple(map(lambda i, j: i - j, test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that computedivide two two of a array from the elements of another tuple.\\n\\n So',\n",
              "    'test_cases': ['assert substract_elements((10, 4, 5), (2, 5, 18)) == (8, -1, -13)',\n",
              "     'assert substract_elements((11, 2, 3), (24, 45 ,16)) == (-13, -43, -13)',\n",
              "     'assert substract_elements((7, 18, 9), (10, 11, 12)) == (-3, 7, -3)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.396999999997206,\n",
              "     'tokenization_energy': 4.835000000006403,\n",
              "     'inference_energy': 23.561999999990803,\n",
              "     'energy_per_token': 1.494578947368274,\n",
              "     'time': 0.5621640682220459,\n",
              "     'components': {'embeddings': np.float64(0.12318017578125),\n",
              "      'attention': np.float64(9.387438133006917),\n",
              "      'ffn': np.float64(13.504081008660842),\n",
              "      'layernorm': np.float64(0.12431275057792664),\n",
              "      'output_layer': np.float64(0.3044467182159424)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to find sum of even index binomial coefficients.',\n",
              "    'ground_truth_code': 'import math  \\r\\ndef even_binomial_Coeff_Sum( n): \\r\\n    return (1 << (n - 1)) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the of all numbers elementsomial coefficients in So',\n",
              "    'test_cases': ['assert even_binomial_Coeff_Sum(4) == 8',\n",
              "     'assert even_binomial_Coeff_Sum(6) == 32',\n",
              "     'assert even_binomial_Coeff_Sum(2) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.84229387093091,\n",
              "     'tokenization_energy': 0.12129387092590331,\n",
              "     'inference_energy': 28.721000000005006,\n",
              "     'energy_per_token': 1.922819591395394,\n",
              "     'time': 0.6439766883850098,\n",
              "     'components': {'embeddings': np.float64(0.1218437783718109),\n",
              "      'attention': np.float64(9.580606494675157),\n",
              "      'ffn': np.float64(9.279959339134045),\n",
              "      'layernorm': np.float64(0.22006879138946533),\n",
              "      'output_layer': np.float64(0.2723436818122864)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the position of the last removed element from the given array.',\n",
              "    'ground_truth_code': 'import math as mt \\r\\ndef get_Position(a,n,m): \\r\\n    for i in range(n): \\r\\n        a[i] = (a[i] // m + (a[i] % m != 0))  \\r\\n    result,maxx = -1,-1\\r\\n    for i in range(n - 1,-1,-1): \\r\\n        if (maxx < a[i]): \\r\\n            maxx = a[i] \\r\\n            result = i \\r\\n    return result + 1',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of the first occurrence element from a array array after The',\n",
              "    'test_cases': ['assert get_Position([2,5,4],3,2) == 2',\n",
              "     'assert get_Position([4,3],2,2) == 2',\n",
              "     'assert get_Position([1,2,3,4],4,1) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 33.00699999999779,\n",
              "     'tokenization_energy': 4.505999999993946,\n",
              "     'inference_energy': 28.50100000000384,\n",
              "     'energy_per_token': 1.737210526315673,\n",
              "     'time': 0.6453490257263184,\n",
              "     'components': {'embeddings': np.float64(0.12194196653366089),\n",
              "      'attention': np.float64(18.861549342160927),\n",
              "      'ffn': np.float64(13.971503037439428),\n",
              "      'layernorm': np.float64(0.12742232537269593),\n",
              "      'output_layer': np.float64(0.29249548554420474)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the volume of a cylinder.',\n",
              "    'ground_truth_code': 'def volume_cylinder(r,h):\\r\\n  volume=3.1415*r*r*h\\r\\n  return volume',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a cube given The',\n",
              "    'test_cases': ['assert volume_cylinder(10,5)==1570.7500000000002',\n",
              "     'assert volume_cylinder(4,5)==251.32000000000002',\n",
              "     'assert volume_cylinder(4,10)==502.64000000000004'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.786699006324866,\n",
              "     'tokenization_energy': 0.18669900631904604,\n",
              "     'inference_energy': 23.60000000000582,\n",
              "     'energy_per_token': 1.982224917193739,\n",
              "     'time': 0.5613992214202881,\n",
              "     'components': {'embeddings': np.float64(0.1211903853416443),\n",
              "      'attention': np.float64(13.86266584706004),\n",
              "      'ffn': np.float64(13.46940271712269),\n",
              "      'layernorm': np.float64(0.12694907236099243),\n",
              "      'output_layer': np.float64(0.21181261730194093)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to filter a dictionary based on values.',\n",
              "    'ground_truth_code': 'def dict_filter(dict,n):\\r\\n result = {key:value for (key, value) in dict.items() if value >=n}\\r\\n return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the matrix of on the that The',\n",
              "    'test_cases': [\"assert dict_filter({'Cierra Vega': 175, 'Alden Cantrell': 180, 'Kierra Gentry': 165, 'Pierre Cox': 190},170)=={'Cierra Vega': 175, 'Alden Cantrell': 180, 'Pierre Cox': 190}\",\n",
              "     \"assert dict_filter({'Cierra Vega': 175, 'Alden Cantrell': 180, 'Kierra Gentry': 165, 'Pierre Cox': 190},180)=={ 'Alden Cantrell': 180, 'Pierre Cox': 190}\",\n",
              "     \"assert dict_filter({'Cierra Vega': 175, 'Alden Cantrell': 180, 'Kierra Gentry': 165, 'Pierre Cox': 190},190)=={ 'Pierre Cox': 190}\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.890742434269864,\n",
              "     'tokenization_energy': 0.16174243426322937,\n",
              "     'inference_energy': 23.729000000006636,\n",
              "     'energy_per_token': 1.990895202855822,\n",
              "     'time': 0.5590212345123291,\n",
              "     'components': {'embeddings': np.float64(0.12975047707557677),\n",
              "      'attention': np.float64(13.884559449674677),\n",
              "      'ffn': np.float64(8.911706865553045),\n",
              "      'layernorm': np.float64(0.12401864457130432),\n",
              "      'output_layer': np.float64(0.20916610360145568)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find the element count that occurs before the record in the given tuple.',\n",
              "    'ground_truth_code': 'def count_first_elements(test_tup):\\r\\n  for count, ele in enumerate(test_tup):\\r\\n    if isinstance(ele, tuple):\\r\\n      break\\r\\n  return (count) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum in in is the the first of the record array.\\n\\n So',\n",
              "    'test_cases': ['assert count_first_elements((1, 5, 7, (4, 6), 10) ) == 3',\n",
              "     'assert count_first_elements((2, 9, (5, 7), 11) ) == 2',\n",
              "     'assert count_first_elements((11, 15, 5, 8, (2, 3), 8) ) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.408301677460432,\n",
              "     'tokenization_energy': 0.12930167746543883,\n",
              "     'inference_energy': 28.278999999994994,\n",
              "     'energy_per_token': 1.4951737724979175,\n",
              "     'time': 0.5536313056945801,\n",
              "     'components': {'embeddings': np.float64(0.16681342148780823),\n",
              "      'attention': np.float64(13.829916410449776),\n",
              "      'ffn': np.float64(9.03239847993676),\n",
              "      'layernorm': np.float64(0.1260206377506256),\n",
              "      'output_layer': np.float64(4.728999999992084)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the nth decagonal number.',\n",
              "    'ground_truth_code': 'def is_num_decagonal(n): \\r\\n\\treturn 4 * n * n - 3 * n ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum rooti number.\\n The',\n",
              "    'test_cases': ['assert is_num_decagonal(3) == 27',\n",
              "     'assert is_num_decagonal(7) == 175',\n",
              "     'assert is_num_decagonal(10) == 370'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.8653774771773,\n",
              "     'tokenization_energy': 0.12837747716903686,\n",
              "     'inference_energy': 23.737000000008265,\n",
              "     'energy_per_token': 1.9887814564314417,\n",
              "     'time': 0.5589721202850342,\n",
              "     'components': {'embeddings': np.float64(0.12863949632644653),\n",
              "      'attention': np.float64(14.087827300793027),\n",
              "      'ffn': np.float64(4.610292537689208),\n",
              "      'layernorm': np.float64(0.1284897379875183),\n",
              "      'output_layer': np.float64(0.21436501693725585)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to search an element in the given array by using sequential search.',\n",
              "    'ground_truth_code': 'def sequential_search(dlist, item):\\r\\n    pos = 0\\r\\n    found = False\\r\\n    while pos < len(dlist) and not found:\\r\\n        if dlist[pos] == item:\\r\\n            found = True\\r\\n        else:\\r\\n            pos = pos + 1\\r\\n    return found, pos',\n",
              "    'generated_code': ')\\n\\n the function that compute for array in a matrix matrix, using the search. The',\n",
              "    'test_cases': ['assert sequential_search([11,23,58,31,56,77,43,12,65,19],31) == (True, 3)',\n",
              "     'assert sequential_search([12, 32, 45, 62, 35, 47, 44, 61],61) == (True, 7)',\n",
              "     'assert sequential_search([9, 10, 17, 19, 22, 39, 48, 56],48) == (True, 6)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.54110207986494,\n",
              "     'tokenization_energy': 0.12910207986831665,\n",
              "     'inference_energy': 28.411999999996624,\n",
              "     'energy_per_token': 1.6788883576391143,\n",
              "     'time': 0.5666673183441162,\n",
              "     'components': {'embeddings': np.float64(0.12398789119720459),\n",
              "      'attention': np.float64(18.556534547576334),\n",
              "      'ffn': np.float64(13.779552176224417),\n",
              "      'layernorm': np.float64(0.13000384020805358),\n",
              "      'output_layer': np.float64(0.2337469274997711)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to check if the elements of a given list are unique or not.',\n",
              "    'ground_truth_code': 'def all_unique(test_list):\\r\\n    if len(test_list) > len(set(test_list)):\\r\\n        return False\\r\\n    return True',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given in a given matrix are all.\\n not. Return',\n",
              "    'test_cases': ['assert all_unique([1,2,3]) == True',\n",
              "     'assert all_unique([1,2,1,2]) == False',\n",
              "     'assert all_unique([1,2,3,4,5]) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.579374284980585,\n",
              "     'tokenization_energy': 0.12537428498268127,\n",
              "     'inference_energy': 28.453999999997905,\n",
              "     'energy_per_token': 1.5041775939463466,\n",
              "     'time': 0.5625505447387695,\n",
              "     'components': {'embeddings': np.float64(0.12297968745231629),\n",
              "      'attention': np.float64(18.209364599462127),\n",
              "      'ffn': np.float64(13.411757065057056),\n",
              "      'layernorm': np.float64(0.12968101501464843),\n",
              "      'output_layer': np.float64(0.2518432903289795)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to substaract two lists using map and lambda function.',\n",
              "    'ground_truth_code': 'def sub_list(nums1,nums2):\\r\\n  result = map(lambda x, y: x - y, nums1, nums2)\\r\\n  return list(result)',\n",
              "    'generated_code': ')\\n\\n the function that computedivide a the matrices of the and filter in in The',\n",
              "    'test_cases': ['assert sub_list([1, 2, 3],[4,5,6])==[-3,-3,-3]',\n",
              "     'assert sub_list([1,2],[3,4])==[-2,-2]',\n",
              "     'assert sub_list([90,120],[50,70])==[40,50]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.91768687725719,\n",
              "     'tokenization_energy': 0.13568687725067138,\n",
              "     'inference_energy': 23.78200000000652,\n",
              "     'energy_per_token': 1.4948554298285743,\n",
              "     'time': 0.5557372570037842,\n",
              "     'components': {'embeddings': np.float64(0.13246852111816407),\n",
              "      'attention': np.float64(18.510698851827648),\n",
              "      'ffn': np.float64(13.571584282162483),\n",
              "      'layernorm': np.float64(0.128363862991333),\n",
              "      'output_layer': np.float64(0.22295077514648437)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to check whether the frequency of each digit is less than or equal to the digit itself.',\n",
              "    'ground_truth_code': 'def validate(n): \\r\\n    for i in range(10): \\r\\n        temp = n;  \\r\\n        count = 0; \\r\\n        while (temp): \\r\\n            if (temp % 10 == i): \\r\\n                count+=1;  \\r\\n            if (count > i): \\r\\n                return False\\r\\n            temp //= 10; \\r\\n    return True',\n",
              "    'generated_code': \")\\n\\n the function function that compute whether a given of each character in the than or equal to the frequency's.\\n So\",\n",
              "    'test_cases': ['assert validate(1234) == True',\n",
              "     'assert validate(51241) == False',\n",
              "     'assert validate(321) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.783603416430765,\n",
              "     'tokenization_energy': 0.1466034164428711,\n",
              "     'inference_energy': 28.636999999987893,\n",
              "     'energy_per_token': 1.2514610181056853,\n",
              "     'time': 0.5540649890899658,\n",
              "     'components': {'embeddings': np.float64(0.15590066528320312),\n",
              "      'attention': np.float64(4.9673806221485135),\n",
              "      'ffn': np.float64(4.618573649406433),\n",
              "      'layernorm': np.float64(0.1294583201408386),\n",
              "      'output_layer': np.float64(4.811000000001513)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a function to check whether all items of a list are equal to a given string.',\n",
              "    'ground_truth_code': 'def check_element(list,element):\\r\\n  check_element=all(v== element for v in list)\\r\\n  return check_element',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a the in a given are unique.\\n each given value.\\n The',\n",
              "    'test_cases': ['assert check_element([\"green\", \"orange\", \"black\", \"white\"],\\'blue\\')==False',\n",
              "     'assert check_element([1,2,3,4],7)==False',\n",
              "     'assert check_element([\"green\", \"green\", \"green\", \"green\"],\\'green\\')==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.764350679396188,\n",
              "     'tokenization_energy': 0.128350679397583,\n",
              "     'inference_energy': 23.635999999998603,\n",
              "     'energy_per_token': 1.2507552989155888,\n",
              "     'time': 0.5580270290374756,\n",
              "     'components': {'embeddings': np.float64(0.12987011790275574),\n",
              "      'attention': np.float64(9.322721352092223),\n",
              "      'ffn': np.float64(4.560998524665832),\n",
              "      'layernorm': np.float64(0.12383779406547546),\n",
              "      'output_layer': np.float64(0.22627726793289185)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': \"Write a function that matches a string that has an a followed by two to three 'b'.\",\n",
              "    'ground_truth_code': \"import re\\r\\ndef text_match_two_three(text):\\r\\n        patterns = 'ab{2,3}'\\r\\n        if re.search(patterns,  text):\\r\\n                return 'Found a match!'\\r\\n        else:\\r\\n                return('Not matched!')\",\n",
              "    'generated_code': \")\\n\\n the function that, the given to is been odd... by a b......b's So\",\n",
              "    'test_cases': ['assert text_match_two_three(\"ac\")==(\\'Not matched!\\')',\n",
              "     'assert text_match_two_three(\"dc\")==(\\'Not matched!\\')',\n",
              "     'assert text_match_two_three(\"abbbba\")==(\\'Found a match!\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.67162098741741,\n",
              "     'tokenization_energy': 0.12562098741531372,\n",
              "     'inference_energy': 28.546000000002095,\n",
              "     'energy_per_token': 1.4335810493708705,\n",
              "     'time': 0.5571582317352295,\n",
              "     'components': {'embeddings': np.float64(0.12085842132568358),\n",
              "      'attention': np.float64(18.35645363284531),\n",
              "      'ffn': np.float64(18.080477234113495),\n",
              "      'layernorm': np.float64(0.13299508953094483),\n",
              "      'output_layer': np.float64(0.24083117532730103)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find the largest sum of contiguous array in the modified array which is formed by repeating the given array k times.',\n",
              "    'ground_truth_code': 'def max_sub_array_sum_repeated(a, n, k): \\r\\n\\tmax_so_far = -2147483648\\r\\n\\tmax_ending_here = 0\\r\\n\\tfor i in range(n*k): \\r\\n\\t\\tmax_ending_here = max_ending_here + a[i%n] \\r\\n\\t\\tif (max_so_far < max_ending_here): \\r\\n\\t\\t\\tmax_so_far = max_ending_here \\r\\n\\t\\tif (max_ending_here < 0): \\r\\n\\t\\t\\tmax_ending_here = 0\\r\\n\\treturn max_so_far',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum prime of contiguous sub elements a array...\\n.\\n\\n is created by replacing the first array twice times.\\n So',\n",
              "    'test_cases': ['assert max_sub_array_sum_repeated([10, 20, -30, -1], 4, 3) == 30',\n",
              "     'assert max_sub_array_sum_repeated([-1, 10, 20], 3, 2) == 59',\n",
              "     'assert max_sub_array_sum_repeated([-1, -2, -3], 3, 3) == -1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.77591398907639,\n",
              "     'tokenization_energy': 0.14091398906707764,\n",
              "     'inference_energy': 23.635000000009313,\n",
              "     'energy_per_token': 0.8805894070028293,\n",
              "     'time': 0.5667133331298828,\n",
              "     'components': {'embeddings': np.float64(0.1280929136276245),\n",
              "      'attention': np.float64(9.427052227738663),\n",
              "      'ffn': np.float64(9.211024424086325),\n",
              "      'layernorm': np.float64(0.17366950845718385),\n",
              "      'output_layer': np.float64(0.335051242351532)},\n",
              "     'num_tokens': 27}},\n",
              "   {'prompt': 'Write a python function to find the sum of squares of first n even natural numbers.',\n",
              "    'ground_truth_code': 'def square_Sum(n):  \\r\\n    return int(2*n*(n+1)*(2*n+1)/3)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all of the n natural numbers numbers.\\n \\n',\n",
              "    'test_cases': ['assert square_Sum(2) == 20',\n",
              "     'assert square_Sum(3) == 56',\n",
              "     'assert square_Sum(4) == 120'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.894572354323813,\n",
              "     'tokenization_energy': 0.12757235431671143,\n",
              "     'inference_energy': 23.7670000000071,\n",
              "     'energy_per_token': 1.3274762419068784,\n",
              "     'time': 0.5673058032989502,\n",
              "     'components': {'embeddings': np.float64(0.12853574800491332),\n",
              "      'attention': np.float64(14.342315660717313),\n",
              "      'ffn': np.float64(18.33403127336991),\n",
              "      'layernorm': np.float64(0.13281981468200682),\n",
              "      'output_layer': np.float64(0.23883152961730955)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to count array elements having modular inverse under given prime number p equal to itself.',\n",
              "    'ground_truth_code': 'def modular_inverse(arr, N, P):\\r\\n\\tcurrent_element = 0\\r\\n\\tfor i in range(0, N):\\r\\n\\t\\tif ((arr[i] * arr[i]) % P == 1):\\r\\n\\t\\t\\tcurrent_element = current_element + 1\\r\\n\\treturn current_element',\n",
              "    'generated_code': ')\\n\\n the function that compute the elements that a invers, a modulus.\\n.\\n.\\n\\n to k.\\n So',\n",
              "    'test_cases': ['assert modular_inverse([ 1, 6, 4, 5 ], 4, 7) == 2',\n",
              "     'assert modular_inverse([1, 3, 8, 12, 12], 5, 13) == 3',\n",
              "     'assert modular_inverse([2, 3, 4, 5], 4, 6) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.659329061980824,\n",
              "     'tokenization_energy': 0.12632906198501587,\n",
              "     'inference_energy': 28.53299999999581,\n",
              "     'energy_per_token': 1.4329664530990411,\n",
              "     'time': 0.5635945796966553,\n",
              "     'components': {'embeddings': np.float64(0.12727978706359863),\n",
              "      'attention': np.float64(13.799784731624065),\n",
              "      'ffn': np.float64(13.948719627376878),\n",
              "      'layernorm': np.float64(0.1989416046142578),\n",
              "      'output_layer': np.float64(0.23775011253356934)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to calculate the number of odd days in a given year.',\n",
              "    'ground_truth_code': 'def odd_Days(N): \\r\\n    hund1 = N // 100\\r\\n    hund4 = N // 400\\r\\n    leap = N >> 2\\r\\n    ordd = N - leap \\r\\n    if (hund1): \\r\\n        ordd += hund1 \\r\\n        leap -= hund1 \\r\\n    if (hund4): \\r\\n        ordd -= hund4 \\r\\n        leap += hund4 \\r\\n    days = ordd + leap * 2\\r\\n    odd = days % 7\\r\\n    return odd ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of possible numbers in a year year, The',\n",
              "    'test_cases': ['assert odd_Days(100) == 5',\n",
              "     'assert odd_Days(50) ==6',\n",
              "     'assert odd_Days(75) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.866746547708054,\n",
              "     'tokenization_energy': 0.12574654769897461,\n",
              "     'inference_energy': 23.74100000000908,\n",
              "     'energy_per_token': 1.4039262675122384,\n",
              "     'time': 0.5562350749969482,\n",
              "     'components': {'embeddings': np.float64(0.19268104171752928),\n",
              "      'attention': np.float64(14.04577643752424),\n",
              "      'ffn': np.float64(18.220081773763756),\n",
              "      'layernorm': np.float64(0.13332452058792113),\n",
              "      'output_layer': np.float64(0.23995831489562985)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the list of lists with maximum length.',\n",
              "    'ground_truth_code': 'def max_length(list1):\\r\\n    max_length = max(len(x) for x in  list1 )  \\r\\n    max_list = max((x) for x in   list1)\\r\\n    return(max_length, max_list)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of all of the sum in The',\n",
              "    'test_cases': ['assert max_length([[0], [1, 3], [5, 7], [9, 11], [13, 15, 17]])==(3, [13, 15, 17])',\n",
              "     'assert max_length([[1], [5, 7], [10, 12, 14,15]])==(4, [10, 12, 14,15])',\n",
              "     'assert max_length([[5], [15,20,25]])==(3, [15,20,25])'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.761059103006847,\n",
              "     'tokenization_energy': 0.12605910301208495,\n",
              "     'inference_energy': 28.63499999999476,\n",
              "     'energy_per_token': 2.054361364500489,\n",
              "     'time': 0.5611419677734375,\n",
              "     'components': {'embeddings': np.float64(0.17740511298179626),\n",
              "      'attention': np.float64(13.895074193713953),\n",
              "      'ffn': np.float64(18.18984042716131),\n",
              "      'layernorm': np.float64(0.19863426733016967),\n",
              "      'output_layer': np.float64(0.22283666038513184)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find out the number of ways of painting the fence such that at most 2 adjacent posts have the same color for the given fence with n posts and k colors.',\n",
              "    'ground_truth_code': 'def count_no_of_ways(n, k): \\r\\n\\tdp = [0] * (n + 1) \\r\\n\\ttotal = k \\r\\n\\tmod = 1000000007\\r\\n\\tdp[1] = k \\r\\n\\tdp[2] = k * k\\t \\r\\n\\tfor i in range(3,n+1): \\r\\n\\t\\tdp[i] = ((k - 1) * (dp[i - 1] + dp[i - 2])) % mod \\r\\n\\treturn dp[n]',\n",
              "    'generated_code': ')\\n\\n the function that compute the the number of unique to...\\n a edges such that the least one15...\\n are the same color.\\n all fence n post n',\n",
              "    'test_cases': ['assert count_no_of_ways(2, 4) == 16',\n",
              "     'assert count_no_of_ways(3, 2) == 6',\n",
              "     'assert count_no_of_ways(4, 4) == 228'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.79085008382157,\n",
              "     'tokenization_energy': 0.12585008382797241,\n",
              "     'inference_energy': 28.664999999993597,\n",
              "     'energy_per_token': 0.8997140651194241,\n",
              "     'time': 0.5576515197753906,\n",
              "     'components': {'embeddings': np.float64(0.1274785237312317),\n",
              "      'attention': np.float64(13.962514438147423),\n",
              "      'ffn': np.float64(18.503100023032747),\n",
              "      'layernorm': np.float64(0.12740700936317445),\n",
              "      'output_layer': np.float64(0.2308560950756073)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a python function to find quotient of two numbers.',\n",
              "    'ground_truth_code': 'def find(n,m):  \\r\\n    q = n//m \\r\\n    return (q)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the and two integers without Write',\n",
              "    'test_cases': ['assert find(10,3) == 3',\n",
              "     'assert find(4,2) == 2',\n",
              "     'assert find(20,5) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.997082841396914,\n",
              "     'tokenization_energy': 0.13708284139633178,\n",
              "     'inference_energy': 23.860000000000582,\n",
              "     'energy_per_token': 1.9997569034497429,\n",
              "     'time': 0.5565183162689209,\n",
              "     'components': {'embeddings': np.float64(0.13768396973609925),\n",
              "      'attention': np.float64(14.144550220740259),\n",
              "      'ffn': np.float64(18.284193438995047),\n",
              "      'layernorm': np.float64(0.1296921443939209),\n",
              "      'output_layer': np.float64(0.21899312496185303)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find the third side of a right angled triangle.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef otherside_rightangle(w,h):\\r\\n  s=math.sqrt((w*w)+(h*h))\\r\\n  return s',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-order of a triangle triangle triangle given The',\n",
              "    'test_cases': ['assert otherside_rightangle(7,8)==10.63014581273465',\n",
              "     'assert otherside_rightangle(3,4)==5',\n",
              "     'assert otherside_rightangle(7,15)==16.55294535724685'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.65887577343639,\n",
              "     'tokenization_energy': 0.1268757734298706,\n",
              "     'inference_energy': 28.53200000000652,\n",
              "     'energy_per_token': 1.9105917182290926,\n",
              "     'time': 0.5629661083221436,\n",
              "     'components': {'embeddings': np.float64(0.1260992431640625),\n",
              "      'attention': np.float64(13.81802833223727),\n",
              "      'ffn': np.float64(13.68819865417399),\n",
              "      'layernorm': np.float64(0.1575935821533203),\n",
              "      'output_layer': np.float64(0.21697683668136597)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the maximum value in a given heterogeneous list.',\n",
              "    'ground_truth_code': 'def max_val(listval):\\r\\n     max_val = max(i for i in listval if isinstance(i, int)) \\r\\n     return(max_val)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number in a matrix matrix array of H',\n",
              "    'test_cases': [\"assert max_val(['Python', 3, 2, 4, 5, 'version'])==5\",\n",
              "     \"assert max_val(['Python', 15, 20, 25])==25\",\n",
              "     \"assert max_val(['Python', 30, 20, 40, 50, 'version'])==50\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.928284740927747,\n",
              "     'tokenization_energy': 0.12828474092483522,\n",
              "     'inference_energy': 23.80000000000291,\n",
              "     'energy_per_token': 1.5952189827285166,\n",
              "     'time': 0.555605411529541,\n",
              "     'components': {'embeddings': np.float64(0.12462827730178834),\n",
              "      'attention': np.float64(13.91123666739417),\n",
              "      'ffn': np.float64(18.15582392096857),\n",
              "      'layernorm': np.float64(0.13364453506469726),\n",
              "      'output_layer': np.float64(0.22207745838165283)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to return the sum of all divisors of a number.',\n",
              "    'ground_truth_code': 'def sum_div(number):\\r\\n    divisors = [1]\\r\\n    for i in range(2, number):\\r\\n        if (number % i)==0:\\r\\n            divisors.append(i)\\r\\n    return sum(divisors)',\n",
              "    'generated_code': ')\\n\\n the function that compute the minimum of all theisors of a number n If',\n",
              "    'test_cases': ['assert sum_div(8)==7',\n",
              "     'assert sum_div(12)==16',\n",
              "     'assert sum_div(7)==1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.785686449996543,\n",
              "     'tokenization_energy': 0.12868645000457765,\n",
              "     'inference_energy': 28.656999999991967,\n",
              "     'energy_per_token': 1.799105403124784,\n",
              "     'time': 0.555607795715332,\n",
              "     'components': {'embeddings': np.float64(4.804999999993015),\n",
              "      'attention': np.float64(18.878315214638715),\n",
              "      'ffn': np.float64(8.847977280851339),\n",
              "      'layernorm': np.float64(0.12970162057876589),\n",
              "      'output_layer': np.float64(0.2824960942268372)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to count inversions in an array.',\n",
              "    'ground_truth_code': 'def get_Inv_Count(arr,n): \\r\\n    inv_count = 0\\r\\n    for i in range(n): \\r\\n        for j in range(i + 1,n): \\r\\n            if (arr[i] > arr[j]): \\r\\n                inv_count += 1\\r\\n    return inv_count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute theersions in a array of An',\n",
              "    'test_cases': ['assert get_Inv_Count([1,20,6,4,5],5) == 5',\n",
              "     'assert get_Inv_Count([1,2,1],3) == 1',\n",
              "     'assert get_Inv_Count([1,2,5,6,1],5) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.201717698576044,\n",
              "     'tokenization_energy': 0.22771769857406618,\n",
              "     'inference_energy': 23.97400000000198,\n",
              "     'energy_per_token': 1.8616705921981571,\n",
              "     'time': 0.5542378425598145,\n",
              "     'components': {'embeddings': np.float64(0.1256795105934143),\n",
              "      'attention': np.float64(9.427190569397762),\n",
              "      'ffn': np.float64(9.213968362330924),\n",
              "      'layernorm': np.float64(0.12987271523475646),\n",
              "      'output_layer': np.float64(0.2165774781703949)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to flatten a given nested list structure.',\n",
              "    'ground_truth_code': 'def flatten_list(list1):\\r\\n    result_list = []\\r\\n    if not list1: return result_list\\r\\n    stack = [list(list1)]\\r\\n    while stack:\\r\\n        c_num = stack.pop()\\r\\n        next = c_num.pop()\\r\\n        if c_num: stack.append(c_num)\\r\\n        if isinstance(next, list):\\r\\n            if next: stack.append(list(next))\\r\\n        else: result_list.append(next)\\r\\n    result_list.reverse()\\r\\n    return result_list ',\n",
              "    'generated_code': ')\\n\\n the function that compute a binary matrix array into into The',\n",
              "    'test_cases': ['assert flatten_list([0, 10, [20, 30], 40, 50, [60, 70, 80], [90, 100, 110, 120]])==[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]',\n",
              "     'assert flatten_list([[10, 20], [40], [30, 56, 25], [10, 20], [33], [40]])==[10, 20, 40, 30, 56, 25, 10, 20, 33, 40]',\n",
              "     'assert flatten_list([[1,2,3], [4,5,6], [10,11,12], [7,8,9]])==[1, 2, 3, 4, 5, 6, 10, 11, 12, 7, 8, 9]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.49000000000524,\n",
              "     'tokenization_energy': 4.823000000003958,\n",
              "     'inference_energy': 23.66700000000128,\n",
              "     'energy_per_token': 2.374166666667103,\n",
              "     'time': 0.5607190132141113,\n",
              "     'components': {'embeddings': np.float64(0.12173738574981689),\n",
              "      'attention': np.float64(13.834584761139471),\n",
              "      'ffn': np.float64(13.505908344041558),\n",
              "      'layernorm': np.float64(0.1287484154701233),\n",
              "      'output_layer': np.float64(0.21798395252227784)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find the nested list elements which are present in another list.',\n",
              "    'ground_truth_code': 'def intersection_nested_lists(l1, l2):\\r\\n    result = [[n for n in lst if n in l1] for lst in l2]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum sum\\n that have not in the list. The',\n",
              "    'test_cases': ['assert intersection_nested_lists( [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],[[12, 18, 23, 25, 45], [7, 11, 19, 24, 28], [1, 5, 8, 18, 15, 16]])==[[12], [7, 11], [1, 5, 8]]',\n",
              "     'assert intersection_nested_lists([[2, 3, 1], [4, 5], [6, 8]], [[4, 5], [6, 8]])==[[], []]',\n",
              "     \"assert intersection_nested_lists(['john','amal','joel','george'],[['john'],['jack','john','mary'],['howard','john'],['jude']])==[['john'], ['john'], ['john'], []]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.803780324455932,\n",
              "     'tokenization_energy': 0.12278032445907593,\n",
              "     'inference_energy': 28.680999999996857,\n",
              "     'energy_per_token': 1.694340019085643,\n",
              "     'time': 0.5573306083679199,\n",
              "     'components': {'embeddings': np.float64(0.1266675868034363),\n",
              "      'attention': np.float64(18.317564732293835),\n",
              "      'ffn': np.float64(13.501285350815394),\n",
              "      'layernorm': np.float64(0.12599246406555176),\n",
              "      'output_layer': np.float64(4.841000000000349)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to calculate the maximum aggregate from the list of tuples.',\n",
              "    'ground_truth_code': 'from collections import defaultdict\\r\\ndef max_aggregate(stdata):\\r\\n    temp = defaultdict(int)\\r\\n    for name, marks in stdata:\\r\\n        temp[name] += marks\\r\\n    return max(temp.items(), key=lambda x: x[1])',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability number score a given of integers in The',\n",
              "    'test_cases': [\"assert max_aggregate([('Juan Whelan',90),('Sabah Colley',88),('Peter Nichols',7),('Juan Whelan',122),('Sabah Colley',84)])==('Juan Whelan', 212)\",\n",
              "     \"assert max_aggregate([('Juan Whelan',50),('Sabah Colley',48),('Peter Nichols',37),('Juan Whelan',22),('Sabah Colley',14)])==('Juan Whelan', 72)\",\n",
              "     \"assert max_aggregate([('Juan Whelan',10),('Sabah Colley',20),('Peter Nichols',30),('Juan Whelan',40),('Sabah Colley',50)])==('Sabah Colley', 70)\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.982216892245226,\n",
              "     'tokenization_energy': 0.12921689224243163,\n",
              "     'inference_energy': 23.853000000002794,\n",
              "     'energy_per_token': 1.5988144594830151,\n",
              "     'time': 0.5609972476959229,\n",
              "     'components': {'embeddings': np.float64(0.13047479820251465),\n",
              "      'attention': np.float64(18.53692594122479),\n",
              "      'ffn': np.float64(13.829481148726655),\n",
              "      'layernorm': np.float64(0.12901015090942383),\n",
              "      'output_layer': np.float64(0.21603238677978517)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the count of all binary sequences of length 2n such that sum of first n bits is same as sum of last n bits.',\n",
              "    'ground_truth_code': 'def count_binary_seq(n): \\r\\n\\tnCr = 1\\r\\n\\tres = 1\\r\\n\\tfor r in range(1, n + 1): \\r\\n\\t\\tnCr = (nCr * (n + 1 - r)) / r \\r\\n\\t\\tres += nCr * nCr \\r\\n\\treturn res ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of all possible numbers of length n6n that that the of any n elements is equal as sum of last n bits.\\n',\n",
              "    'test_cases': ['assert count_binary_seq(1) == 2.0',\n",
              "     'assert count_binary_seq(2) == 6.0',\n",
              "     'assert count_binary_seq(3) == 20.0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.974324031828786,\n",
              "     'tokenization_energy': 0.12232403182983399,\n",
              "     'inference_energy': 28.851999999998952,\n",
              "     'energy_per_token': 0.9054476259946496,\n",
              "     'time': 0.5665934085845947,\n",
              "     'components': {'embeddings': np.float64(0.1223924903869629),\n",
              "      'attention': np.float64(14.199614326241193),\n",
              "      'ffn': np.float64(13.988353506789894),\n",
              "      'layernorm': np.float64(0.12872468185424804),\n",
              "      'output_layer': np.float64(0.23529351544380187)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a function to find the depth of a dictionary.',\n",
              "    'ground_truth_code': 'def dict_depth(d):\\r\\n    if isinstance(d, dict):\\r\\n        return 1 + (max(map(dict_depth, d.values())) if d else 0)\\r\\n    return 0',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a binary, The',\n",
              "    'test_cases': [\"assert dict_depth({'a':1, 'b': {'c': {'d': {}}}})==4\",\n",
              "     \"assert dict_depth({'a':1, 'b': {'c':'python'}})==2\",\n",
              "     \"assert dict_depth({1: 'Sun', 2: {3: {4:'Mon'}}})==3\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.83391395020357,\n",
              "     'tokenization_energy': 0.12591395020484925,\n",
              "     'inference_energy': 28.70799999999872,\n",
              "     'energy_per_token': 2.402826162516964,\n",
              "     'time': 0.5594511032104492,\n",
              "     'components': {'embeddings': np.float64(0.1236835720539093),\n",
              "      'attention': np.float64(14.019417237997404),\n",
              "      'ffn': np.float64(18.397407869093122),\n",
              "      'layernorm': np.float64(0.12616750240325927),\n",
              "      'output_layer': np.float64(0.27810909390449523)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to find the most significant bit number which is also a set bit.',\n",
              "    'ground_truth_code': 'def set_Bit_Number(n): \\r\\n    if (n == 0): \\r\\n        return 0; \\r\\n    msb = 0; \\r\\n    n = int(n / 2); \\r\\n    while (n > 0): \\r\\n        n = int(n / 2); \\r\\n        msb += 1; \\r\\n    return (1 << msb)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number frequent digit of for is the the prime bit in So',\n",
              "    'test_cases': ['assert set_Bit_Number(6) == 4',\n",
              "     'assert set_Bit_Number(10) == 8',\n",
              "     'assert set_Bit_Number(18) == 16'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.16418806028913,\n",
              "     'tokenization_energy': 0.1551880602836609,\n",
              "     'inference_energy': 24.00900000000547,\n",
              "     'energy_per_token': 1.271799371594165,\n",
              "     'time': 0.5580203533172607,\n",
              "     'components': {'embeddings': np.float64(0.13792304992675783),\n",
              "      'attention': np.float64(14.09037930823583),\n",
              "      'ffn': np.float64(9.099828702204743),\n",
              "      'layernorm': np.float64(0.12816901683807372),\n",
              "      'output_layer': np.float64(0.29209696412086483)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to check whether the count of inversion of two types are same or not.',\n",
              "    'ground_truth_code': 'import sys \\r\\ndef solve(a,n):   \\r\\n    mx = -sys.maxsize - 1\\r\\n    for j in range(1,n):  \\r\\n        if (mx > a[j]):  \\r\\n            return False  \\r\\n        mx = max(mx,a[j - 1])    \\r\\n    return True',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given of the in a-digit of equal in not. The',\n",
              "    'test_cases': ['assert solve([1,0,2],3) == True',\n",
              "     'assert solve([1,2,0],3) == False',\n",
              "     'assert solve([1,2,1],3) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.99599995516846,\n",
              "     'tokenization_energy': 0.2179999551773071,\n",
              "     'inference_energy': 28.777999999991152,\n",
              "     'energy_per_token': 1.449799997758423,\n",
              "     'time': 0.5601692199707031,\n",
              "     'components': {'embeddings': np.float64(0.1211974332332611),\n",
              "      'attention': np.float64(13.909006035328026),\n",
              "      'ffn': np.float64(18.497362508524557),\n",
              "      'layernorm': np.float64(4.777000000001863),\n",
              "      'output_layer': np.float64(0.2938375203609467)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to find element at a given index after number of rotations.',\n",
              "    'ground_truth_code': 'def find_Element(arr,ranges,rotations,index) :  \\r\\n    for i in range(rotations - 1,-1,-1 ) : \\r\\n        left = ranges[i][0] \\r\\n        right = ranges[i][1] \\r\\n        if (left <= index and right >= index) : \\r\\n            if (index == left) : \\r\\n                index = right \\r\\n            else : \\r\\n                index = index - 1 \\r\\n    return arr[index] ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the in position position position in removing of elements, \\n',\n",
              "    'test_cases': ['assert find_Element([1,2,3,4,5],[[0,2],[0,3]],2,1) == 3',\n",
              "     'assert find_Element([1,2,3,4],[[0,1],[0,2]],1,2) == 3',\n",
              "     'assert find_Element([1,2,3,4,5,6],[[0,1],[0,2]],1,1) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.117813068868823,\n",
              "     'tokenization_energy': 0.19681306886672975,\n",
              "     'inference_energy': 23.921000000002095,\n",
              "     'energy_per_token': 1.4186948864040485,\n",
              "     'time': 0.5621333122253418,\n",
              "     'components': {'embeddings': np.float64(0.12171246528625489),\n",
              "      'attention': np.float64(9.346445935484022),\n",
              "      'ffn': np.float64(13.58448606253194),\n",
              "      'layernorm': np.float64(0.12560842037200928),\n",
              "      'output_layer': np.float64(0.22649532508850095)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': \"Write a function to match two words from a list of words starting with letter 'p'.\",\n",
              "    'ground_truth_code': 'import re\\r\\ndef start_withp(words):\\r\\n for w in words:\\r\\n        m = re.match(\"(P\\\\w+)\\\\W(P\\\\w+)\", w)\\r\\n        if m:\\r\\n            return m.groups()',\n",
              "    'generated_code': \")\\n\\n the function that compute the strings with a word of words, from the AA' The\",\n",
              "    'test_cases': ['assert start_withp([\"Python PHP\", \"Java JavaScript\", \"c c++\"])==(\\'Python\\', \\'PHP\\')',\n",
              "     'assert start_withp([\"Python Programming\",\"Java Programming\"])==(\\'Python\\',\\'Programming\\')',\n",
              "     'assert start_withp([\"Pqrst Pqr\",\"qrstuv\"])==(\\'Pqrst\\',\\'Pqr\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.839395957235713,\n",
              "     'tokenization_energy': 0.1223959572315216,\n",
              "     'inference_energy': 28.71700000000419,\n",
              "     'energy_per_token': 1.517862945117669,\n",
              "     'time': 0.5525410175323486,\n",
              "     'components': {'embeddings': np.float64(4.834000000002561),\n",
              "      'attention': np.float64(18.414985705862286),\n",
              "      'ffn': np.float64(13.76021379708429),\n",
              "      'layernorm': np.float64(0.13084963130950927),\n",
              "      'output_layer': np.float64(0.2379243206977844)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the maximum sum of increasing subsequence from prefix till ith index and also including a given kth element which is after i, i.e., k > i .',\n",
              "    'ground_truth_code': 'def max_sum_increasing_subseq(a, n, index, k):\\r\\n\\tdp = [[0 for i in range(n)] \\r\\n\\t\\t\\tfor i in range(n)]\\r\\n\\tfor i in range(n):\\r\\n\\t\\tif a[i] > a[0]:\\r\\n\\t\\t\\tdp[0][i] = a[i] + a[0]\\r\\n\\t\\telse:\\r\\n\\t\\t\\tdp[0][i] = a[i]\\r\\n\\tfor i in range(1, n):\\r\\n\\t\\tfor j in range(n):\\r\\n\\t\\t\\tif a[j] > a[i] and j > i:\\r\\n\\t\\t\\t\\tif dp[i - 1][i] + a[j] > dp[i - 1][j]:\\r\\n\\t\\t\\t\\t\\tdp[i][j] = dp[i - 1][i] + a[j]\\r\\n\\t\\t\\t\\telse:\\r\\n\\t\\t\\t\\t\\tdp[i][j] = dp[i - 1][j]\\r\\n\\t\\t\\telse:\\r\\n\\t\\t\\t\\tdp[i][j] = dp[i - 1][j]\\r\\n\\treturn dp[index][k]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of a subsequarrays of a to the element in then find the new value-th element in is in the.\\n\\n but.e',\n",
              "    'test_cases': ['assert max_sum_increasing_subseq([1, 101, 2, 3, 100, 4, 5 ], 7, 4, 6) == 11',\n",
              "     'assert max_sum_increasing_subseq([1, 101, 2, 3, 100, 4, 5 ], 7, 2, 5) == 7',\n",
              "     'assert max_sum_increasing_subseq([11, 15, 19, 21, 26, 28, 31], 7, 2, 4) == 71'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.36417116308352,\n",
              "     'tokenization_energy': 0.1251711630821228,\n",
              "     'inference_energy': 24.239000000001397,\n",
              "     'energy_per_token': 0.76138034884636,\n",
              "     'time': 0.560420036315918,\n",
              "     'components': {'embeddings': np.float64(0.12643045377731324),\n",
              "      'attention': np.float64(9.565221446983514),\n",
              "      'ffn': np.float64(9.162149383789977),\n",
              "      'layernorm': np.float64(0.13395214080810547),\n",
              "      'output_layer': np.float64(0.2454524803161621)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a function to get a colon of a tuple.',\n",
              "    'ground_truth_code': 'from copy import deepcopy\\r\\ndef colon_tuplex(tuplex,m,n):\\r\\n  tuplex_colon = deepcopy(tuplex)\\r\\n  tuplex_colon[m].append(n)\\r\\n  return tuplex_colon',\n",
              "    'generated_code': ')\\n\\n the function that compute the function in a given of So',\n",
              "    'test_cases': ['assert colon_tuplex((\"HELLO\", 5, [], True) ,2,50)==(\"HELLO\", 5, [50], True) ',\n",
              "     'assert colon_tuplex((\"HELLO\", 5, [], True) ,2,100)==((\"HELLO\", 5, [100],True))',\n",
              "     'assert colon_tuplex((\"HELLO\", 5, [], True) ,2,500)==(\"HELLO\", 5, [500], True)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.049682614812276,\n",
              "     'tokenization_energy': 0.1306826148033142,\n",
              "     'inference_energy': 23.919000000008964,\n",
              "     'energy_per_token': 2.004140217901023,\n",
              "     'time': 0.5611889362335205,\n",
              "     'components': {'embeddings': np.float64(0.13023503017425536),\n",
              "      'attention': np.float64(18.57425381970184),\n",
              "      'ffn': np.float64(13.713544192563742),\n",
              "      'layernorm': np.float64(0.12568038082122804),\n",
              "      'output_layer': np.float64(0.21005431509017947)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find the specified number of largest products from two given lists.',\n",
              "    'ground_truth_code': 'def large_product(nums1, nums2, N):\\r\\n    result = sorted([x*y for x in nums1 for y in nums2], reverse=True)[:N]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum\\n of the elements in a arrays arrays of The',\n",
              "    'test_cases': ['assert large_product([1, 2, 3, 4, 5, 6],[3, 6, 8, 9, 10, 6],3)==[60, 54, 50]',\n",
              "     'assert large_product([1, 2, 3, 4, 5, 6],[3, 6, 8, 9, 10, 6],4)==[60, 54, 50, 48]',\n",
              "     'assert large_product([1, 2, 3, 4, 5, 6],[3, 6, 8, 9, 10, 6],5)==[60, 54, 50, 48, 45]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.629909965506055,\n",
              "     'tokenization_energy': 0.12090996551513672,\n",
              "     'inference_energy': 28.50899999999092,\n",
              "     'energy_per_token': 1.684112350912121,\n",
              "     'time': 0.5618841648101807,\n",
              "     'components': {'embeddings': np.float64(0.12018548655509949),\n",
              "      'attention': np.float64(13.913918030261993),\n",
              "      'ffn': np.float64(13.769982568734441),\n",
              "      'layernorm': np.float64(4.730999999999767),\n",
              "      'output_layer': np.float64(0.29715237069129946)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find the maximum of two numbers.',\n",
              "    'ground_truth_code': 'def maximum(a,b):   \\r\\n    if a >= b: \\r\\n        return a \\r\\n    else: \\r\\n        return b ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number a numbers a The',\n",
              "    'test_cases': ['assert maximum(5,10) == 10',\n",
              "     'assert maximum(-1,-2) == -1',\n",
              "     'assert maximum(9,7) == 9'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.14884598350979,\n",
              "     'tokenization_energy': 0.21584598350524903,\n",
              "     'inference_energy': 23.93300000000454,\n",
              "     'energy_per_token': 1.8576035371930608,\n",
              "     'time': 0.5665876865386963,\n",
              "     'components': {'embeddings': np.float64(0.12334218764305115),\n",
              "      'attention': np.float64(14.118137568470091),\n",
              "      'ffn': np.float64(13.613085529335775),\n",
              "      'layernorm': np.float64(0.12549112367630005),\n",
              "      'output_layer': np.float64(0.23956886219978332)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to convert a given string to a tuple.',\n",
              "    'ground_truth_code': 'def string_to_tuple(str1):\\r\\n    result = tuple(x for x in str1 if not x.isspace()) \\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute a given integer of a given of The',\n",
              "    'test_cases': ['assert string_to_tuple(\"python 3.0\")==(\\'p\\', \\'y\\', \\'t\\', \\'h\\', \\'o\\', \\'n\\', \\'3\\', \\'.\\', \\'0\\')',\n",
              "     'assert string_to_tuple(\"item1\")==(\\'i\\', \\'t\\', \\'e\\', \\'m\\', \\'1\\')',\n",
              "     'assert string_to_tuple(\"15.10\")==(\\'1\\', \\'5\\', \\'.\\', \\'1\\', \\'0\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.86331631612615,\n",
              "     'tokenization_energy': 0.12131631612777709,\n",
              "     'inference_energy': 23.74199999999837,\n",
              "     'energy_per_token': 1.8356397166250884,\n",
              "     'time': 0.5671069622039795,\n",
              "     'components': {'embeddings': np.float64(0.12355767488479615),\n",
              "      'attention': np.float64(18.446179587130782),\n",
              "      'ffn': np.float64(14.13108367609314),\n",
              "      'layernorm': np.float64(0.12816404628753664),\n",
              "      'output_layer': np.float64(0.21381365418434145)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to set the left most unset bit.',\n",
              "    'ground_truth_code': 'def set_left_most_unset_bit(n): \\r\\n    if not (n & (n + 1)): \\r\\n        return n \\r\\n    pos, temp, count = 0, n, 0 \\r\\n    while temp: \\r\\n        if not (temp & 1): \\r\\n            pos = count      \\r\\n        count += 1; temp>>=1\\r\\n    return (n | (1 << (pos))) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the bitmost bit bit in If',\n",
              "    'test_cases': ['assert set_left_most_unset_bit(10) == 14',\n",
              "     'assert set_left_most_unset_bit(12) == 14',\n",
              "     'assert set_left_most_unset_bit(15) == 15'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.7449003050396,\n",
              "     'tokenization_energy': 0.12190030503273011,\n",
              "     'inference_energy': 28.62300000000687,\n",
              "     'energy_per_token': 2.2111461773107384,\n",
              "     'time': 0.5636932849884033,\n",
              "     'components': {'embeddings': np.float64(0.21260605001449587),\n",
              "      'attention': np.float64(9.313635231015155),\n",
              "      'ffn': np.float64(9.033148297790436),\n",
              "      'layernorm': np.float64(4.706000000005588),\n",
              "      'output_layer': np.float64(0.3097429347038269)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the volume of a cone.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef volume_cone(r,h):\\r\\n  volume = (1.0/3) * math.pi * r * r * h\\r\\n  return volume',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a cube given The',\n",
              "    'test_cases': ['assert volume_cone(5,12)==314.15926535897927',\n",
              "     'assert volume_cone(10,15)==1570.7963267948965',\n",
              "     'assert volume_cone(19,17)==6426.651371693521'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.01474263763067,\n",
              "     'tokenization_energy': 0.12174263763427734,\n",
              "     'inference_energy': 23.89299999999639,\n",
              "     'energy_per_token': 2.001228553135889,\n",
              "     'time': 0.5562953948974609,\n",
              "     'components': {'embeddings': np.float64(0.12191273260116577),\n",
              "      'attention': np.float64(4.640955823421478),\n",
              "      'ffn': np.float64(4.5560941021442405),\n",
              "      'layernorm': np.float64(0.1265981538295746),\n",
              "      'output_layer': np.float64(0.21364500904083253)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a python function to print positive numbers in a list.',\n",
              "    'ground_truth_code': 'def pos_nos(list1):\\r\\n  for num in list1: \\r\\n    if num >= 0: \\r\\n       return num ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the integers in a given of The',\n",
              "    'test_cases': ['assert pos_nos([-1,-2,1,2]) == 1,2',\n",
              "     'assert pos_nos([3,4,-5]) == 3,4',\n",
              "     'assert pos_nos([-2,-3,1]) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.870852449417114,\n",
              "     'tokenization_energy': 0.12085244941711426,\n",
              "     'inference_energy': 28.75,\n",
              "     'energy_per_token': 2.2208348038013166,\n",
              "     'time': 0.5572109222412109,\n",
              "     'components': {'embeddings': np.float64(0.12113576817512513),\n",
              "      'attention': np.float64(13.850594499109082),\n",
              "      'ffn': np.float64(13.47818635177682),\n",
              "      'layernorm': np.float64(0.12682289958000184),\n",
              "      'output_layer': np.float64(0.21035297632217406)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find out the maximum sum such that no two chosen numbers are adjacent for the given rectangular grid of dimension 2 x n.',\n",
              "    'ground_truth_code': 'def max_sum_rectangular_grid(grid, n) : \\r\\n\\tincl = max(grid[0][0], grid[1][0]) \\r\\n\\texcl = 0\\r\\n\\tfor i in range(1, n) : \\r\\n\\t\\texcl_new = max(excl, incl) \\r\\n\\t\\tincl = excl + max(grid[0][i], grid[1][i]) \\r\\n\\t\\texcl = excl_new \\r\\n\\treturn max(excl, incl)',\n",
              "    'generated_code': ')\\n\\n the function that compute the the number number of that no two elements numbers are adjacent in a given array matrix.\\n numbers N {x N.\\n The',\n",
              "    'test_cases': ['assert max_sum_rectangular_grid([ [1, 4, 5], [2, 0, 0 ] ], 3) == 7',\n",
              "     'assert max_sum_rectangular_grid([ [ 1, 2, 3, 4, 5], [ 6, 7, 8, 9, 10] ], 5) == 24',\n",
              "     'assert max_sum_rectangular_grid([ [7, 9, 11, 15, 19], [21, 25, 28, 31, 32] ], 5) == 81'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.244006630416845,\n",
              "     'tokenization_energy': 0.12000663042068481,\n",
              "     'inference_energy': 24.12399999999616,\n",
              "     'energy_per_token': 0.8081335543472281,\n",
              "     'time': 0.5577371120452881,\n",
              "     'components': {'embeddings': np.float64(0.1359560286998749),\n",
              "      'attention': np.float64(18.804561075677046),\n",
              "      'ffn': np.float64(14.037429194218479),\n",
              "      'layernorm': np.float64(0.19830013155937193),\n",
              "      'output_layer': np.float64(0.24002856826782226)},\n",
              "     'num_tokens': 30}},\n",
              "   {'prompt': 'Write a python function to find the first maximum length of even word.',\n",
              "    'ground_truth_code': 'def find_Max_Len_Even(str): \\r\\n    n = len(str) \\r\\n    i = 0\\r\\n    currlen = 0\\r\\n    maxlen = 0\\r\\n    st = -1\\r\\n    while (i < n): \\r\\n        if (str[i] == \\' \\'): \\r\\n            if (currlen % 2 == 0): \\r\\n                if (maxlen < currlen): \\r\\n                    maxlen = currlen \\r\\n                    st = i - currlen \\r\\n            currlen = 0 \\r\\n        else : \\r\\n            currlen += 1\\r\\n        i += 1\\r\\n    if (currlen % 2 == 0): \\r\\n        if (maxlen < currlen): \\r\\n            maxlen = currlen \\r\\n            st = i - currlen \\r\\n    if (st == -1): \\r\\n        return \"-1\" \\r\\n    return str[st: st + maxlen] ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence in of a numbers in So',\n",
              "    'test_cases': ['assert find_Max_Len_Even(\"python language\") == \"language\"',\n",
              "     'assert find_Max_Len_Even(\"maximum even length\") == \"length\"',\n",
              "     'assert find_Max_Len_Even(\"eve\") == \"-1\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.829000000012456,\n",
              "     'tokenization_energy': 4.885000000009313,\n",
              "     'inference_energy': 23.944000000003143,\n",
              "     'energy_per_token': 1.9219333333341637,\n",
              "     'time': 0.5614378452301025,\n",
              "     'components': {'embeddings': np.float64(0.1910731315612793),\n",
              "      'attention': np.float64(18.667975163941275),\n",
              "      'ffn': np.float64(13.85258001017419),\n",
              "      'layernorm': np.float64(0.13140744590759276),\n",
              "      'output_layer': np.float64(0.2244516019821167)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the index of the last occurrence of a given number in a sorted array.',\n",
              "    'ground_truth_code': 'def find_last_occurrence(A, x):\\r\\n    (left, right) = (0, len(A) - 1)\\r\\n    result = -1\\r\\n    while left <= right:\\r\\n        mid = (left + right) // 2\\r\\n        if x == A[mid]:\\r\\n            result = mid\\r\\n            left = mid + 1\\r\\n        elif x < A[mid]:\\r\\n            right = mid - 1\\r\\n        else:\\r\\n            left = mid + 1\\r\\n    return result ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of the maximum element of a value value in a given array.\\n If',\n",
              "    'test_cases': ['assert find_last_occurrence([2, 5, 5, 5, 6, 6, 8, 9, 9, 9], 5) == 3',\n",
              "     'assert find_last_occurrence([2, 3, 5, 8, 6, 6, 8, 9, 9, 9], 9) == 9',\n",
              "     'assert find_last_occurrence([2, 2, 1, 5, 6, 6, 6, 9, 9, 9], 6) == 6'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.97451100158505,\n",
              "     'tokenization_energy': 0.12651100158691406,\n",
              "     'inference_energy': 28.847999999998137,\n",
              "     'energy_per_token': 1.3797386191230976,\n",
              "     'time': 0.5593938827514648,\n",
              "     'components': {'embeddings': np.float64(0.164148024559021),\n",
              "      'attention': np.float64(18.668684003569883),\n",
              "      'ffn': np.float64(14.02661544037843),\n",
              "      'layernorm': np.float64(0.1332237148284912),\n",
              "      'output_layer': np.float64(0.2607782635688782)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function to reflect the modified run-length encoding from a list.',\n",
              "    'ground_truth_code': 'from itertools import groupby\\r\\ndef modified_encode(alist):\\r\\n        def ctr_ele(el):\\r\\n            if len(el)>1: return [len(el), el[0]]\\r\\n            else: return el[0]\\r\\n        return [ctr_ele(list(group)) for key, group in groupby(alist)]',\n",
              "    'generated_code': ')\\n\\n the function that compute a points\\n-length encoding of the modified of The',\n",
              "    'test_cases': ['assert modified_encode([1,1,2,3,4,4,5,1])==[[2, 1], 2, 3, [2, 4], 5, 1]',\n",
              "     \"assert modified_encode('automatically')==['a', 'u', 't', 'o', 'm', 'a', 't', 'i', 'c', 'a', [2, 'l'], 'y']\",\n",
              "     \"assert modified_encode('python')==['p', 'y', 't', 'h', 'o', 'n']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.29525292253017,\n",
              "     'tokenization_energy': 0.12225292253494262,\n",
              "     'inference_energy': 24.172999999995227,\n",
              "     'energy_per_token': 1.619683528168678,\n",
              "     'time': 0.5587105751037598,\n",
              "     'components': {'embeddings': np.float64(0.12274052810668945),\n",
              "      'attention': np.float64(18.74049598455045),\n",
              "      'ffn': np.float64(13.883878729104067),\n",
              "      'layernorm': np.float64(0.12905380249023438),\n",
              "      'output_layer': np.float64(0.21920677185058593)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the maximum volume of a cuboid with given sum of sides.',\n",
              "    'ground_truth_code': 'def max_volume (s): \\r\\n    maxvalue = 0\\r\\n    i = 1\\r\\n    for i in range(s - 1): \\r\\n        j = 1\\r\\n        for j in range(s): \\r\\n            k = s - i - j \\r\\n            maxvalue = max(maxvalue, i * j * k)         \\r\\n    return maxvalue ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number of a rectangularoid with the... of edges, The',\n",
              "    'test_cases': ['assert max_volume(8) == 18',\n",
              "     'assert max_volume(4) == 2',\n",
              "     'assert max_volume(1) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.936020935063947,\n",
              "     'tokenization_energy': 0.12402093505859374,\n",
              "     'inference_energy': 28.812000000005355,\n",
              "     'energy_per_token': 1.4468010467531973,\n",
              "     'time': 0.5641827583312988,\n",
              "     'components': {'embeddings': np.float64(0.19093729400634765),\n",
              "      'attention': np.float64(14.355390915392782),\n",
              "      'ffn': np.float64(9.169900707250811),\n",
              "      'layernorm': np.float64(0.12727934074401856),\n",
              "      'output_layer': np.float64(0.23222120261192322)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find all five characters long word in the given string by using regex.',\n",
              "    'ground_truth_code': 'import re\\r\\ndef find_long_word(text):\\r\\n  return (re.findall(r\"\\\\b\\\\w{5}\\\\b\", text))',\n",
              "    'generated_code': ')\\n\\n the function that compute the the-digit in pal in a five string, using the, The',\n",
              "    'test_cases': [\"assert find_long_word('Please move back to strem') == ['strem']\",\n",
              "     \"assert find_long_word('4K Ultra HD streaming player') == ['Ultra']\",\n",
              "     \"assert find_long_word('Streaming Media Player') == ['Media']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.081601944919093,\n",
              "     'tokenization_energy': 0.12060194492340089,\n",
              "     'inference_energy': 23.960999999995693,\n",
              "     'energy_per_token': 1.26745273394311,\n",
              "     'time': 0.5579087734222412,\n",
              "     'components': {'embeddings': np.float64(0.12239621114730835),\n",
              "      'attention': np.float64(9.319919445274746),\n",
              "      'ffn': np.float64(9.217495384691167),\n",
              "      'layernorm': np.float64(0.13506954288482667),\n",
              "      'output_layer': np.float64(0.2394484214782715)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to calculate the difference between the squared sum of first n natural numbers and the sum of squared first n natural numbers.',\n",
              "    'ground_truth_code': 'def sum_difference(n):\\r\\n    sumofsquares = 0\\r\\n    squareofsum = 0\\r\\n    for num in range(1, n+1):\\r\\n        sumofsquares += num * num\\r\\n        squareofsum += num\\r\\n    squareofsum = squareofsum ** 2\\r\\n    return squareofsum - sumofsquares',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability between the two sums and two n integers numbers and the sum of the first n natural numbers. Return',\n",
              "    'test_cases': ['assert sum_difference(12)==5434',\n",
              "     'assert sum_difference(20)==41230',\n",
              "     'assert sum_difference(54)==2151270'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.128865243922455,\n",
              "     'tokenization_energy': 0.12986524391174317,\n",
              "     'inference_energy': 23.99900000001071,\n",
              "     'energy_per_token': 0.8936616757008317,\n",
              "     'time': 0.5578474998474121,\n",
              "     'components': {'embeddings': np.float64(0.13109197616577148),\n",
              "      'attention': np.float64(18.577556299950345),\n",
              "      'ffn': np.float64(14.024055871948718),\n",
              "      'layernorm': np.float64(0.13472925806045533),\n",
              "      'output_layer': np.float64(0.23519059610366821)},\n",
              "     'num_tokens': 27}},\n",
              "   {'prompt': 'Write a function to find the demlo number for the given number.',\n",
              "    'ground_truth_code': 'def find_demlo(s): \\r\\n\\tl = len(s) \\r\\n\\tres = \"\" \\r\\n\\tfor i in range(1,l+1): \\r\\n\\t\\tres = res + str(i) \\r\\n\\tfor i in range(l-1,0,-1): \\r\\n\\t\\tres = res + str(i) \\r\\n\\treturn res \\t',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximumical numbers for a given n n The',\n",
              "    'test_cases': ['assert find_demlo(\"111111\") == \\'12345654321\\'',\n",
              "     'assert find_demlo(\"1111\") == \\'1234321\\'',\n",
              "     'assert find_demlo(\"13333122222\") == \\'123456789101110987654321\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.901662556635564,\n",
              "     'tokenization_energy': 0.1246625566482544,\n",
              "     'inference_energy': 28.77699999998731,\n",
              "     'energy_per_token': 1.9267775037757042,\n",
              "     'time': 0.5589814186096191,\n",
              "     'components': {'embeddings': np.float64(0.18238897609710694),\n",
              "      'attention': np.float64(4.7408228554725635),\n",
              "      'ffn': np.float64(4.430118807792664),\n",
              "      'layernorm': np.float64(0.13269748282432556),\n",
              "      'output_layer': np.float64(0.25647456192970275)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find all index positions of the minimum values in a given list.',\n",
              "    'ground_truth_code': 'def position_min(list1):\\r\\n    min_val = min(list1)\\r\\n    min_result = [i for i, j in enumerate(list1) if j == min_val]\\r\\n    return min_result',\n",
              "    'generated_code': ')\\n\\n the function that compute the the pairs of the two value in a given matrix of If',\n",
              "    'test_cases': ['assert position_min([12,33,23,10,67,89,45,667,23,12,11,10,54])==[3,11]',\n",
              "     'assert position_min([1,2,2,2,4,4,4,5,5,5,5])==[0]',\n",
              "     'assert position_min([2,1,5,6,8,3,4,9,10,11,8,12])==[1]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.24494310426712,\n",
              "     'tokenization_energy': 0.11994310426712036,\n",
              "     'inference_energy': 24.125,\n",
              "     'energy_per_token': 1.3469412835703956,\n",
              "     'time': 0.5637803077697754,\n",
              "     'components': {'embeddings': np.float64(0.18203446626663208),\n",
              "      'attention': np.float64(14.112317213531467),\n",
              "      'ffn': np.float64(9.01457181620272),\n",
              "      'layernorm': np.float64(0.12769323682785033),\n",
              "      'output_layer': np.float64(0.23311838102340698)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to re-arrange the given array in alternating positive and negative items.',\n",
              "    'ground_truth_code': 'def right_rotate(arr, n, out_of_place, cur):\\r\\n\\ttemp = arr[cur]\\r\\n\\tfor i in range(cur, out_of_place, -1):\\r\\n\\t\\tarr[i] = arr[i - 1]\\r\\n\\tarr[out_of_place] = temp\\r\\n\\treturn arr\\r\\ndef re_arrange(arr, n):\\r\\n\\tout_of_place = -1\\r\\n\\tfor index in range(n):\\r\\n\\t\\tif (out_of_place >= 0):\\r\\n\\t\\t\\tif ((arr[index] >= 0 and arr[out_of_place] < 0) or\\r\\n\\t\\t\\t(arr[index] < 0 and arr[out_of_place] >= 0)):\\r\\n\\t\\t\\t\\tarr = right_rotate(arr, n, out_of_place, index)\\r\\n\\t\\t\\t\\tif (index-out_of_place > 2):\\r\\n\\t\\t\\t\\t\\tout_of_place += 2\\r\\n\\t\\t\\t\\telse:\\r\\n\\t\\t\\t\\t\\tout_of_place = - 1\\r\\n\\t\\tif (out_of_place == -1):\\r\\n\\t\\t\\tif ((arr[index] >= 0 and index % 2 == 0) or\\r\\n\\t\\t\\t (arr[index] < 0 and index % 2 == 1)):\\r\\n\\t\\t\\t\\tout_of_place = index\\r\\n\\treturn arr',\n",
              "    'generated_code': ')\\n\\n the function that computeorganconvertange the digits matrix in a even and negative order, For',\n",
              "    'test_cases': ['assert re_arrange([-5, -2, 5, 2, 4,\\t7, 1, 8, 0, -8], 10) == [-5, 5, -2, 2, -8, 4, 7, 1, 8, 0]',\n",
              "     'assert re_arrange([1, 2, 3, -4, -1, 4], 6) == [-4, 1, -1, 2, 3, 4]',\n",
              "     'assert re_arrange([4, 7, 9, 77, -4, 5, -3, -9], 8) == [-4, 4, -3, 7, -9, 9, 77, 5]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.89994271040149,\n",
              "     'tokenization_energy': 0.12294271039962767,\n",
              "     'inference_energy': 28.777000000001863,\n",
              "     'energy_per_token': 1.5210496163369205,\n",
              "     'time': 0.5573015213012695,\n",
              "     'components': {'embeddings': np.float64(4.817000000010012),\n",
              "      'attention': np.float64(18.442284008738003),\n",
              "      'ffn': np.float64(13.692441781277653),\n",
              "      'layernorm': np.float64(0.12531755304336548),\n",
              "      'output_layer': np.float64(0.23296734833717347)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to extract the sum of alternate chains of tuples.',\n",
              "    'ground_truth_code': 'def sum_of_alternates(test_tuple):\\r\\n  sum1 = 0\\r\\n  sum2 = 0\\r\\n  for idx, ele in enumerate(test_tuple):\\r\\n    if idx % 2:\\r\\n      sum1 += ele\\r\\n    else:\\r\\n      sum2 += ele\\r\\n  return ((sum1),(sum2)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits of all even of a in The',\n",
              "    'test_cases': ['assert sum_of_alternates((5, 6, 3, 6, 10, 34)) == (46, 18)',\n",
              "     'assert sum_of_alternates((1, 2, 3, 4, 5)) == (6, 9)',\n",
              "     'assert sum_of_alternates((6, 7, 8, 9, 4, 5)) == (21, 18)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.232827065949095,\n",
              "     'tokenization_energy': 0.12182706594467163,\n",
              "     'inference_energy': 24.111000000004424,\n",
              "     'energy_per_token': 1.730916218996364,\n",
              "     'time': 0.5616652965545654,\n",
              "     'components': {'embeddings': np.float64(0.1234249837398529),\n",
              "      'attention': np.float64(14.019723974227439),\n",
              "      'ffn': np.float64(13.711012676232142),\n",
              "      'layernorm': np.float64(0.1313697636127472),\n",
              "      'output_layer': np.float64(0.21398233461380006)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the minimum number of squares whose sum is equal to a given number.',\n",
              "    'ground_truth_code': 'def get_Min_Squares(n):\\r\\n    if n <= 3:\\r\\n        return n;\\r\\n    res = n \\r\\n    for x in range(1,n + 1):\\r\\n        temp = x * x;\\r\\n        if temp > n:\\r\\n            break\\r\\n        else:\\r\\n            res = min(res,1 + get_Min_Squares(n  - temp)) \\r\\n    return res;',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number of coins of sum is equal to the given n n The',\n",
              "    'test_cases': ['assert get_Min_Squares(6) == 3',\n",
              "     'assert get_Min_Squares(2) == 2',\n",
              "     'assert get_Min_Squares(4) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.13311364530446,\n",
              "     'tokenization_energy': 0.13211364531517028,\n",
              "     'inference_energy': 24.00099999998929,\n",
              "     'energy_per_token': 1.1491958878716408,\n",
              "     'time': 0.5589721202850342,\n",
              "     'components': {'embeddings': np.float64(0.13302847528457643),\n",
              "      'attention': np.float64(14.240575841425333),\n",
              "      'ffn': np.float64(14.09453332566144),\n",
              "      'layernorm': np.float64(0.13198814392089844),\n",
              "      'output_layer': np.float64(0.24089126586914064)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function to get the word with most number of occurrences in the given strings list.',\n",
              "    'ground_truth_code': 'from collections import defaultdict \\r\\n\\r\\ndef most_occurrences(test_list):\\r\\n  temp = defaultdict(int)\\r\\n  for sub in test_list:\\r\\n    for wrd in sub.split():\\r\\n      temp[wrd] += 1\\r\\n  res = max(temp, key=temp.get)\\r\\n  return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum that the unique of unique in a array array.. If',\n",
              "    'test_cases': ['assert most_occurrences([\"UTS is best for RTF\", \"RTF love UTS\", \"UTS is best\"] ) == \\'UTS\\'',\n",
              "     'assert most_occurrences([\"Its been a great year\", \"this year is so worse\", \"this year is okay\"] ) == \\'year\\'',\n",
              "     'assert most_occurrences([\"Families can be reunited\", \"people can be reunited\", \"Tasks can be achieved \"] ) == \\'can\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.964061458586364,\n",
              "     'tokenization_energy': 0.13106145858764648,\n",
              "     'inference_energy': 28.83299999999872,\n",
              "     'energy_per_token': 1.5244242872940192,\n",
              "     'time': 0.5586798191070557,\n",
              "     'components': {'embeddings': np.float64(0.12704973220825197),\n",
              "      'attention': np.float64(13.831974976056255),\n",
              "      'ffn': np.float64(18.637226232058484),\n",
              "      'layernorm': np.float64(4.760999999998603),\n",
              "      'output_layer': np.float64(0.23081855964660644)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to print check if the triangle is isosceles or not.',\n",
              "    'ground_truth_code': 'def check_isosceles(x,y,z):\\r\\n  if x==y or y==z or z==x:\\r\\n\\t   return True\\r\\n  else:\\r\\n     return False',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits a number is equosceles, equ.\\n The',\n",
              "    'test_cases': ['assert check_isosceles(6,8,12)==False ',\n",
              "     'assert check_isosceles(6,6,12)==True',\n",
              "     'assert check_isosceles(6,16,20)==False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.204600788125884,\n",
              "     'tokenization_energy': 0.12260078811645507,\n",
              "     'inference_energy': 24.08200000000943,\n",
              "     'energy_per_token': 1.3447000437847714,\n",
              "     'time': 0.560511589050293,\n",
              "     'components': {'embeddings': np.float64(0.12361925506591796),\n",
              "      'attention': np.float64(9.306899051913643),\n",
              "      'ffn': np.float64(9.361405413148692),\n",
              "      'layernorm': np.float64(0.12690943384170533),\n",
              "      'output_layer': np.float64(0.23410489106178284)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to rotate a given list by specified number of items to the left direction.',\n",
              "    'ground_truth_code': 'def rotate_left(list1,m,n):\\r\\n  result =  list1[m:]+list1[:n]\\r\\n  return result',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix matrix of ...\\n of positions, the right.\\n.\\n So',\n",
              "    'test_cases': ['assert rotate_left([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],3,4)==[4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4]',\n",
              "     'assert rotate_left([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],2,2)==[3, 4, 5, 6, 7, 8, 9, 10, 1, 2]',\n",
              "     'assert rotate_left([1, 2, 3, 4, 5, 6, 7, 8, 9, 10],5,2)==[6, 7, 8, 9, 10, 1, 2]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.053233464714722,\n",
              "     'tokenization_energy': 0.12223346471786499,\n",
              "     'inference_energy': 28.930999999996857,\n",
              "     'energy_per_token': 1.529117550774459,\n",
              "     'time': 0.5584073066711426,\n",
              "     'components': {'embeddings': np.float64(4.870999999999185),\n",
              "      'attention': np.float64(18.575433815476714),\n",
              "      'ffn': np.float64(13.893821348667377),\n",
              "      'layernorm': np.float64(0.12850836753845216),\n",
              "      'output_layer': np.float64(0.24721018314361573)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to count negative numbers in a list.',\n",
              "    'ground_truth_code': 'def neg_count(list):\\r\\n  neg_count= 0\\r\\n  for num in list: \\r\\n    if num <= 0: \\r\\n      neg_count += 1\\r\\n  return neg_count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the numbers in a matrix.\\n The',\n",
              "    'test_cases': ['assert neg_count([-1,-2,3,-4,-5]) == 4',\n",
              "     'assert neg_count([1,2,3]) == 0',\n",
              "     'assert neg_count([1,2,-3,-10,20]) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.040783088689203,\n",
              "     'tokenization_energy': 0.12278308868408203,\n",
              "     'inference_energy': 23.918000000005122,\n",
              "     'energy_per_token': 1.8492910068222463,\n",
              "     'time': 0.5596349239349365,\n",
              "     'components': {'embeddings': np.float64(0.1253468179702759),\n",
              "      'attention': np.float64(9.355355138050394),\n",
              "      'ffn': np.float64(13.637625521198732),\n",
              "      'layernorm': np.float64(0.1346515130996704),\n",
              "      'output_layer': np.float64(0.2269829571247101)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find all three, four, five characters long words in the given string by using regex.',\n",
              "    'ground_truth_code': 'import re\\r\\ndef find_char(text):\\r\\n  return (re.findall(r\"\\\\b\\\\w{3,5}\\\\b\", text))',\n",
              "    'generated_code': ')\\n\\n the function that compute the the-digit four, five,...\\n strings that a three string. using the. The',\n",
              "    'test_cases': [\"assert find_char('For the four consumer complaints contact manager AKR reddy') == ['For', 'the', 'four', 'AKR', 'reddy']\",\n",
              "     \"assert find_char('Certain service are subject to change MSR') == ['are', 'MSR']\",\n",
              "     \"assert find_char('Third party legal desclaimers') == ['Third', 'party', 'legal']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.076937245358362,\n",
              "     'tokenization_energy': 0.1289372453689575,\n",
              "     'inference_energy': 23.947999999989406,\n",
              "     'energy_per_token': 1.0468233584938418,\n",
              "     'time': 0.5650720596313477,\n",
              "     'components': {'embeddings': np.float64(0.12785343885421754),\n",
              "      'attention': np.float64(14.120929057600327),\n",
              "      'ffn': np.float64(9.138081436154664),\n",
              "      'layernorm': np.float64(0.13529078102111816),\n",
              "      'output_layer': np.float64(0.313805606842041)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a python function to count unset bits of a given number.',\n",
              "    'ground_truth_code': 'def count_unset_bits(n): \\r\\n    count = 0\\r\\n    x = 1\\r\\n    while(x < n + 1): \\r\\n        if ((x & n) == 0): \\r\\n            count += 1\\r\\n        x = x << 1\\r\\n    return count  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the bits in a number integer n The',\n",
              "    'test_cases': ['assert count_unset_bits(2) == 1',\n",
              "     'assert count_unset_bits(4) == 2',\n",
              "     'assert count_unset_bits(6) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.181550378803863,\n",
              "     'tokenization_energy': 0.3205503787994385,\n",
              "     'inference_energy': 28.861000000004424,\n",
              "     'energy_per_token': 2.0843964556288475,\n",
              "     'time': 0.5669267177581787,\n",
              "     'components': {'embeddings': np.float64(0.12872570991516114),\n",
              "      'attention': np.float64(9.413808288808678),\n",
              "      'ffn': np.float64(13.927192921402748),\n",
              "      'layernorm': np.float64(0.1263219413757324),\n",
              "      'output_layer': np.float64(0.21422696566581725)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to count character frequency of a given string.',\n",
              "    'ground_truth_code': 'def char_frequency(str1):\\r\\n    dict = {}\\r\\n    for n in str1:\\r\\n        keys = dict.keys()\\r\\n        if n in keys:\\r\\n            dict[n] += 1\\r\\n        else:\\r\\n            dict[n] = 1\\r\\n    return dict',\n",
              "    'generated_code': ')\\n\\n the function that compute the frequencies in a string string, Return',\n",
              "    'test_cases': [\"assert char_frequency('python')=={'p': 1, 'y': 1, 't': 1, 'h': 1, 'o': 1, 'n': 1}\",\n",
              "     \"assert char_frequency('program')=={'p': 1, 'r': 2, 'o': 1, 'g': 1, 'a': 1, 'm': 1}\",\n",
              "     \"assert char_frequency('language')=={'l': 1, 'a': 2, 'n': 1, 'g': 2, 'u': 1, 'e': 1}\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.24333020878525,\n",
              "     'tokenization_energy': 0.12033020877838134,\n",
              "     'inference_energy': 24.12300000000687,\n",
              "     'energy_per_token': 1.8648715545219423,\n",
              "     'time': 0.56719970703125,\n",
              "     'components': {'embeddings': np.float64(0.12236874938011169),\n",
              "      'attention': np.float64(13.990407731528977),\n",
              "      'ffn': np.float64(13.880224605328287),\n",
              "      'layernorm': np.float64(0.13075635051727294),\n",
              "      'output_layer': np.float64(0.21941974353790283)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to sort a list according to the second element in sublist.',\n",
              "    'ground_truth_code': 'def Sort(sub_li): \\r\\n    sub_li.sort(key = lambda x: x[1]) \\r\\n    return sub_li ',\n",
              "    'generated_code': ')\\n\\n the function function that compute a matrix of to the number highest of each in So',\n",
              "    'test_cases': [\"assert Sort([['a', 10], ['b', 5], ['c', 20], ['d', 15]]) == [['b', 5], ['a', 10], ['d', 15], ['c', 20]]\",\n",
              "     \"assert Sort([['452', 10], ['256', 5], ['100', 20], ['135', 15]]) == [['256', 5], ['452', 10], ['135', 15], ['100', 20]]\",\n",
              "     \"assert Sort([['rishi', 10], ['akhil', 5], ['ramya', 20], ['gaur', 15]]) == [['akhil', 5], ['rishi', 10], ['gaur', 15], ['ramya', 20]]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.130808756829122,\n",
              "     'tokenization_energy': 0.1268087568283081,\n",
              "     'inference_energy': 24.004000000000815,\n",
              "     'energy_per_token': 1.4194593386370071,\n",
              "     'time': 0.5650718212127686,\n",
              "     'components': {'embeddings': np.float64(0.12739121174812318),\n",
              "      'attention': np.float64(14.086504772673475),\n",
              "      'ffn': np.float64(13.945900004376425),\n",
              "      'layernorm': np.float64(0.1349548530578613),\n",
              "      'output_layer': np.float64(0.3121668462753296)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to check whether the triangle is valid or not if sides are given.',\n",
              "    'ground_truth_code': 'def check_Validity(a,b,c):  \\r\\n    if (a + b <= c) or (a + c <= b) or (b + c <= a) : \\r\\n        return False\\r\\n    else: \\r\\n        return True        ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given is a, not. the are given as The',\n",
              "    'test_cases': ['assert check_Validity(1,2,3) == False',\n",
              "     'assert check_Validity(2,3,5) == False',\n",
              "     'assert check_Validity(7,10,5) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.915200129263336,\n",
              "     'tokenization_energy': 0.12920012927055358,\n",
              "     'inference_energy': 28.785999999992782,\n",
              "     'energy_per_token': 1.5218526383822808,\n",
              "     'time': 0.602677583694458,\n",
              "     'components': {'embeddings': np.float64(0.13311238431930542),\n",
              "      'attention': np.float64(6.229644347190857),\n",
              "      'ffn': np.float64(18.22119449878042),\n",
              "      'layernorm': np.float64(0.14471270799636843),\n",
              "      'output_layer': np.float64(0.2515313494205475)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the sum of arithmetic progression.',\n",
              "    'ground_truth_code': 'def ap_sum(a,n,d):\\r\\n  total = (n * (2 * a + (n - 1) * d)) / 2\\r\\n  return total',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of all sequence.\\n The',\n",
              "    'test_cases': ['assert ap_sum(1,5,2)==25',\n",
              "     'assert ap_sum(2,6,4)==72',\n",
              "     'assert ap_sum(1,4,5)==34'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.94736310004664,\n",
              "     'tokenization_energy': 0.1873631000518799,\n",
              "     'inference_energy': 28.75999999999476,\n",
              "     'energy_per_token': 2.41228025833722,\n",
              "     'time': 0.5921082496643066,\n",
              "     'components': {'embeddings': np.float64(0.13473044514656068),\n",
              "      'attention': np.float64(10.475783282763672),\n",
              "      'ffn': np.float64(18.404121972325722),\n",
              "      'layernorm': np.float64(0.14143046593666075),\n",
              "      'output_layer': np.float64(0.22452711057662963)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to check whether the given month name contains 28 days or not.',\n",
              "    'ground_truth_code': 'def check_monthnum(monthname1):\\r\\n  if monthname1 == \"February\":\\r\\n    return True\\r\\n  else:\\r\\n    return False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given\\n and is a12 days, more. The',\n",
              "    'test_cases': ['assert check_monthnum(\"February\")==True',\n",
              "     'assert check_monthnum(\"January\")==False',\n",
              "     'assert check_monthnum(\"March\")==False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.684639156830613,\n",
              "     'tokenization_energy': 0.12463915681838988,\n",
              "     'inference_energy': 28.560000000012224,\n",
              "     'energy_per_token': 1.509717850359506,\n",
              "     'time': 0.6070003509521484,\n",
              "     'components': {'embeddings': np.float64(0.13041443753242493),\n",
              "      'attention': np.float64(5.12807771730423),\n",
              "      'ffn': np.float64(31.850152540457554),\n",
              "      'layernorm': np.float64(0.13679669404029846),\n",
              "      'output_layer': np.float64(0.2352998080253601)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function that matches a word at the end of a string, with optional punctuation.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef text_match_word(text):\\r\\n        patterns = '\\\\w+\\\\S*$'\\r\\n        if re.search(patterns,  text):\\r\\n                return 'Found a match!'\\r\\n        else:\\r\\n                return 'Not matched!'\",\n",
              "    'generated_code': ')\\n\\n the function that, the given by the same of each sentence, but the...\\n, The',\n",
              "    'test_cases': ['assert text_match_word(\"python.\")==(\\'Found a match!\\')',\n",
              "     'assert text_match_word(\"python.\")==(\\'Found a match!\\')',\n",
              "     'assert text_match_word(\"  lang  .\")==(\\'Not matched!\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.809121574640972,\n",
              "     'tokenization_energy': 0.12712157464027404,\n",
              "     'inference_energy': 28.6820000000007,\n",
              "     'energy_per_token': 1.5162695565600512,\n",
              "     'time': 0.6127862930297852,\n",
              "     'components': {'embeddings': np.float64(0.14021011233329772),\n",
              "      'attention': np.float64(32.686002317429285),\n",
              "      'ffn': np.float64(4.198652794122696),\n",
              "      'layernorm': np.float64(0.13323623657226563),\n",
              "      'output_layer': np.float64(0.23504376411437988)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to count the number of substrings with same first and last characters.',\n",
              "    'ground_truth_code': 'def check_Equality(s): \\r\\n    return (ord(s[0]) == ord(s[len(s) - 1])); \\r\\ndef count_Substring_With_Equal_Ends(s): \\r\\n    result = 0; \\r\\n    n = len(s); \\r\\n    for i in range(n):\\r\\n        for j in range(1,n-i+1): \\r\\n            if (check_Equality(s[i:i+j])): \\r\\n                result+=1; \\r\\n    return result; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of integersings of exactly number and last character in So',\n",
              "    'test_cases': [\"assert count_Substring_With_Equal_Ends('aba') == 4\",\n",
              "     \"assert count_Substring_With_Equal_Ends('abcab') == 7\",\n",
              "     \"assert count_Substring_With_Equal_Ends('abc') == 3\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.81836093020451,\n",
              "     'tokenization_energy': 0.12136093020439148,\n",
              "     'inference_energy': 28.697000000000116,\n",
              "     'energy_per_token': 1.5167558384318163,\n",
              "     'time': 0.6114275455474854,\n",
              "     'components': {'embeddings': np.float64(0.1727942669391632),\n",
              "      'attention': np.float64(16.662929568298278),\n",
              "      'ffn': np.float64(4.255588170051574),\n",
              "      'layernorm': np.float64(0.13449550366401675),\n",
              "      'output_layer': np.float64(0.23553924322128297)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to find the maximum occuring divisor in an interval.',\n",
              "    'ground_truth_code': 'def find_Divisor(x,y):  \\r\\n    if (x==y): \\r\\n        return y \\r\\n    return 2',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number numberuring number of a array [ So',\n",
              "    'test_cases': ['assert find_Divisor(2,2) == 2',\n",
              "     'assert find_Divisor(2,5) == 2',\n",
              "     'assert find_Divisor(5,10) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.883950019840267,\n",
              "     'tokenization_energy': 0.1329500198364258,\n",
              "     'inference_energy': 23.75100000000384,\n",
              "     'energy_per_token': 1.4927468762400167,\n",
              "     'time': 0.6022179126739502,\n",
              "     'components': {'embeddings': np.float64(0.1941112518310547),\n",
              "      'attention': np.float64(9.765213286637795),\n",
              "      'ffn': np.float64(6.168173876762388),\n",
              "      'layernorm': np.float64(0.13340444111824037),\n",
              "      'output_layer': np.float64(0.21581670928001404)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find the sum of the three lowest positive numbers from a given list of numbers.',\n",
              "    'ground_truth_code': 'def sum_three_smallest_nums(lst):\\r\\n\\treturn sum(sorted([x for x in lst if x > 0])[:3])',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all digits digits numbers integers in a given array of numbers.\\n If',\n",
              "    'test_cases': ['assert sum_three_smallest_nums([10,20,30,40,50,60,7]) == 37',\n",
              "     'assert sum_three_smallest_nums([1,2,3,4,5]) == 6',\n",
              "     'assert sum_three_smallest_nums([0,1,2,3,4,5]) == 6'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.426615230562398,\n",
              "     'tokenization_energy': 0.13061523056030275,\n",
              "     'inference_energy': 28.296000000002095,\n",
              "     'energy_per_token': 1.2921188741164726,\n",
              "     'time': 0.6293973922729492,\n",
              "     'components': {'embeddings': np.float64(0.13460705065727235),\n",
              "      'attention': np.float64(9.773404002675436),\n",
              "      'ffn': np.float64(27.1857617838314),\n",
              "      'layernorm': np.float64(0.14339711380004883),\n",
              "      'output_layer': np.float64(0.24580002307891846)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to convert the given set into ordered tuples.',\n",
              "    'ground_truth_code': 'def set_to_tuple(s):\\r\\n  t = tuple(sorted(s))\\r\\n  return (t)',\n",
              "    'generated_code': ')\\n\\n the function that compute a digits matrix of a pairs.\\n The',\n",
              "    'test_cases': ['assert set_to_tuple({1, 2, 3, 4, 5}) == (1, 2, 3, 4, 5)',\n",
              "     'assert set_to_tuple({6, 7, 8, 9, 10, 11}) == (6, 7, 8, 9, 10, 11)',\n",
              "     'assert set_to_tuple({12, 13, 14, 15, 16}) == (12, 13, 14, 15, 16)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.68152602291398,\n",
              "     'tokenization_energy': 0.13152602291107177,\n",
              "     'inference_energy': 28.55000000000291,\n",
              "     'energy_per_token': 2.2062712325318445,\n",
              "     'time': 0.5905067920684814,\n",
              "     'components': {'embeddings': np.float64(0.1476688184738159),\n",
              "      'attention': np.float64(23.348257529979225),\n",
              "      'ffn': np.float64(8.9467930810384),\n",
              "      'layernorm': np.float64(4.736000000004424),\n",
              "      'output_layer': np.float64(0.21710696363449097)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the smallest range that includes at-least one element from each of the given arrays.',\n",
              "    'ground_truth_code': \"from heapq import heappop, heappush\\r\\nclass Node:\\r\\n    def __init__(self, value, list_num, index):\\r\\n        self.value = value\\r\\n        self.list_num = list_num\\r\\n        self.index = index\\r\\n    def __lt__(self, other):\\r\\n        return self.value < other.value\\r\\ndef find_minimum_range(list):\\r\\n    high = float('-inf')\\r\\n    p = (0, float('inf'))\\r\\n    pq = []\\r\\n    for i in range(len(list)):\\r\\n        heappush(pq, Node(list[i][0], i, 0))\\r\\n        high = max(high, list[i][0])\\r\\n    while True:\\r\\n        top = heappop(pq)\\r\\n        low = top.value\\r\\n        i = top.list_num\\r\\n        j = top.index\\r\\n        if high - low < p[1] - p[0]:\\r\\n            p = (low, high)\\r\\n        if j == len(list[i]) - 1:\\r\\n            return p\\r\\n        heappush(pq, Node(list[i][j + 1], i, j + 1))\\r\\n        high = max(high, list[i][j + 1])\",\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number in contains at leastast one...\\n from each of the three arrays.\\n You',\n",
              "    'test_cases': ['assert find_minimum_range([[3, 6, 8, 10, 15], [1, 5, 12], [4, 8, 15, 16], [2, 6]]) == (4, 6)',\n",
              "     'assert find_minimum_range([[ 2, 3, 4, 8, 10, 15 ], [1, 5, 12], [7, 8, 15, 16], [3, 6]]) == (4, 7)',\n",
              "     'assert find_minimum_range([[4, 7, 9, 11, 16], [2, 6, 13], [5, 9, 16, 17], [3, 7]]) == (5, 7)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.19340551184851,\n",
              "     'tokenization_energy': 0.1234055118560791,\n",
              "     'inference_energy': 24.069999999992433,\n",
              "     'energy_per_token': 1.0518871961673266,\n",
              "     'time': 0.5641934871673584,\n",
              "     'components': {'embeddings': np.float64(0.12442662477493287),\n",
              "      'attention': np.float64(13.81272922135168),\n",
              "      'ffn': np.float64(18.873719292625434),\n",
              "      'layernorm': np.float64(0.13498419165611267),\n",
              "      'output_layer': np.float64(0.2469143614768982)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a function to calculate the number of digits and letters in a string.',\n",
              "    'ground_truth_code': 'def dig_let(s):\\r\\n d=l=0\\r\\n for c in s:\\r\\n    if c.isdigit():\\r\\n        d=d+1\\r\\n    elif c.isalpha():\\r\\n        l=l+1\\r\\n    else:\\r\\n        pass\\r\\n return (l,d)',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability of possible in the in a string.\\n The',\n",
              "    'test_cases': ['assert dig_let(\"python\")==(6,0)',\n",
              "     'assert dig_let(\"program\")==(7,0)',\n",
              "     'assert dig_let(\"python3.0\")==(6,2)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.91251161933213,\n",
              "     'tokenization_energy': 0.13151161932945252,\n",
              "     'inference_energy': 28.781000000002678,\n",
              "     'energy_per_token': 1.807031976208258,\n",
              "     'time': 0.5615041255950928,\n",
              "     'components': {'embeddings': np.float64(0.1503459529876709),\n",
              "      'attention': np.float64(14.004824571132895),\n",
              "      'ffn': np.float64(18.165947128056082),\n",
              "      'layernorm': np.float64(0.13307774090766905),\n",
              "      'output_layer': np.float64(0.28762834882736205)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find number of elements with odd factors in a given range.',\n",
              "    'ground_truth_code': 'def count_Odd_Squares(n,m): \\r\\n    return int(m**0.5) - int((n-1)**0.5) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the of unique in the parity in a given range.\\n The',\n",
              "    'test_cases': ['assert count_Odd_Squares(5,100) == 8',\n",
              "     'assert count_Odd_Squares(8,65) == 6',\n",
              "     'assert count_Odd_Squares(2,5) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.937924757960836,\n",
              "     'tokenization_energy': 0.22492475795745848,\n",
              "     'inference_energy': 28.713000000003376,\n",
              "     'energy_per_token': 1.6076624865533797,\n",
              "     'time': 0.5693912506103516,\n",
              "     'components': {'embeddings': np.float64(0.1257243411540985),\n",
              "      'attention': np.float64(9.698173268546237),\n",
              "      'ffn': np.float64(13.42686665321479),\n",
              "      'layernorm': np.float64(0.2012861747741699),\n",
              "      'output_layer': np.float64(0.26057234144210817)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the difference between two consecutive numbers in a given list.',\n",
              "    'ground_truth_code': 'def diff_consecutivenums(nums):\\r\\n    result = [b-a for a, b in zip(nums[:-1], nums[1:])]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum between the numbers elements in a sequence array of If',\n",
              "    'test_cases': ['assert diff_consecutivenums([1, 1, 3, 4, 4, 5, 6, 7])==[0, 2, 1, 0, 1, 1, 1]',\n",
              "     'assert diff_consecutivenums([4, 5, 8, 9, 6, 10])==[1, 3, 1, -3, 4]',\n",
              "     'assert diff_consecutivenums([0, 1, 2, 3, 4, 4, 4, 4, 5, 7])==[1, 1, 1, 1, 0, 0, 0, 1, 2]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.328923636915047,\n",
              "     'tokenization_energy': 0.12392363691329956,\n",
              "     'inference_energy': 24.205000000001746,\n",
              "     'energy_per_token': 1.4311131551126497,\n",
              "     'time': 0.5616552829742432,\n",
              "     'components': {'embeddings': np.float64(0.12350061130523682),\n",
              "      'attention': np.float64(18.73639108682366),\n",
              "      'ffn': np.float64(13.705083519930486),\n",
              "      'layernorm': np.float64(0.22613577032089233),\n",
              "      'output_layer': np.float64(0.23411609125137328)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find entringer number e(n, k).',\n",
              "    'ground_truth_code': 'def zigzag(n, k): \\r\\n\\tif (n == 0 and k == 0): \\r\\n\\t\\treturn 1\\r\\n\\tif (k == 0): \\r\\n\\t\\treturn 0\\r\\n\\treturn zigzag(n, k - 1) + zigzag(n - 1, n - k)',\n",
              "    'generated_code': \")\\n\\n the function that compute theances's for(n) k) The\",\n",
              "    'test_cases': ['assert zigzag(4, 3) == 5',\n",
              "     'assert zigzag(4, 2) == 4',\n",
              "     'assert zigzag(3, 1) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.81281462383503,\n",
              "     'tokenization_energy': 0.12281462383270264,\n",
              "     'inference_energy': 28.69000000000233,\n",
              "     'energy_per_token': 2.058058187416788,\n",
              "     'time': 0.5678806304931641,\n",
              "     'components': {'embeddings': np.float64(0.18817779684066774),\n",
              "      'attention': np.float64(13.743244059809482),\n",
              "      'ffn': np.float64(18.14052972602809),\n",
              "      'layernorm': np.float64(0.13152347779273987),\n",
              "      'output_layer': np.float64(0.2884395799636841)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to count the number of squares in a rectangle.',\n",
              "    'ground_truth_code': 'def count_Squares(m,n): \\r\\n    if (n < m): \\r\\n        temp = m \\r\\n        m = n \\r\\n        n = temp \\r\\n    return n * (n + 1) * (3 * m - n + 1) // 6',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of integers in a given, The',\n",
              "    'test_cases': ['assert count_Squares(4,3) == 20',\n",
              "     'assert count_Squares(1,2) == 2',\n",
              "     'assert count_Squares(2,2) == 5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.760162417651852,\n",
              "     'tokenization_energy': 0.12716241765022276,\n",
              "     'inference_energy': 28.63300000000163,\n",
              "     'energy_per_token': 1.91734416117679,\n",
              "     'time': 0.5558390617370605,\n",
              "     'components': {'embeddings': np.float64(0.12668176317214966),\n",
              "      'attention': np.float64(14.062480612022686),\n",
              "      'ffn': np.float64(18.450881901519022),\n",
              "      'layernorm': np.float64(0.1333077428340912),\n",
              "      'output_layer': np.float64(0.2225229344367981)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to count sequences of given length having non-negative prefix sums that can be generated by given values.',\n",
              "    'ground_truth_code': 'def bin_coff(n, r): \\r\\n\\tval = 1\\r\\n\\tif (r > (n - r)): \\r\\n\\t\\tr = (n - r) \\r\\n\\tfor i in range(0, r): \\r\\n\\t\\tval *= (n - i) \\r\\n\\t\\tval //= (i + 1) \\r\\n\\treturn val \\r\\ndef find_ways(M): \\r\\n\\tn = M // 2\\r\\n\\ta = bin_coff(2 * n, n) \\r\\n\\tb = a // (n + 1) \\r\\n\\treturn (b) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the of length length with all-negative integers sums.\\n are be split by a pattern of So',\n",
              "    'test_cases': ['assert find_ways(4) == 2',\n",
              "     'assert find_ways(6) == 5',\n",
              "     'assert find_ways(8) == 14'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.852322229383514,\n",
              "     'tokenization_energy': 0.129322229385376,\n",
              "     'inference_energy': 23.722999999998137,\n",
              "     'energy_per_token': 1.0370574882340657,\n",
              "     'time': 0.5766260623931885,\n",
              "     'components': {'embeddings': np.float64(0.12834616708755495),\n",
              "      'attention': np.float64(9.670468152769027),\n",
              "      'ffn': np.float64(13.761660079701105),\n",
              "      'layernorm': np.float64(0.20980269336700438),\n",
              "      'output_layer': np.float64(0.23417064666748047)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a python function to check whether the given string is a binary string or not.',\n",
              "    'ground_truth_code': 'def check(string) :\\r\\n    p = set(string) \\r\\n    s = {\\'0\\', \\'1\\'} \\r\\n    if s == p or p == {\\'0\\'} or p == {\\'1\\'}: \\r\\n        return (\"Yes\") \\r\\n    else : \\r\\n        return (\"No\") ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n is a palindrome\\n. not.\\n A',\n",
              "    'test_cases': ['assert check(\"01010101010\") == \"Yes\"',\n",
              "     'assert check(\"name0\") == \"No\"',\n",
              "     'assert check(\"101\") == \"Yes\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.90580211162148,\n",
              "     'tokenization_energy': 0.12280211162567138,\n",
              "     'inference_energy': 28.78299999999581,\n",
              "     'energy_per_token': 1.6058778950900823,\n",
              "     'time': 0.5698966979980469,\n",
              "     'components': {'embeddings': np.float64(4.902000000001863),\n",
              "      'attention': np.float64(13.978398819907333),\n",
              "      'ffn': np.float64(9.263423906810234),\n",
              "      'layernorm': np.float64(0.12709200382232666),\n",
              "      'output_layer': np.float64(0.22866949439048767)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to minimize the length of the string by removing occurrence of only one character.',\n",
              "    'ground_truth_code': \"def minimum_Length(s) : \\r\\n    maxOcc = 0\\r\\n    n = len(s) \\r\\n    arr = [0]*26\\r\\n    for i in range(n) : \\r\\n        arr[ord(s[i]) -ord('a')] += 1\\r\\n    for i in range(26) : \\r\\n        if arr[i] > maxOcc : \\r\\n            maxOcc = arr[i] \\r\\n    return n - maxOcc \",\n",
              "    'generated_code': ')\\n\\n the function function that compute the sum of the length s removing the of a the character in The',\n",
              "    'test_cases': ['assert minimum_Length(\"mnm\") == 1',\n",
              "     'assert minimum_Length(\"abcda\") == 3',\n",
              "     'assert minimum_Length(\"abcb\") == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.96134808707575,\n",
              "     'tokenization_energy': 0.12334808707237244,\n",
              "     'inference_energy': 28.838000000003376,\n",
              "     'energy_per_token': 1.4480674043537873,\n",
              "     'time': 0.5738191604614258,\n",
              "     'components': {'embeddings': np.float64(0.13588741421699524),\n",
              "      'attention': np.float64(14.239734732157782),\n",
              "      'ffn': np.float64(13.906498130563065),\n",
              "      'layernorm': np.float64(0.13072615337371826),\n",
              "      'output_layer': np.float64(0.23696573209762575)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to find the first element occurring k times in a given array.',\n",
              "    'ground_truth_code': 'def first_Element(arr,n,k): \\r\\n    count_map = {}; \\r\\n    for i in range(0, n): \\r\\n        if(arr[i] in count_map.keys()): \\r\\n            count_map[arr[i]] += 1\\r\\n        else: \\r\\n            count_map[arr[i]] = 1\\r\\n        i += 1\\r\\n    for i in range(0, n):  \\r\\n        if (count_map[arr[i]] == k): \\r\\n            return arr[i] \\r\\n        i += 1 \\r\\n    return -1',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence of in times in a row matrix, The',\n",
              "    'test_cases': ['assert first_Element([0,1,2,3,4,5],6,1) == 0',\n",
              "     'assert first_Element([1,2,1,3,4],5,2) == 1',\n",
              "     'assert first_Element([2,3,4,3,5,7,1,2,3,5],10,2) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.027642101278992,\n",
              "     'tokenization_energy': 0.12464210128784181,\n",
              "     'inference_energy': 23.902999999991152,\n",
              "     'energy_per_token': 1.3348690056266106,\n",
              "     'time': 0.5736401081085205,\n",
              "     'components': {'embeddings': np.float64(0.12522043323516846),\n",
              "      'attention': np.float64(9.51591875528102),\n",
              "      'ffn': np.float64(13.910935487517854),\n",
              "      'layernorm': np.float64(0.30064658260345456),\n",
              "      'output_layer': np.float64(0.23528261947631834)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to check whether all the characters in a given string are unique.',\n",
              "    'ground_truth_code': 'def unique_Characters(str):\\r\\n    for i in range(len(str)):\\r\\n        for j in range(i + 1,len(str)): \\r\\n            if (str[i] == str[j]):\\r\\n                return False;\\r\\n    return True;',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a the elements in a given string are unique, Return',\n",
              "    'test_cases': [\"assert unique_Characters('aba') == False\",\n",
              "     \"assert unique_Characters('abc') == True\",\n",
              "     \"assert unique_Characters('abab') == False\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.90608606672776,\n",
              "     'tokenization_energy': 0.13208606672286988,\n",
              "     'inference_energy': 23.77400000000489,\n",
              "     'energy_per_token': 1.3281158925959866,\n",
              "     'time': 0.5610842704772949,\n",
              "     'components': {'embeddings': np.float64(0.24021278715133665),\n",
              "      'attention': np.float64(13.745115504749585),\n",
              "      'ffn': np.float64(9.018691968191646),\n",
              "      'layernorm': np.float64(0.129758752822876),\n",
              "      'output_layer': np.float64(0.23300814437866213)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to remove a specified column from a given nested list.',\n",
              "    'ground_truth_code': 'def remove_column(list1, n):\\r\\n   for i in list1: \\r\\n    del i[n] \\r\\n   return list1',\n",
              "    'generated_code': ')\\n\\n the function that compute the substring\\n from a matrix matrix array in The',\n",
              "    'test_cases': ['assert remove_column([[1, 2, 3], [2, 4, 5], [1, 1, 1]],0)==[[2, 3], [4, 5], [1, 1]]',\n",
              "     'assert remove_column([[1, 2, 3], [-2, 4, -5], [1, -1, 1]],2)==[[1, 2], [-2, 4], [1, -1]]',\n",
              "     'assert remove_column([[1, 3], [5, 7], [1, 3], [13, 15, 17], [5, 7], [9, 11]],0)==[[3], [7], [3], [15, 17], [7], [11]]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.88183432482765,\n",
              "     'tokenization_energy': 0.12283432483673096,\n",
              "     'inference_energy': 28.75899999999092,\n",
              "     'energy_per_token': 1.9254556216551768,\n",
              "     'time': 0.5642614364624023,\n",
              "     'components': {'embeddings': np.float64(0.20404209661483766),\n",
              "      'attention': np.float64(14.086299467801815),\n",
              "      'ffn': np.float64(18.293929988860384),\n",
              "      'layernorm': np.float64(0.128434059381485),\n",
              "      'output_layer': np.float64(0.21490294432640075)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find t-nth term of arithemetic progression.',\n",
              "    'ground_truth_code': 'def tn_ap(a,n,d):\\r\\n  tn = a + (n - 1) * d\\r\\n  return tn',\n",
              "    'generated_code': ')\\n\\n the function that compute the suchorm term of anithmettic sequence.\\n The',\n",
              "    'test_cases': ['assert tn_ap(1,5,2)==9',\n",
              "     'assert tn_ap(2,6,4)==22',\n",
              "     'assert tn_ap(1,4,5)==16'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.091838398696158,\n",
              "     'tokenization_energy': 0.12183839869499206,\n",
              "     'inference_energy': 23.970000000001164,\n",
              "     'energy_per_token': 1.4171669646291858,\n",
              "     'time': 0.5651686191558838,\n",
              "     'components': {'embeddings': np.float64(0.1251248962879181),\n",
              "      'attention': np.float64(14.1089797449084),\n",
              "      'ffn': np.float64(9.069325407277095),\n",
              "      'layernorm': np.float64(0.13912611651420592),\n",
              "      'output_layer': np.float64(0.3268169515132904)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to count the number of rectangles in a circle of radius r.',\n",
              "    'ground_truth_code': 'def count_Rectangles(radius):  \\r\\n    rectangles = 0 \\r\\n    diameter = 2 * radius \\r\\n    diameterSquare = diameter * diameter \\r\\n    for a in range(1, 2 * radius):  \\r\\n        for b in range(1, 2 * radius): \\r\\n            diagnalLengthSquare = (a * a +  b * b)  \\r\\n            if (diagnalLengthSquare <= diameterSquare) : \\r\\n                rectangles += 1\\r\\n    return rectangles ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of integers in a given that radius R, The',\n",
              "    'test_cases': ['assert count_Rectangles(2) == 8',\n",
              "     'assert count_Rectangles(1) == 1',\n",
              "     'assert count_Rectangles(0) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.6820000000007,\n",
              "     'tokenization_energy': 4.788000000000466,\n",
              "     'inference_energy': 23.894000000000233,\n",
              "     'energy_per_token': 1.5934444444444833,\n",
              "     'time': 0.5658845901489258,\n",
              "     'components': {'embeddings': np.float64(0.12615719318389892),\n",
              "      'attention': np.float64(14.174893367300392),\n",
              "      'ffn': np.float64(13.607529025067693),\n",
              "      'layernorm': np.float64(0.1284174358844757),\n",
              "      'output_layer': np.float64(0.23316555261611938)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the third angle of a triangle using two angles.',\n",
              "    'ground_truth_code': 'def find_angle(a,b):\\r\\n c = 180 - (a + b)\\r\\n return c\\r\\n',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-order of a triangle given the angles. The',\n",
              "    'test_cases': ['assert find_angle(47,89)==44',\n",
              "     'assert find_angle(45,95)==40',\n",
              "     'assert find_angle(50,40)==90'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.91170493674709,\n",
              "     'tokenization_energy': 0.12270493674278259,\n",
              "     'inference_energy': 28.789000000004307,\n",
              "     'energy_per_token': 1.806981558546693,\n",
              "     'time': 0.5544135570526123,\n",
              "     'components': {'embeddings': np.float64(0.12177181935310363),\n",
              "      'attention': np.float64(18.65683793379087),\n",
              "      'ffn': np.float64(13.450998401633232),\n",
              "      'layernorm': np.float64(0.12527465295791626),\n",
              "      'output_layer': np.float64(4.754000000000815)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find the maximum element of all the given tuple records.',\n",
              "    'ground_truth_code': 'def find_max(test_list):\\r\\n  res = max(int(j) for i in test_list for j in i)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number in a possible elements vectors elements in Each',\n",
              "    'test_cases': ['assert find_max([(2, 4), (6, 7), (5, 1), (6, 10), (8, 7)]) == 10',\n",
              "     'assert find_max([(3, 5), (7, 8), (6, 2), (7, 11), (9, 8)]) == 11',\n",
              "     'assert find_max([(4, 6), (8, 9), (7, 3), (8, 12), (10, 9)]) == 12'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.0326555430867,\n",
              "     'tokenization_energy': 0.15065554308891296,\n",
              "     'inference_energy': 23.881999999997788,\n",
              "     'energy_per_token': 1.5020409714429188,\n",
              "     'time': 0.5554158687591553,\n",
              "     'components': {'embeddings': np.float64(0.1229513909816742),\n",
              "      'attention': np.float64(4.758135298490524),\n",
              "      'ffn': np.float64(4.5606240234375),\n",
              "      'layernorm': np.float64(0.1256981225013733),\n",
              "      'output_layer': np.float64(0.22266907501220704)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find modulo division of two lists using map and lambda function.',\n",
              "    'ground_truth_code': 'def moddiv_list(nums1,nums2):\\r\\n  result = map(lambda x, y: x % y, nums1, nums2)\\r\\n  return list(result)',\n",
              "    'generated_code': ')\\n\\n the function that compute the of with two integers in the function filter functions.\\n\\n The',\n",
              "    'test_cases': ['assert moddiv_list([4,5,6],[1, 2, 3])==[0, 1, 0]',\n",
              "     'assert moddiv_list([3,2],[1,4])==[0, 2]',\n",
              "     'assert moddiv_list([90,120],[50,70])==[40, 50]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.825715947398216,\n",
              "     'tokenization_energy': 0.12271594738960266,\n",
              "     'inference_energy': 28.703000000008615,\n",
              "     'energy_per_token': 1.6956303498469538,\n",
              "     'time': 0.5590677261352539,\n",
              "     'components': {'embeddings': np.float64(0.12258191704750061),\n",
              "      'attention': np.float64(9.440254320377601),\n",
              "      'ffn': np.float64(9.189608143581077),\n",
              "      'layernorm': np.float64(0.13212788200378417),\n",
              "      'output_layer': np.float64(0.23662079501152036)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to check whether one root of the quadratic equation is twice of the other or not.',\n",
              "    'ground_truth_code': 'def Check_Solution(a,b,c): \\r\\n    if (2*b*b == 9*a*c): \\r\\n        return (\"Yes\"); \\r\\n    else: \\r\\n        return (\"No\"); ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a of of a root equation\\n greater another another other root not.\\n The',\n",
              "    'test_cases': ['assert Check_Solution(1,3,2) == \"Yes\"',\n",
              "     'assert Check_Solution(1,2,3) == \"No\"',\n",
              "     'assert Check_Solution(1,-5,6) == \"No\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.060897060619666,\n",
              "     'tokenization_energy': 0.12489706063270568,\n",
              "     'inference_energy': 23.93599999998696,\n",
              "     'energy_per_token': 1.0936771391190758,\n",
              "     'time': 0.5589561462402344,\n",
              "     'components': {'embeddings': np.float64(0.12534971237182616),\n",
              "      'attention': np.float64(9.4027501811852),\n",
              "      'ffn': np.float64(4.358508063554764),\n",
              "      'layernorm': np.float64(0.1266502275466919),\n",
              "      'output_layer': np.float64(0.24048065257072448)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to find the n’th carol number.',\n",
              "    'ground_truth_code': 'def get_carol(n): \\r\\n\\tresult = (2**n) - 1\\r\\n\\treturn result * result - 2',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-thth smallest...\\n number.\\n The',\n",
              "    'test_cases': ['assert get_carol(2) == 7',\n",
              "     'assert get_carol(4) == 223',\n",
              "     'assert get_carol(5) == 959'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.21894132160954,\n",
              "     'tokenization_energy': 0.12094132161140442,\n",
              "     'inference_energy': 24.097999999998137,\n",
              "     'energy_per_token': 1.7299243801149673,\n",
              "     'time': 0.5581414699554443,\n",
              "     'components': {'embeddings': np.float64(0.12425373744964599),\n",
              "      'attention': np.float64(9.41163035201782),\n",
              "      'ffn': np.float64(18.496098005765234),\n",
              "      'layernorm': np.float64(0.13544356083869932),\n",
              "      'output_layer': np.float64(0.22570344591140745)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to remove empty lists from a given list of lists.',\n",
              "    'ground_truth_code': 'def remove_empty(list1):\\r\\n  remove_empty = [x for x in list1 if x]\\r\\n  return remove_empty',\n",
              "    'generated_code': ')\\n\\n the function that compute the strings from a matrix list of lists, The',\n",
              "    'test_cases': [\"assert remove_empty([[], [], [], 'Red', 'Green', [1,2], 'Blue', [], []])==['Red', 'Green', [1, 2], 'Blue']\",\n",
              "     \"assert remove_empty([[], [], [],[],[], 'Green', [1,2], 'Blue', [], []])==[ 'Green', [1, 2], 'Blue']\",\n",
              "     \"assert remove_empty([[], [], [], 'Python',[],[], 'programming', 'language',[],[],[], [], []])==['Python', 'programming', 'language']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.09353592586855,\n",
              "     'tokenization_energy': 0.13053592586517335,\n",
              "     'inference_energy': 28.963000000003376,\n",
              "     'energy_per_token': 1.93956906172457,\n",
              "     'time': 0.5586705207824707,\n",
              "     'components': {'embeddings': np.float64(0.12885228466987608),\n",
              "      'attention': np.float64(9.295084402319512),\n",
              "      'ffn': np.float64(13.746182316546212),\n",
              "      'layernorm': np.float64(0.12814083576202392),\n",
              "      'output_layer': np.float64(0.21793680095672607)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the item with maximum occurrences in a given list.',\n",
              "    'ground_truth_code': 'def max_occurrences(nums):\\r\\n    max_val = 0\\r\\n    result = nums[0] \\r\\n    for i in nums:\\r\\n        occu = nums.count(i)\\r\\n        if occu > max_val:\\r\\n            max_val = occu\\r\\n            result = i \\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number in the frequency in a list array of If',\n",
              "    'test_cases': ['assert max_occurrences([1,2,3,1,2,3,12,4,2]) ==  2',\n",
              "     'assert max_occurrences([1,2,6,7,0,1,0,1,0]) == 1,0',\n",
              "     'assert max_occurrences([1,2,3,1,2,4,1]) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.265512135499623,\n",
              "     'tokenization_energy': 0.13451213550567628,\n",
              "     'inference_energy': 24.130999999993946,\n",
              "     'energy_per_token': 1.4273830667940954,\n",
              "     'time': 0.5575175285339355,\n",
              "     'components': {'embeddings': np.float64(0.13579368209838868),\n",
              "      'attention': np.float64(9.55278773283772),\n",
              "      'ffn': np.float64(13.97194630932121),\n",
              "      'layernorm': np.float64(0.13424217224121093),\n",
              "      'output_layer': np.float64(0.24226665782928467)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to add the k elements to each element in the tuple.',\n",
              "    'ground_truth_code': 'def add_K_element(test_list, K):\\r\\n  res = [tuple(j + K for j in sub ) for sub in test_list]\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute two digits-th from the row of the array.\\n\\n So',\n",
              "    'test_cases': ['assert add_K_element([(1, 3, 4), (2, 4, 6), (3, 8, 1)], 4) == [(5, 7, 8), (6, 8, 10), (7, 12, 5)]',\n",
              "     'assert add_K_element([(1, 2, 3), (4, 5, 6), (7, 8, 9)], 8) == [(9, 10, 11), (12, 13, 14), (15, 16, 17)]',\n",
              "     'assert add_K_element([(11, 12, 13), (14, 15, 16), (17, 18, 19)], 9) == [(20, 21, 22), (23, 24, 25), (26, 27, 28)]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.17351816272945,\n",
              "     'tokenization_energy': 0.12751816272735594,\n",
              "     'inference_energy': 29.046000000002095,\n",
              "     'energy_per_token': 1.8233448851705907,\n",
              "     'time': 0.5607304573059082,\n",
              "     'components': {'embeddings': np.float64(0.19380618572235106),\n",
              "      'attention': np.float64(13.88608592892671),\n",
              "      'ffn': np.float64(14.008831150530956),\n",
              "      'layernorm': np.float64(0.15969543695449828),\n",
              "      'output_layer': np.float64(0.22142049312591552)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find the number of flips required to make the given binary string a sequence of alternate characters.',\n",
              "    'ground_truth_code': \"def make_flip(ch): \\r\\n\\treturn '1' if (ch == '0') else '0'\\r\\ndef get_flip_with_starting_charcter(str, expected): \\r\\n\\tflip_count = 0\\r\\n\\tfor i in range(len( str)): \\r\\n\\t\\tif (str[i] != expected): \\r\\n\\t\\t\\tflip_count += 1\\r\\n\\t\\texpected = make_flip(expected) \\r\\n\\treturn flip_count \\r\\ndef min_flip_to_make_string_alternate(str): \\r\\n\\treturn min(get_flip_with_starting_charcter(str, '0'),get_flip_with_starting_charcter(str, '1')) \",\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of unique in to make the number binary string into palindrome of alternating . You',\n",
              "    'test_cases': ['assert min_flip_to_make_string_alternate(\"0001010111\") == 2',\n",
              "     'assert min_flip_to_make_string_alternate(\"001\") == 1',\n",
              "     'assert min_flip_to_make_string_alternate(\"010111011\") == 2 '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.268598585616566,\n",
              "     'tokenization_energy': 0.12559858560562134,\n",
              "     'inference_energy': 24.143000000010943,\n",
              "     'energy_per_token': 1.0551564602441985,\n",
              "     'time': 0.5667843818664551,\n",
              "     'components': {'embeddings': np.float64(0.12583085298538207),\n",
              "      'attention': np.float64(9.493334920414373),\n",
              "      'ffn': np.float64(9.190435290574563),\n",
              "      'layernorm': np.float64(0.1312659595012665),\n",
              "      'output_layer': np.float64(0.3006313719749451)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a python function to count the number of digits of a given number.',\n",
              "    'ground_truth_code': 'def count_Digit(n):\\r\\n    count = 0\\r\\n    while n != 0:\\r\\n        n //= 10\\r\\n        count += 1\\r\\n    return count',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of integers in a positive integer n The',\n",
              "    'test_cases': ['assert count_Digit(12345) == 5',\n",
              "     'assert count_Digit(11223305) == 8',\n",
              "     'assert count_Digit(4123459) == 7'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.047999999995227,\n",
              "     'tokenization_energy': 4.926999999996042,\n",
              "     'inference_energy': 24.120999999999185,\n",
              "     'energy_per_token': 1.8154999999997017,\n",
              "     'time': 0.5588746070861816,\n",
              "     'components': {'embeddings': np.float64(0.1264518985748291),\n",
              "      'attention': np.float64(4.7053948564529415),\n",
              "      'ffn': np.float64(4.594184255123139),\n",
              "      'layernorm': np.float64(0.1272273066043854),\n",
              "      'output_layer': np.float64(0.2834709713459015)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find the largest product of the pair of adjacent elements from a given list of integers.',\n",
              "    'ground_truth_code': 'def adjacent_num_product(list_nums):\\r\\n    return max(a*b for a, b in zip(list_nums, list_nums[1:]))',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number prime of k two of consecutive numbers in a given array of integers.\\n If',\n",
              "    'test_cases': ['assert adjacent_num_product([1,2,3,4,5,6]) == 30',\n",
              "     'assert adjacent_num_product([1,2,3,4,5]) == 20',\n",
              "     'assert adjacent_num_product([2,3]) == 6'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.049182455535746,\n",
              "     'tokenization_energy': 0.12218245553970337,\n",
              "     'inference_energy': 28.926999999996042,\n",
              "     'energy_per_token': 1.2630079328493802,\n",
              "     'time': 0.5594687461853027,\n",
              "     'components': {'embeddings': np.float64(0.12133600401878358),\n",
              "      'attention': np.float64(18.544435167076998),\n",
              "      'ffn': np.float64(13.71395680928172),\n",
              "      'layernorm': np.float64(0.12939451122283935),\n",
              "      'output_layer': np.float64(4.80899999999383)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a function to check if a binary tree is balanced or not.',\n",
              "    'ground_truth_code': 'class Node: \\r\\n\\tdef __init__(self, data): \\r\\n\\t\\tself.data = data \\r\\n\\t\\tself.left = None\\r\\n\\t\\tself.right = None\\r\\ndef get_height(root): \\r\\n\\tif root is None: \\r\\n\\t\\treturn 0\\r\\n\\treturn max(get_height(root.left), get_height(root.right)) + 1\\r\\ndef is_tree_balanced(root): \\r\\n\\tif root is None: \\r\\n\\t\\treturn True\\r\\n\\tlh = get_height(root.left) \\r\\n\\trh = get_height(root.right) \\r\\n\\tif (abs(lh - rh) <= 1) and is_tree_balanced( \\r\\n\\troot.left) is True and is_tree_balanced( root.right) is True: \\r\\n\\t\\treturn True\\r\\n\\treturn False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number tree is a. not. A',\n",
              "    'test_cases': ['assert is_tree_balanced(root) == False',\n",
              "     'assert is_tree_balanced(root1) == True',\n",
              "     'assert is_tree_balanced(root2) == False '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.247064071664354,\n",
              "     'tokenization_energy': 0.13106407165527342,\n",
              "     'inference_energy': 24.11600000000908,\n",
              "     'energy_per_token': 1.616470938110957,\n",
              "     'time': 0.5553696155548096,\n",
              "     'components': {'embeddings': np.float64(0.13275601196289064),\n",
              "      'attention': np.float64(13.830967882155324),\n",
              "      'ffn': np.float64(13.582788997888798),\n",
              "      'layernorm': np.float64(0.12666155242919921),\n",
              "      'output_layer': np.float64(0.21404627895355224)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to repeat the given tuple n times.',\n",
              "    'ground_truth_code': 'def repeat_tuples(test_tup, N):\\r\\n  res = ((test_tup, ) * N)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits string ( times, The',\n",
              "    'test_cases': ['assert repeat_tuples((1, 3), 4) == ((1, 3), (1, 3), (1, 3), (1, 3))',\n",
              "     'assert repeat_tuples((1, 2), 3) == ((1, 2), (1, 2), (1, 2))',\n",
              "     'assert repeat_tuples((3, 4), 5) == ((3, 4), (3, 4), (3, 4), (3, 4), (3, 4))'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.064251086226665,\n",
              "     'tokenization_energy': 0.12325108623504638,\n",
              "     'inference_energy': 28.940999999991618,\n",
              "     'energy_per_token': 2.422020923852222,\n",
              "     'time': 0.55678391456604,\n",
              "     'components': {'embeddings': np.float64(0.12003259992599487),\n",
              "      'attention': np.float64(4.807044808387756),\n",
              "      'ffn': np.float64(4.532556365728379),\n",
              "      'layernorm': np.float64(0.1548280348777771),\n",
              "      'output_layer': np.float64(0.21291971302032472)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to find the lateral surface area of cuboid',\n",
              "    'ground_truth_code': 'def lateralsurface_cuboid(l,w,h):\\r\\n  LSA = 2*h*(l+w)\\r\\n  return LSA',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum surface area of aoids with',\n",
              "    'test_cases': ['assert lateralsurface_cuboid(8,5,6)==156',\n",
              "     'assert lateralsurface_cuboid(7,9,10)==320',\n",
              "     'assert lateralsurface_cuboid(10,20,30)==1800'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.06448708343436,\n",
              "     'tokenization_energy': 0.1214870834350586,\n",
              "     'inference_energy': 23.9429999999993,\n",
              "     'energy_per_token': 1.8511143910334125,\n",
              "     'time': 0.559394359588623,\n",
              "     'components': {'embeddings': np.float64(0.1848598232269287),\n",
              "      'attention': np.float64(14.105939313418235),\n",
              "      'ffn': np.float64(18.343008394710953),\n",
              "      'layernorm': np.float64(0.13670109987258913),\n",
              "      'output_layer': np.float64(0.22909720945358278)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to sort a tuple by its float element.',\n",
              "    'ground_truth_code': 'def float_sort(price):\\r\\n  float_sort=sorted(price, key=lambda x: float(x[1]), reverse=True)\\r\\n  return float_sort',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix in its elements value in So',\n",
              "    'test_cases': [\"assert float_sort([('item1', '12.20'), ('item2', '15.10'), ('item3', '24.5')])==[('item3', '24.5'), ('item2', '15.10'), ('item1', '12.20')] \",\n",
              "     \"assert float_sort([('item1', '15'), ('item2', '10'), ('item3', '20')])==[('item3', '20'), ('item1', '15'), ('item2', '10')] \",\n",
              "     \"assert float_sort([('item1', '5'), ('item2', '10'), ('item3', '14')])==[('item3', '14'), ('item2', '10'), ('item1', '5')] \"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.967832305430086,\n",
              "     'tokenization_energy': 0.13483230543136598,\n",
              "     'inference_energy': 28.83299999999872,\n",
              "     'energy_per_token': 2.228294792725391,\n",
              "     'time': 0.5547173023223877,\n",
              "     'components': {'embeddings': np.float64(4.918000000005122),\n",
              "      'attention': np.float64(18.41717541955947),\n",
              "      'ffn': np.float64(13.66536038756685),\n",
              "      'layernorm': np.float64(0.12732266330718994),\n",
              "      'output_layer': np.float64(0.21592019891738892)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the smallest missing element in a sorted array.',\n",
              "    'ground_truth_code': 'def smallest_missing(A, left_element, right_element):\\r\\n    if left_element > right_element:\\r\\n        return left_element\\r\\n    mid = left_element + (right_element - left_element) // 2\\r\\n    if A[mid] == mid:\\r\\n        return smallest_missing(A, mid + 1, right_element)\\r\\n    else:\\r\\n        return smallest_missing(A, left_element, mid - 1)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number positive in an binary array. The',\n",
              "    'test_cases': ['assert smallest_missing([0, 1, 2, 3, 4, 5, 6], 0, 6) == 7',\n",
              "     'assert smallest_missing([0, 1, 2, 6, 9, 11, 15], 0, 6) == 3',\n",
              "     'assert smallest_missing([1, 2, 3, 4, 6, 9, 11, 15], 0, 7) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.245872585776496,\n",
              "     'tokenization_energy': 0.12387258577346802,\n",
              "     'inference_energy': 24.122000000003027,\n",
              "     'energy_per_token': 1.616391505718433,\n",
              "     'time': 0.5609893798828125,\n",
              "     'components': {'embeddings': np.float64(0.12348544836044312),\n",
              "      'attention': np.float64(14.158896320818572),\n",
              "      'ffn': np.float64(13.673742313623311),\n",
              "      'layernorm': np.float64(0.2068187236785889),\n",
              "      'output_layer': np.float64(0.21742246818542482)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to sort a given list of elements in ascending order using heap queue algorithm.',\n",
              "    'ground_truth_code': 'import heapq as hq\\r\\ndef heap_assending(nums):\\r\\n  hq.heapify(nums)\\r\\n  s_result = [hq.heappop(nums) for i in range(len(nums))]\\r\\n  return s_result',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix matrix of integers in a order, only sorting.\\n But',\n",
              "    'test_cases': ['assert heap_assending([18, 14, 10, 9, 8, 7, 9, 3, 2, 4, 1])==[1, 2, 3, 4, 7, 8, 9, 9, 10, 14, 18]',\n",
              "     'assert heap_assending([25, 35, 22, 85, 14, 65, 75, 25, 58])==[14, 22, 25, 25, 35, 58, 65, 75, 85]',\n",
              "     'assert heap_assending([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])==[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.082311927785632,\n",
              "     'tokenization_energy': 0.13031192779541015,\n",
              "     'inference_energy': 23.95199999999022,\n",
              "     'energy_per_token': 1.2674901014624016,\n",
              "     'time': 0.5542876720428467,\n",
              "     'components': {'embeddings': np.float64(0.13000166130065918),\n",
              "      'attention': np.float64(18.369027348266215),\n",
              "      'ffn': np.float64(13.465883290771627),\n",
              "      'layernorm': np.float64(0.13099104166030884),\n",
              "      'output_layer': np.float64(0.23715782546997072)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the volume of a cuboid.',\n",
              "    'ground_truth_code': 'def volume_cuboid(l,w,h):\\r\\n  volume=l*w*h\\r\\n  return volume',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a cubeoid with The',\n",
              "    'test_cases': ['assert volume_cuboid(1,2,3)==6',\n",
              "     'assert volume_cuboid(5,7,9)==315',\n",
              "     'assert volume_cuboid(10,15,21)==3150'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.772615737438436,\n",
              "     'tokenization_energy': 0.1286157374382019,\n",
              "     'inference_energy': 28.644000000000233,\n",
              "     'energy_per_token': 2.2132781336491103,\n",
              "     'time': 0.558645486831665,\n",
              "     'components': {'embeddings': np.float64(0.12696233940124513),\n",
              "      'attention': np.float64(9.322821874382676),\n",
              "      'ffn': np.float64(4.458788864135742),\n",
              "      'layernorm': np.float64(0.13085569190979005),\n",
              "      'output_layer': np.float64(0.241430287361145)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to print all permutations of a given string including duplicates.',\n",
              "    'ground_truth_code': \"def permute_string(str):\\r\\n    if len(str) == 0:\\r\\n        return ['']\\r\\n    prev_list = permute_string(str[1:len(str)])\\r\\n    next_list = []\\r\\n    for i in range(0,len(prev_list)):\\r\\n        for j in range(0,len(str)):\\r\\n            new_str = prev_list[i][0:j]+str[0]+prev_list[i][j:len(str)-1]\\r\\n            if new_str not in next_list:\\r\\n                next_list.append(new_str)\\r\\n    return next_list\",\n",
              "    'generated_code': ')\\n\\n the function that compute the the of a given string. duplicates.\\n\\n For',\n",
              "    'test_cases': [\"assert permute_string('ab')==['ab', 'ba']\",\n",
              "     \"assert permute_string('abc')==['abc', 'bac', 'bca', 'acb', 'cab', 'cba']\",\n",
              "     \"assert permute_string('abcd')==['abcd', 'bacd', 'bcad', 'bcda', 'acbd', 'cabd', 'cbad', 'cbda', 'acdb', 'cadb', 'cdab', 'cdba', 'abdc', 'badc', 'bdac', 'bdca', 'adbc', 'dabc', 'dbac', 'dbca', 'adcb', 'dacb', 'dcab', 'dcba']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.18216339588456,\n",
              "     'tokenization_energy': 0.13216339588165282,\n",
              "     'inference_energy': 24.05000000000291,\n",
              "     'energy_per_token': 1.612144226392304,\n",
              "     'time': 0.5584306716918945,\n",
              "     'components': {'embeddings': np.float64(0.12405019283294677),\n",
              "      'attention': np.float64(14.11198109937436),\n",
              "      'ffn': np.float64(9.051883584015071),\n",
              "      'layernorm': np.float64(0.1313949394226074),\n",
              "      'output_layer': np.float64(0.2848969388008118)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to round the given number to the nearest multiple of a specific number.',\n",
              "    'ground_truth_code': 'def round_num(n,m):\\r\\n    a = (n //m) * m\\r\\n    b = a + m\\r\\n    return (b if n - a > b - n else a)',\n",
              "    'generated_code': ')\\n\\n the function that compute a numbers integer to the nearest integer of  given number. For',\n",
              "    'test_cases': ['assert round_num(4722,10)==4720',\n",
              "     'assert round_num(1111,5)==1110',\n",
              "     'assert round_num(219,2)==218'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.066277857545646,\n",
              "     'tokenization_energy': 0.20927785754203795,\n",
              "     'inference_energy': 28.85700000000361,\n",
              "     'energy_per_token': 1.6147932143080914,\n",
              "     'time': 0.561389684677124,\n",
              "     'components': {'embeddings': np.float64(0.12425692319869995),\n",
              "      'attention': np.float64(9.432316907173139),\n",
              "      'ffn': np.float64(4.290814037322998),\n",
              "      'layernorm': np.float64(0.131346483707428),\n",
              "      'output_layer': np.float64(0.23376177048683167)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to remove tuple elements that occur more than once and replace the duplicates with some custom value.',\n",
              "    'ground_truth_code': \"def remove_replica(test_tup):\\r\\n  temp = set()\\r\\n  res = tuple(ele if ele not in temp and not temp.add(ele) \\r\\n\\t\\t\\t\\telse 'MSP' for ele in test_tup)\\r\\n  return (res)\",\n",
              "    'generated_code': ')\\n\\n the function that compute the elements from are in than once in return them elements with the unique\\n.\\n The',\n",
              "    'test_cases': [\"assert remove_replica((1, 1, 4, 4, 4, 5, 5, 6, 7, 7)) == (1, 'MSP', 4, 'MSP', 'MSP', 5, 'MSP', 6, 7, 'MSP')\",\n",
              "     \"assert remove_replica((2, 3, 4, 4, 5, 6, 6, 7, 8, 9, 9)) == (2, 3, 4, 'MSP', 5, 6, 'MSP', 7, 8, 9, 'MSP')\",\n",
              "     \"assert remove_replica((2, 2, 5, 4, 5, 7, 5, 6, 7, 7)) == (2, 'MSP', 5, 4, 'MSP', 7, 'MSP', 6, 'MSP', 'MSP')\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.15632187509723,\n",
              "     'tokenization_energy': 0.12932187509536744,\n",
              "     'inference_energy': 24.027000000001863,\n",
              "     'energy_per_token': 1.0980146306862377,\n",
              "     'time': 0.5616164207458496,\n",
              "     'components': {'embeddings': np.float64(0.12331707000732423),\n",
              "      'attention': np.float64(14.2297713639749),\n",
              "      'ffn': np.float64(13.626271300068707),\n",
              "      'layernorm': np.float64(0.1375748255252838),\n",
              "      'output_layer': np.float64(0.23790595722198485)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a python function to remove all occurrences of a character in a given string.',\n",
              "    'ground_truth_code': \"def remove_Char(s,c) :  \\r\\n    counts = s.count(c) \\r\\n    s = list(s) \\r\\n    while counts :  \\r\\n        s.remove(c) \\r\\n        counts -= 1 \\r\\n    s = '' . join(s)   \\r\\n    return (s) \",\n",
              "    'generated_code': ')\\n\\n the function function that compute all the of a given in a string string, The',\n",
              "    'test_cases': ['assert remove_Char(\"aba\",\\'a\\') == \"b\"',\n",
              "     'assert remove_Char(\"toggle\",\\'g\\') == \"tole\"',\n",
              "     'assert remove_Char(\"aabbc\",\\'b\\') == \"aac\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.162178453441825,\n",
              "     'tokenization_energy': 0.14417845344543456,\n",
              "     'inference_energy': 24.01799999999639,\n",
              "     'energy_per_token': 1.4213046149083426,\n",
              "     'time': 0.5585577487945557,\n",
              "     'components': {'embeddings': np.float64(0.12812812900543213),\n",
              "      'attention': np.float64(13.961565087090246),\n",
              "      'ffn': np.float64(13.827246002428582),\n",
              "      'layernorm': np.float64(0.13414092898368835),\n",
              "      'output_layer': np.float64(0.23006827116012574)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to shift last element to first position in the given list.',\n",
              "    'ground_truth_code': 'def move_first(test_list):\\r\\n  test_list = test_list[-1:] + test_list[:-1]  \\r\\n  return test_list',\n",
              "    'generated_code': ')\\n\\n the function function that compute the k of the position in a matrix matrix.\\n The',\n",
              "    'test_cases': ['assert move_first([1,2,3,4]) == [4,1,2,3]',\n",
              "     'assert move_first([0,1,2,3]) == [3,0,1,2]',\n",
              "     'assert move_first([9,8,7,1]) == [1,9,8,7]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.758632489448296,\n",
              "     'tokenization_energy': 0.12463248944282532,\n",
              "     'inference_energy': 28.63400000000547,\n",
              "     'energy_per_token': 1.691684264085194,\n",
              "     'time': 0.5586972236633301,\n",
              "     'components': {'embeddings': np.float64(0.12325005674362183),\n",
              "      'attention': np.float64(13.89644775487599),\n",
              "      'ffn': np.float64(8.932577817190905),\n",
              "      'layernorm': np.float64(0.12940239930152894),\n",
              "      'output_layer': np.float64(0.2570701062679291)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the surface area of a cuboid.',\n",
              "    'ground_truth_code': 'def surfacearea_cuboid(l,w,h):\\r\\n  SA = 2*(l*w + l * h + w * h)\\r\\n  return SA',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum area of a cubeoid with The',\n",
              "    'test_cases': ['assert surfacearea_cuboid(1,2,3)==22',\n",
              "     'assert surfacearea_cuboid(5,7,9)==286',\n",
              "     'assert surfacearea_cuboid(10,15,21)==1350'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.122720268007253,\n",
              "     'tokenization_energy': 0.12372026801109313,\n",
              "     'inference_energy': 23.99899999999616,\n",
              "     'energy_per_token': 1.7230514477148038,\n",
              "     'time': 0.5525977611541748,\n",
              "     'components': {'embeddings': np.float64(0.12308955931663512),\n",
              "      'attention': np.float64(4.7996442043781276),\n",
              "      'ffn': np.float64(4.342602045536041),\n",
              "      'layernorm': np.float64(0.1251095552444458),\n",
              "      'output_layer': np.float64(0.212039822101593)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to generate a two-dimensional array.',\n",
              "    'ground_truth_code': 'def multi_list(rownum,colnum):\\r\\n  multi_list = [[0 for col in range(colnum)] for row in range(rownum)]\\r\\n  for row in range(rownum):\\r\\n    for col in range(colnum):\\r\\n        multi_list[row][col]= row*col\\r\\n  return multi_list\\r\\n',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix-dimensional array with The',\n",
              "    'test_cases': ['assert multi_list(3,4)==[[0, 0, 0, 0], [0, 1, 2, 3], [0, 2, 4, 6]] ',\n",
              "     'assert multi_list(5,7)==[[0, 0, 0, 0, 0, 0, 0], [0, 1, 2, 3, 4, 5, 6], [0, 2, 4, 6, 8, 10, 12], [0, 3, 6, 9, 12, 15, 18], [0, 4, 8, 12, 16, 20, 24]]',\n",
              "     'assert multi_list(10,15)==[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28], [0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42], [0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56], [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70], [0, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84], [0, 7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91, 98], [0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112], [0, 9, 18, 27, 36, 45, 54, 63, 72, 81, 90, 99, 108, 117, 126]]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.46999045086035,\n",
              "     'tokenization_energy': 0.1779904508590698,\n",
              "     'inference_energy': 28.29200000000128,\n",
              "     'energy_per_token': 2.588180950078214,\n",
              "     'time': 0.559272050857544,\n",
              "     'components': {'embeddings': np.float64(0.12100208330154419),\n",
              "      'attention': np.float64(13.562090985545074),\n",
              "      'ffn': np.float64(13.381817446233123),\n",
              "      'layernorm': np.float64(0.13031571006774903),\n",
              "      'output_layer': np.float64(0.22547924637794498)},\n",
              "     'num_tokens': 11}},\n",
              "   {'prompt': 'Write a function to sort a list of lists by a given index of the inner list.',\n",
              "    'ground_truth_code': 'from operator import itemgetter\\r\\ndef index_on_inner_list(list_data, index_no):\\r\\n    result = sorted(list_data, key=itemgetter(index_no))\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix of integers of the specific\\n in each given lists.\\n So',\n",
              "    'test_cases': [\"assert index_on_inner_list([('Greyson Fulton', 98, 99), ('Brady Kent', 97, 96), ('Wyatt Knott', 91, 94), ('Beau Turnbull', 94, 98)] ,0)==[('Beau Turnbull', 94, 98), ('Brady Kent', 97, 96), ('Greyson Fulton', 98, 99), ('Wyatt Knott', 91, 94)]\",\n",
              "     \"assert index_on_inner_list([('Greyson Fulton', 98, 99), ('Brady Kent', 97, 96), ('Wyatt Knott', 91, 94), ('Beau Turnbull', 94, 98)] ,1)==[('Wyatt Knott', 91, 94), ('Beau Turnbull', 94, 98), ('Brady Kent', 97, 96), ('Greyson Fulton', 98, 99)]\",\n",
              "     \"assert index_on_inner_list([('Greyson Fulton', 98, 99), ('Brady Kent', 97, 96), ('Wyatt Knott', 91, 94), ('Beau Turnbull', 94, 98)] ,2)==[('Wyatt Knott', 91, 94), ('Brady Kent', 97, 96), ('Beau Turnbull', 94, 98), ('Greyson Fulton', 98, 99)]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.892506883375347,\n",
              "     'tokenization_energy': 0.12550688338279725,\n",
              "     'inference_energy': 23.76699999999255,\n",
              "     'energy_per_token': 1.257500362282913,\n",
              "     'time': 0.5593688488006592,\n",
              "     'components': {'embeddings': np.float64(0.1256698944568634),\n",
              "      'attention': np.float64(9.256491136082799),\n",
              "      'ffn': np.float64(13.754671104650944),\n",
              "      'layernorm': np.float64(0.1563648512363434),\n",
              "      'output_layer': np.float64(0.23115337157249452)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the number of rotations in a circularly sorted array.',\n",
              "    'ground_truth_code': 'def find_rotation_count(A):\\r\\n    (left, right) = (0, len(A) - 1)\\r\\n    while left <= right:\\r\\n        if A[left] <= A[right]:\\r\\n            return left\\r\\n        mid = (left + right) // 2\\r\\n        next = (mid + 1) % len(A)\\r\\n        prev = (mid - 1 + len(A)) % len(A)\\r\\n        if A[mid] <= A[next] and A[mid] <= A[prev]:\\r\\n            return mid\\r\\n        elif A[mid] <= A[right]:\\r\\n            right = mid - 1\\r\\n        elif A[mid] >= A[left]:\\r\\n            left = mid + 1\\r\\n    return -1',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of unique required a triangle array sorted array of The',\n",
              "    'test_cases': ['assert find_rotation_count([8, 9, 10, 1, 2, 3, 4, 5, 6, 7]) == 3',\n",
              "     'assert find_rotation_count([8, 9, 10,2, 5, 6]) == 3',\n",
              "     'assert find_rotation_count([2, 5, 6, 8, 9, 10]) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.036572465883335,\n",
              "     'tokenization_energy': 0.11957246589660644,\n",
              "     'inference_energy': 23.91699999998673,\n",
              "     'energy_per_token': 1.413916027404902,\n",
              "     'time': 0.5669629573822021,\n",
              "     'components': {'embeddings': np.float64(0.12619528985023498),\n",
              "      'attention': np.float64(9.41462320589379),\n",
              "      'ffn': np.float64(9.48318686056754),\n",
              "      'layernorm': np.float64(0.13116242837905884),\n",
              "      'output_layer': np.float64(0.2354757857322693)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to toggle all odd bits of a given number.',\n",
              "    'ground_truth_code': 'def even_bit_toggle_number(n) : \\r\\n    res = 0; count = 0; temp = n    \\r\\n    while(temp > 0 ) : \\r\\n        if (count % 2 == 0) : \\r\\n            res = res | (1 << count)      \\r\\n        count = count + 1\\r\\n        temp >>= 1 \\r\\n    return n ^ res ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the the numbers in a number integer.\\n The',\n",
              "    'test_cases': ['assert even_bit_toggle_number(10) == 15',\n",
              "     'assert even_bit_toggle_number(20) == 1',\n",
              "     'assert even_bit_toggle_number(30) == 11'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.850289475691856,\n",
              "     'tokenization_energy': 0.1462894756793976,\n",
              "     'inference_energy': 28.704000000012456,\n",
              "     'energy_per_token': 1.9233526317127905,\n",
              "     'time': 0.5582098960876465,\n",
              "     'components': {'embeddings': np.float64(0.12296046280860902),\n",
              "      'attention': np.float64(18.53430706120783),\n",
              "      'ffn': np.float64(13.725964490891785),\n",
              "      'layernorm': np.float64(0.12468512058258056),\n",
              "      'output_layer': np.float64(0.48258656048774723)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the frequency of the smallest value in a given array.',\n",
              "    'ground_truth_code': 'def frequency_Of_Smallest(n,arr): \\r\\n    mn = arr[0] \\r\\n    freq = 1\\r\\n    for i in range(1,n): \\r\\n        if (arr[i] < mn): \\r\\n            mn = arr[i] \\r\\n            freq = 1\\r\\n        elif (arr[i] == mn): \\r\\n            freq += 1\\r\\n    return freq ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of each most number in a matrix matrix.\\n The',\n",
              "    'test_cases': ['assert frequency_Of_Smallest(5,[1,2,3,4,3]) == 1',\n",
              "     'assert frequency_Of_Smallest(7,[3,1,2,5,6,2,3]) == 1',\n",
              "     'assert frequency_Of_Smallest(7,[3,3,6,3,7,4,9]) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.07721739554347,\n",
              "     'tokenization_energy': 0.18721739554405215,\n",
              "     'inference_energy': 23.889999999999418,\n",
              "     'energy_per_token': 1.337623188641304,\n",
              "     'time': 0.5595064163208008,\n",
              "     'components': {'embeddings': np.float64(0.12237366509437562),\n",
              "      'attention': np.float64(18.555265543229062),\n",
              "      'ffn': np.float64(13.621702637665207),\n",
              "      'layernorm': np.float64(0.12634913063049316),\n",
              "      'output_layer': np.float64(0.31212782764434815)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': \"Write a function to find the n'th perrin number using recursion.\",\n",
              "    'ground_truth_code': 'def get_perrin(n):\\r\\n  if (n == 0):\\r\\n    return 3\\r\\n  if (n == 1):\\r\\n    return 0\\r\\n  if (n == 2):\\r\\n    return 2 \\r\\n  return get_perrin(n - 2) + get_perrin(n - 3)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-thh smallest-valueing number.\\n the.\\n The',\n",
              "    'test_cases': ['assert get_perrin(9) == 12',\n",
              "     'assert get_perrin(4) == 2',\n",
              "     'assert get_perrin(6) == 5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.789004738329794,\n",
              "     'tokenization_energy': 0.18700473833084108,\n",
              "     'inference_energy': 28.601999999998952,\n",
              "     'energy_per_token': 1.693470866960576,\n",
              "     'time': 0.5631840229034424,\n",
              "     'components': {'embeddings': np.float64(0.11956132006645204),\n",
              "      'attention': np.float64(14.21073142575228),\n",
              "      'ffn': np.float64(9.071145704747876),\n",
              "      'layernorm': np.float64(0.12703769755363464),\n",
              "      'output_layer': np.float64(0.22996711754798888)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find out the minimum no of swaps required for bracket balancing in the given string.',\n",
              "    'ground_truth_code': \"def swap_count(s):\\r\\n\\tchars = s\\r\\n\\tcount_left = 0\\r\\n\\tcount_right = 0\\r\\n\\tswap = 0\\r\\n\\timbalance = 0; \\r\\n\\tfor i in range(len(chars)):\\r\\n\\t\\tif chars[i] == '[':\\r\\n\\t\\t\\tcount_left += 1\\r\\n\\t\\t\\tif imbalance > 0:\\r\\n\\t\\t\\t\\tswap += imbalance\\r\\n\\t\\t\\t\\timbalance -= 1\\r\\n\\t\\telif chars[i] == ']':\\r\\n\\t\\t\\tcount_right += 1\\r\\n\\t\\t\\timbalance = (count_right - count_left) \\r\\n\\treturn swap\",\n",
              "    'generated_code': ')\\n\\n the function that compute the the number number....\\n required to a...\\n in a bracket bracket. The',\n",
              "    'test_cases': ['assert swap_count(\"[]][][\") == 2',\n",
              "     'assert swap_count(\"[[][]]\") == 0',\n",
              "     'assert swap_count(\"[[][]]][\") == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.021058988810633,\n",
              "     'tokenization_energy': 0.12305898880958557,\n",
              "     'inference_energy': 23.898000000001048,\n",
              "     'energy_per_token': 1.1438599518481254,\n",
              "     'time': 0.554417610168457,\n",
              "     'components': {'embeddings': np.float64(0.12094600224494934),\n",
              "      'attention': np.float64(18.67910960387799),\n",
              "      'ffn': np.float64(13.669583746914986),\n",
              "      'layernorm': np.float64(0.13035193824768065),\n",
              "      'output_layer': np.float64(0.3303364200592041)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a python function to check whether the hexadecimal number is even or odd.',\n",
              "    'ground_truth_code': 'def even_or_odd(N): \\r\\n    l = len(N) \\r\\n    if (N[l-1] ==\\'0\\'or N[l-1] ==\\'2\\'or \\r\\n        N[l-1] ==\\'4\\'or N[l-1] ==\\'6\\'or \\r\\n        N[l-1] ==\\'8\\'or N[l-1] ==\\'A\\'or \\r\\n        N[l-1] ==\\'C\\'or N[l-1] ==\\'E\\'): \\r\\n        return (\"Even\") \\r\\n    else: \\r\\n        return (\"Odd\") ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given representation\\n a or odd.\\n Write',\n",
              "    'test_cases': ['assert even_or_odd(\"AB3454D\") ==\"Odd\"',\n",
              "     'assert even_or_odd(\"ABC\") == \"Even\"',\n",
              "     'assert even_or_odd(\"AAD\") == \"Odd\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.47499999999127,\n",
              "     'tokenization_energy': 4.841000000000349,\n",
              "     'inference_energy': 23.63399999999092,\n",
              "     'energy_per_token': 1.7796874999994543,\n",
              "     'time': 0.562175989151001,\n",
              "     'components': {'embeddings': np.float64(0.12321940469741822),\n",
              "      'attention': np.float64(13.853474700682215),\n",
              "      'ffn': np.float64(13.613384934673205),\n",
              "      'layernorm': np.float64(0.12733100128173827),\n",
              "      'output_layer': np.float64(0.21576788139343261)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find the highest power of 2 that is less than or equal to n.',\n",
              "    'ground_truth_code': 'def highest_Power_of_2(n): \\r\\n    res = 0; \\r\\n    for i in range(n, 0, -1): \\r\\n        if ((i & (i - 1)) == 0): \\r\\n            res = i; \\r\\n            break; \\r\\n    return res; ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number-order of 2 that divides less than or equal to a.\\n Return',\n",
              "    'test_cases': ['assert highest_Power_of_2(10) == 8',\n",
              "     'assert highest_Power_of_2(19) == 16',\n",
              "     'assert highest_Power_of_2(32) == 32'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.82263480376883,\n",
              "     'tokenization_energy': 0.14163480377197266,\n",
              "     'inference_energy': 28.680999999996857,\n",
              "     'energy_per_token': 1.310119763807674,\n",
              "     'time': 0.5591816902160645,\n",
              "     'components': {'embeddings': np.float64(0.13211779594421386),\n",
              "      'attention': np.float64(14.063544061656925),\n",
              "      'ffn': np.float64(13.745634880069526),\n",
              "      'layernorm': np.float64(0.12645082807540894),\n",
              "      'output_layer': np.float64(0.3930957369804382)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': \"Write a function to find the n'th lucas number.\",\n",
              "    'ground_truth_code': 'def find_lucas(n): \\r\\n\\tif (n == 0): \\r\\n\\t\\treturn 2\\r\\n\\tif (n == 1): \\r\\n\\t\\treturn 1\\r\\n\\treturn find_lucas(n - 1) + find_lucas(n - 2) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum-thh smallestas number, The',\n",
              "    'test_cases': ['assert find_lucas(9) == 76',\n",
              "     'assert find_lucas(4) == 7',\n",
              "     'assert find_lucas(3) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.960128249175963,\n",
              "     'tokenization_energy': 0.155128249168396,\n",
              "     'inference_energy': 23.805000000007567,\n",
              "     'energy_per_token': 1.7114377320839973,\n",
              "     'time': 0.5575368404388428,\n",
              "     'components': {'embeddings': np.float64(0.11926633930206298),\n",
              "      'attention': np.float64(18.559341213713047),\n",
              "      'ffn': np.float64(13.389802726028021),\n",
              "      'layernorm': np.float64(0.1264049994945526),\n",
              "      'output_layer': np.float64(0.2785501599311829)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to insert a given string at the beginning of all items in a list.',\n",
              "    'ground_truth_code': 'def add_string(list,string):\\r\\n add_string=[string.format(i) for i in  list]\\r\\n return add_string',\n",
              "    'generated_code': ')\\n\\n the function that compute a character number into the first of a the in a list.\\n The',\n",
              "    'test_cases': [\"assert add_string([1,2,3,4],'temp{0}')==['temp1', 'temp2', 'temp3', 'temp4']\",\n",
              "     \"assert add_string(['a','b','c','d'], 'python{0}')==[ 'pythona', 'pythonb', 'pythonc', 'pythond']\",\n",
              "     \"assert add_string([5,6,7,8],'string{0}')==['string5', 'string6', 'string7', 'string8']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.51942886996374,\n",
              "     'tokenization_energy': 0.12142886996269227,\n",
              "     'inference_energy': 28.398000000001048,\n",
              "     'energy_per_token': 1.5010225721033548,\n",
              "     'time': 0.5596706867218018,\n",
              "     'components': {'embeddings': np.float64(0.12200564861297608),\n",
              "      'attention': np.float64(18.477763073935293),\n",
              "      'ffn': np.float64(13.605472025384078),\n",
              "      'layernorm': np.float64(0.12632086873054504),\n",
              "      'output_layer': np.float64(0.32785534858703613)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to convert more than one list to nested dictionary.',\n",
              "    'ground_truth_code': 'def convert_list_dictionary(l1, l2, l3):\\r\\n     result = [{x: {y: z}} for (x, y, z) in zip(l1, l2, l3)]\\r\\n     return result',\n",
              "    'generated_code': ')\\n\\n the function that compute a than one digit of a lists with For',\n",
              "    'test_cases': ['assert convert_list_dictionary([\"S001\", \"S002\", \"S003\", \"S004\"],[\"Adina Park\", \"Leyton Marsh\", \"Duncan Boyle\", \"Saim Richards\"] ,[85, 98, 89, 92])==[{\\'S001\\': {\\'Adina Park\\': 85}}, {\\'S002\\': {\\'Leyton Marsh\\': 98}}, {\\'S003\\': {\\'Duncan Boyle\\': 89}}, {\\'S004\\': {\\'Saim Richards\\': 92}}]',\n",
              "     'assert convert_list_dictionary([\"abc\",\"def\",\"ghi\",\"jkl\"],[\"python\",\"program\",\"language\",\"programs\"],[100,200,300,400])==[{\\'abc\\':{\\'python\\':100}},{\\'def\\':{\\'program\\':200}},{\\'ghi\\':{\\'language\\':300}},{\\'jkl\\':{\\'programs\\':400}}]',\n",
              "     'assert convert_list_dictionary([\"A1\",\"A2\",\"A3\",\"A4\"],[\"java\",\"C\",\"C++\",\"DBMS\"],[10,20,30,40])==[{\\'A1\\':{\\'java\\':10}},{\\'A2\\':{\\'C\\':20}},{\\'A3\\':{\\'C++\\':30}},{\\'A4\\':{\\'DBMS\\':40}}]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.976162963866955,\n",
              "     'tokenization_energy': 0.1201629638671875,\n",
              "     'inference_energy': 23.855999999999767,\n",
              "     'energy_per_token': 1.7125830688476396,\n",
              "     'time': 0.5563833713531494,\n",
              "     'components': {'embeddings': np.float64(0.12249872088432312),\n",
              "      'attention': np.float64(18.307225778579596),\n",
              "      'ffn': np.float64(13.75631550908077),\n",
              "      'layernorm': np.float64(0.12863209867477418),\n",
              "      'output_layer': np.float64(0.21602267646789552)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find the maximum sum possible by using the given equation f(n) = max( (f(n/2) + f(n/3) + f(n/4) + f(n/5)), n).',\n",
              "    'ground_truth_code': 'def get_max_sum (n):\\r\\n\\tres = list()\\r\\n\\tres.append(0)\\r\\n\\tres.append(1)\\r\\n\\ti = 2\\r\\n\\twhile i<n + 1:\\r\\n\\t\\tres.append(max(i, (res[int(i / 2)] \\r\\n\\t\\t\\t\\t\\t\\t+ res[int(i / 3)] +\\r\\n\\t\\t\\t\\t\\t\\t\\tres[int(i / 4)]\\r\\n\\t\\t\\t\\t\\t\\t+ res[int(i / 5)])))\\r\\n\\t\\ti = i + 1\\r\\n\\treturn res[n]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of by selecting exactly digits\\n.(x) = f{0f(n-2) + f(n/3)',\n",
              "    'test_cases': ['assert get_max_sum(60) == 106',\n",
              "     'assert get_max_sum(10) == 12',\n",
              "     'assert get_max_sum(2) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.42500000000291,\n",
              "     'tokenization_energy': 4.834000000002561,\n",
              "     'inference_energy': 23.59100000000035,\n",
              "     'energy_per_token': 0.888281250000091,\n",
              "     'time': 0.5657083988189697,\n",
              "     'components': {'embeddings': np.float64(0.12132873630523681),\n",
              "      'attention': np.float64(9.141114118338912),\n",
              "      'ffn': np.float64(13.818071465734624),\n",
              "      'layernorm': np.float64(0.1288307056427002),\n",
              "      'output_layer': np.float64(0.23410062336921691)},\n",
              "     'num_tokens': 32}},\n",
              "   {'prompt': 'Write a function to find the list with maximum length using lambda function.',\n",
              "    'ground_truth_code': 'def max_length_list(input_list):\\r\\n    max_length = max(len(x) for x in input_list )   \\r\\n    max_list = max(input_list, key = lambda i: len(i))    \\r\\n    return(max_length, max_list)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of the number in the expressions and You',\n",
              "    'test_cases': ['assert max_length_list([[0], [1, 3], [5, 7], [9, 11], [13, 15, 17]])==(3, [13, 15, 17])',\n",
              "     'assert max_length_list([[1,2,3,4,5],[1,2,3,4],[1,2,3],[1,2],[1]])==(5,[1,2,3,4,5])',\n",
              "     'assert max_length_list([[3,4,5],[6,7,8,9],[10,11,12]])==(4,[6,7,8,9])'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.51687557577342,\n",
              "     'tokenization_energy': 0.12487557578086854,\n",
              "     'inference_energy': 28.39199999999255,\n",
              "     'energy_per_token': 1.9011250383848945,\n",
              "     'time': 0.5654275417327881,\n",
              "     'components': {'embeddings': np.float64(0.1774482045173645),\n",
              "      'attention': np.float64(5.267933133125305),\n",
              "      'ffn': np.float64(4.441258250951766),\n",
              "      'layernorm': np.float64(0.19997427821159364),\n",
              "      'output_layer': np.float64(0.21326081943511965)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to check if given tuple is distinct or not.',\n",
              "    'ground_truth_code': 'def check_distinct(test_tup):\\r\\n  res = True\\r\\n  temp = set()\\r\\n  for ele in test_tup:\\r\\n    if ele in temp:\\r\\n      res = False\\r\\n      break\\r\\n    temp.add(ele)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a two of a.\\n not.\\n Return',\n",
              "    'test_cases': ['assert check_distinct((1, 4, 5, 6, 1, 4)) == False',\n",
              "     'assert check_distinct((1, 4, 5, 6)) == True',\n",
              "     'assert check_distinct((2, 3, 4, 5, 6)) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.82302134538174,\n",
              "     'tokenization_energy': 0.12102134537696839,\n",
              "     'inference_energy': 23.702000000004773,\n",
              "     'energy_per_token': 1.7016443818129814,\n",
              "     'time': 0.5632030963897705,\n",
              "     'components': {'embeddings': np.float64(0.12282443833351137),\n",
              "      'attention': np.float64(13.84656530141097),\n",
              "      'ffn': np.float64(13.491878296868993),\n",
              "      'layernorm': np.float64(0.12606302690505983),\n",
              "      'output_layer': np.float64(0.23127929687499998)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the first non-repeated character in a given string.',\n",
              "    'ground_truth_code': 'def first_non_repeating_character(str1):\\r\\n  char_order = []\\r\\n  ctr = {}\\r\\n  for c in str1:\\r\\n    if c in ctr:\\r\\n      ctr[c] += 1\\r\\n    else:\\r\\n      ctr[c] = 1 \\r\\n      char_order.append(c)\\r\\n  for c in char_order:\\r\\n    if ctr[c] == 1:\\r\\n      return c\\r\\n  return None',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence-zeropeating character in a string string. Return',\n",
              "    'test_cases': ['assert first_non_repeating_character(\"abcabc\") == None',\n",
              "     'assert first_non_repeating_character(\"abc\") == \"a\"',\n",
              "     'assert first_non_repeating_character(\"ababc\") == \"c\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.60941033792251,\n",
              "     'tokenization_energy': 0.12141033792495727,\n",
              "     'inference_energy': 28.487999999997555,\n",
              "     'energy_per_token': 1.5894116854401394,\n",
              "     'time': 0.5610060691833496,\n",
              "     'components': {'embeddings': np.float64(0.2520836012363434),\n",
              "      'attention': np.float64(13.817949914222352),\n",
              "      'ffn': np.float64(18.19161569617968),\n",
              "      'layernorm': np.float64(0.12571497988700867),\n",
              "      'output_layer': np.float64(0.230325101852417)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to check whether the given string starts and ends with the same character or not using regex.',\n",
              "    'ground_truth_code': 'import re  \\r\\nregex = r\\'^[a-z]$|^([a-z]).*\\\\1$\\'\\r\\ndef check_char(string): \\r\\n\\tif(re.search(regex, string)): \\r\\n\\t\\treturn \"Valid\" \\r\\n\\telse: \\r\\n\\t\\treturn \"Invalid\" ',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given\\n is with ends with the same character.\\n not. only. The',\n",
              "    'test_cases': ['assert check_char(\"abba\") == \"Valid\"',\n",
              "     'assert check_char(\"a\") == \"Valid\"',\n",
              "     'assert check_char(\"abcd\") == \"Invalid\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.53898613739526,\n",
              "     'tokenization_energy': 0.12098613739013672,\n",
              "     'inference_energy': 28.418000000005122,\n",
              "     'energy_per_token': 1.2972266426088754,\n",
              "     'time': 0.5615837574005127,\n",
              "     'components': {'embeddings': np.float64(0.12533125519752503),\n",
              "      'attention': np.float64(9.259881903884118),\n",
              "      'ffn': np.float64(9.17566132020764),\n",
              "      'layernorm': np.float64(0.12680725049972533),\n",
              "      'output_layer': np.float64(4.717000000004191)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to find the median of three specific numbers.',\n",
              "    'ground_truth_code': 'def median_numbers(a,b,c):\\r\\n if a > b:\\r\\n    if a < c:\\r\\n        median = a\\r\\n    elif b > c:\\r\\n        median = b\\r\\n    else:\\r\\n        median = c\\r\\n else:\\r\\n    if a > c:\\r\\n        median = a\\r\\n    elif b < c:\\r\\n        median = b\\r\\n    else:\\r\\n        median = c\\r\\n return median',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a integers integers. The',\n",
              "    'test_cases': ['assert median_numbers(25,55,65)==55.0',\n",
              "     'assert median_numbers(20,10,30)==20.0',\n",
              "     'assert median_numbers(15,45,75)==45.0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.864827042105606,\n",
              "     'tokenization_energy': 0.13682704210281374,\n",
              "     'inference_energy': 23.728000000002794,\n",
              "     'energy_per_token': 1.8357559263158159,\n",
              "     'time': 0.5559177398681641,\n",
              "     'components': {'embeddings': np.float64(0.13696773171424867),\n",
              "      'attention': np.float64(13.907941761980648),\n",
              "      'ffn': np.float64(18.422143957369144),\n",
              "      'layernorm': np.float64(0.1307503433227539),\n",
              "      'output_layer': np.float64(0.21903824424743654)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to compute the sum of digits of each number of a given list.',\n",
              "    'ground_truth_code': 'def sum_of_digits(nums):\\r\\n    return sum(int(el) for n in nums for el in str(n) if el.isdigit())',\n",
              "    'generated_code': ')\\n\\n the function that compute the number of all of a number in a given array, The',\n",
              "    'test_cases': ['assert sum_of_digits([10,2,56])==14',\n",
              "     \"assert sum_of_digits([[10,20,4,5,'b',70,'a']])==19\",\n",
              "     'assert sum_of_digits([10,20,-4,5,-70])==19'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.369713665003655,\n",
              "     'tokenization_energy': 0.14371366500854493,\n",
              "     'inference_energy': 28.22599999999511,\n",
              "     'energy_per_token': 1.576095203611314,\n",
              "     'time': 0.5613963603973389,\n",
              "     'components': {'embeddings': np.float64(0.18526844215393065),\n",
              "      'attention': np.float64(13.75573844169639),\n",
              "      'ffn': np.float64(13.52642354155169),\n",
              "      'layernorm': np.float64(0.13409012889862063),\n",
              "      'output_layer': np.float64(0.2433461093902588)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to perform the mathematical bitwise xor operation across the given tuples.',\n",
              "    'ground_truth_code': 'def bitwise_xor(test_tup1, test_tup2):\\r\\n  res = tuple(ele1 ^ ele2 for ele1, ele2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the following operation operations operation on all two array in The',\n",
              "    'test_cases': ['assert bitwise_xor((10, 4, 6, 9), (5, 2, 3, 3)) == (15, 6, 5, 10)',\n",
              "     'assert bitwise_xor((11, 5, 7, 10), (6, 3, 4, 4)) == (13, 6, 3, 14)',\n",
              "     'assert bitwise_xor((12, 6, 8, 11), (7, 4, 5, 6)) == (11, 2, 13, 13)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.972810229302617,\n",
              "     'tokenization_energy': 0.12781022930145264,\n",
              "     'inference_energy': 23.845000000001164,\n",
              "     'energy_per_token': 1.4983006393314136,\n",
              "     'time': 0.5575711727142334,\n",
              "     'components': {'embeddings': np.float64(0.12940399169921876),\n",
              "      'attention': np.float64(4.8665905964374545),\n",
              "      'ffn': np.float64(9.323734395982697),\n",
              "      'layernorm': np.float64(0.12744730472564697),\n",
              "      'output_layer': np.float64(0.2304018805027008)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to extract the frequency of unique tuples in the given list order irrespective.',\n",
              "    'ground_truth_code': 'def extract_freq(test_list):\\r\\n  res = len(list(set(tuple(sorted(sub)) for sub in test_list)))\\r\\n  return (res)',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits of the elements in a matrix matrix of.\\n of So',\n",
              "    'test_cases': ['assert extract_freq([(3, 4), (1, 2), (4, 3), (5, 6)] ) == 3',\n",
              "     'assert extract_freq([(4, 15), (2, 3), (5, 4), (6, 7)] ) == 4',\n",
              "     'assert extract_freq([(5, 16), (2, 3), (6, 5), (6, 9)] ) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.53567176698998,\n",
              "     'tokenization_energy': 0.12067176699638367,\n",
              "     'inference_energy': 28.414999999993597,\n",
              "     'energy_per_token': 1.5853150981661102,\n",
              "     'time': 0.5623533725738525,\n",
              "     'components': {'embeddings': np.float64(0.2546800138950348),\n",
              "      'attention': np.float64(4.699919715404509),\n",
              "      'ffn': np.float64(4.535331912755966),\n",
              "      'layernorm': np.float64(0.12585024690628052),\n",
              "      'output_layer': np.float64(0.2301643226146698)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to perform index wise addition of tuple elements in the given two nested tuples.',\n",
              "    'ground_truth_code': 'def add_nested_tuples(test_tup1, test_tup2):\\r\\n  res = tuple(tuple(a + b for a, b in zip(tup1, tup2))\\r\\n   for tup1, tup2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the-based addition of two elements in a function matrix-dimensional tuples. The',\n",
              "    'test_cases': ['assert add_nested_tuples(((1, 3), (4, 5), (2, 9), (1, 10)), ((6, 7), (3, 9), (1, 1), (7, 3))) == ((7, 10), (7, 14), (3, 10), (8, 13))',\n",
              "     'assert add_nested_tuples(((2, 4), (5, 6), (3, 10), (2, 11)), ((7, 8), (4, 10), (2, 2), (8, 4))) == ((9, 12), (9, 16), (5, 12), (10, 15))',\n",
              "     'assert add_nested_tuples(((3, 5), (6, 7), (4, 11), (3, 12)), ((8, 9), (5, 11), (3, 3), (9, 5))) == ((11, 14), (11, 18), (7, 14), (12, 17))'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.776620514872366,\n",
              "     'tokenization_energy': 0.12062051486968993,\n",
              "     'inference_energy': 28.656000000002678,\n",
              "     'energy_per_token': 1.5145589744669667,\n",
              "     'time': 0.5616016387939453,\n",
              "     'components': {'embeddings': np.float64(0.12128264832496642),\n",
              "      'attention': np.float64(13.783326294173254),\n",
              "      'ffn': np.float64(13.780173122885868),\n",
              "      'layernorm': np.float64(0.12768920946121215),\n",
              "      'output_layer': np.float64(4.819000000003143)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to compute the value of ncr%p.',\n",
              "    'ground_truth_code': 'def ncr_modp(n, r, p): \\r\\n    C = [0 for i in range(r+1)]   \\r\\n    C[0] = 1\\r\\n    for i in range(1, n+1): \\r\\n        for j in range(min(i, r), 0, -1): \\r\\n            C[j] = (C[j] + C[j-1]) % p   \\r\\n    return C[r] ',\n",
              "    'generated_code': ')\\n\\n the function that compute the number of a!, where Where',\n",
              "    'test_cases': ['assert ncr_modp(10,2,13)==6',\n",
              "     'assert ncr_modp(15,12,43)==25',\n",
              "     'assert ncr_modp(17,9,18)==10'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.784163326267734,\n",
              "     'tokenization_energy': 0.12016332626342774,\n",
              "     'inference_energy': 23.664000000004307,\n",
              "     'energy_per_token': 1.829551025097518,\n",
              "     'time': 0.5559179782867432,\n",
              "     'components': {'embeddings': np.float64(0.12174147725105286),\n",
              "      'attention': np.float64(4.784864498376847),\n",
              "      'ffn': np.float64(4.517585569381714),\n",
              "      'layernorm': np.float64(0.12523895740509033),\n",
              "      'output_layer': np.float64(0.2266424720287323)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to check if a url is valid or not using regex.',\n",
              "    'ground_truth_code': 'import re\\r\\ndef is_valid_URL(str):\\r\\n\\tregex = (\"((http|https)://)(www.)?\" +\\r\\n\\t\\t\\t\"[a-zA-Z0-9@:%._\\\\\\\\+~#?&//=]\" +\\r\\n\\t\\t\\t\"{2,256}\\\\\\\\.[a-z]\" +\\r\\n\\t\\t\\t\"{2,6}\\\\\\\\b([-a-zA-Z0-9@:%\" +\\r\\n\\t\\t\\t\"._\\\\\\\\+~#?&//=]*)\")\\r\\n\\tp = re.compile(regex)\\r\\n\\tif (str == None):\\r\\n\\t\\treturn False\\r\\n\\tif(re.search(p, str)):\\r\\n\\t\\treturn True\\r\\n\\telse:\\r\\n\\t\\treturn False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number is a, not.\\n the.\\n The',\n",
              "    'test_cases': ['assert is_valid_URL(\"https://www.google.com\") == True',\n",
              "     'assert is_valid_URL(\"https:/www.gmail.com\") == False',\n",
              "     'assert is_valid_URL(\"https:// www.redit.com\") == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.536781914473046,\n",
              "     'tokenization_energy': 0.12378191447257997,\n",
              "     'inference_energy': 28.413000000000466,\n",
              "     'energy_per_token': 1.7835488696545654,\n",
              "     'time': 0.561983585357666,\n",
              "     'components': {'embeddings': np.float64(0.1839544508457184),\n",
              "      'attention': np.float64(9.406734883783852),\n",
              "      'ffn': np.float64(13.503296997779161),\n",
              "      'layernorm': np.float64(0.12477020573616028),\n",
              "      'output_layer': np.float64(0.20992871713638306)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find the minimum of two numbers.',\n",
              "    'ground_truth_code': 'def minimum(a,b):   \\r\\n    if a <= b: \\r\\n        return a \\r\\n    else: \\r\\n        return b ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number a numbers without The',\n",
              "    'test_cases': ['assert minimum(1,2) == 1',\n",
              "     'assert minimum(-5,-4) == -5',\n",
              "     'assert minimum(0,0) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.894934554336476,\n",
              "     'tokenization_energy': 0.11893455433845519,\n",
              "     'inference_energy': 23.77599999999802,\n",
              "     'energy_per_token': 1.8380718887951135,\n",
              "     'time': 0.5557432174682617,\n",
              "     'components': {'embeddings': np.float64(0.12037136244773865),\n",
              "      'attention': np.float64(4.652563701152803),\n",
              "      'ffn': np.float64(4.582035071849822),\n",
              "      'layernorm': np.float64(0.21437635660171508),\n",
              "      'output_layer': np.float64(0.26295547914505)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to check whether an element exists within a tuple.',\n",
              "    'ground_truth_code': 'def check_tuplex(tuplex,tuple1): \\r\\n  if tuple1 in tuplex:\\r\\n    return True\\r\\n  else:\\r\\n     return False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a integer is in an matrix in If',\n",
              "    'test_cases': ['assert check_tuplex((\"w\", 3, \"r\", \"e\", \"s\", \"o\", \"u\", \"r\", \"c\", \"e\"),\\'r\\')==True',\n",
              "     'assert check_tuplex((\"w\", 3, \"r\", \"e\", \"s\", \"o\", \"u\", \"r\", \"c\", \"e\"),\\'5\\')==False',\n",
              "     'assert check_tuplex((\"w\", 3, \"r\", \"e\", \"s\", \"o\", \"u\", \"r\", \"c\",\"e\"),3)==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.755470485692726,\n",
              "     'tokenization_energy': 0.12147048568725585,\n",
              "     'inference_energy': 23.63400000000547,\n",
              "     'energy_per_token': 1.6968193204066233,\n",
              "     'time': 0.5582766532897949,\n",
              "     'components': {'embeddings': np.float64(0.17740070676803588),\n",
              "      'attention': np.float64(13.81883723664016),\n",
              "      'ffn': np.float64(18.074914389856858),\n",
              "      'layernorm': np.float64(0.19968117952346803),\n",
              "      'output_layer': np.float64(0.22141101694107057)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the parity of a given number.',\n",
              "    'ground_truth_code': 'def find_Parity(x): \\r\\n    y = x ^ (x >> 1); \\r\\n    y = y ^ (y >> 2); \\r\\n    y = y ^ (y >> 4); \\r\\n    y = y ^ (y >> 8); \\r\\n    y = y ^ (y >> 16); \\r\\n    if (y & 1): \\r\\n        return (\"Odd Parity\"); \\r\\n    return (\"Even Parity\"); ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of a number integer.\\n The',\n",
              "    'test_cases': ['assert find_Parity(12) == \"Even Parity\"',\n",
              "     'assert find_Parity(7) == \"Odd Parity\"',\n",
              "     'assert find_Parity(10) == \"Even Parity\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.739619904038847,\n",
              "     'tokenization_energy': 0.12661990404129028,\n",
              "     'inference_energy': 28.612999999997555,\n",
              "     'energy_per_token': 2.052829993145632,\n",
              "     'time': 0.5548245906829834,\n",
              "     'components': {'embeddings': np.float64(0.12749192571640014),\n",
              "      'attention': np.float64(13.734878789911978),\n",
              "      'ffn': np.float64(18.270679566133886),\n",
              "      'layernorm': np.float64(0.13263299274444582),\n",
              "      'output_layer': np.float64(0.22316064834594726)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to create the next bigger number by rearranging the digits of a given number.',\n",
              "    'ground_truth_code': 'def rearrange_bigger(n):\\r\\n    nums = list(str(n))\\r\\n    for i in range(len(nums)-2,-1,-1):\\r\\n        if nums[i] < nums[i+1]:\\r\\n            z = nums[i:]\\r\\n            y = min(filter(lambda x: x > z[0], z))\\r\\n            z.remove(y)\\r\\n            z.sort()\\r\\n            nums[i:] = [y] + z\\r\\n            return int(\"\".join(nums))\\r\\n    return False',\n",
              "    'generated_code': ')\\n\\n the function that compute a following permutation number by swappinganging the digits of a given number. If',\n",
              "    'test_cases': ['assert rearrange_bigger(12)==21',\n",
              "     'assert rearrange_bigger(10)==False',\n",
              "     'assert rearrange_bigger(102)==120'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.818631858819515,\n",
              "     'tokenization_energy': 0.1346318588256836,\n",
              "     'inference_energy': 23.68399999999383,\n",
              "     'energy_per_token': 1.1909315929409758,\n",
              "     'time': 0.5572068691253662,\n",
              "     'components': {'embeddings': np.float64(0.1337981491088867),\n",
              "      'attention': np.float64(9.364740417484192),\n",
              "      'ffn': np.float64(4.451777050256729),\n",
              "      'layernorm': np.float64(0.12683094644546508),\n",
              "      'output_layer': np.float64(0.23134705448150636)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find k number of pairs which consist of one element from the first array and one element from the second array.',\n",
              "    'ground_truth_code': 'import heapq\\r\\ndef k_smallest_pairs(nums1, nums2, k):\\r\\n   queue = []\\r\\n   def push(i, j):\\r\\n       if i < len(nums1) and j < len(nums2):\\r\\n           heapq.heappush(queue, [nums1[i] + nums2[j], i, j])\\r\\n   push(0, 0)\\r\\n   pairs = []\\r\\n   while queue and len(pairs) < k:\\r\\n       _, i, j = heapq.heappop(queue)\\r\\n       pairs.append([nums1[i], nums2[j]])\\r\\n       push(i, j + 1)\\r\\n       if j == 0:\\r\\n           push(i + 1, 0)\\r\\n   return pairs',\n",
              "    'generated_code': ')\\n\\n the function that compute the such of k in have of two even from each first group and one element from the second array. The',\n",
              "    'test_cases': ['assert k_smallest_pairs([1,3,7],[2,4,6],2)==[[1, 2], [1, 4]]',\n",
              "     'assert k_smallest_pairs([1,3,7],[2,4,6],1)==[[1, 2]]',\n",
              "     'assert k_smallest_pairs([1,3,7],[2,4,6],7)==[[1, 2], [1, 4], [3, 2], [1, 6], [3, 4], [3, 6], [7, 2]]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.76700059605087,\n",
              "     'tokenization_energy': 0.15600059604644775,\n",
              "     'inference_energy': 28.611000000004424,\n",
              "     'energy_per_token': 1.0654444665204026,\n",
              "     'time': 0.5648977756500244,\n",
              "     'components': {'embeddings': np.float64(0.12314944982528686),\n",
              "      'attention': np.float64(9.375645812282688),\n",
              "      'ffn': np.float64(13.555493949644267),\n",
              "      'layernorm': np.float64(4.769000000000233),\n",
              "      'output_layer': np.float64(0.23582831954956054)},\n",
              "     'num_tokens': 27}},\n",
              "   {'prompt': 'Write a function to find the minimum product from the pairs of tuples within a given list.',\n",
              "    'ground_truth_code': 'def min_product_tuple(list1):\\r\\n    result_min = min([abs(x * y) for x, y in list1] )\\r\\n    return result_min',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of a minimum of the in a given range of The',\n",
              "    'test_cases': ['assert min_product_tuple([(2, 7), (2, 6), (1, 8), (4, 9)] )==8',\n",
              "     'assert min_product_tuple([(10,20), (15,2), (5,10)] )==30',\n",
              "     'assert min_product_tuple([(11,44), (10,15), (20,5), (12, 9)] )==100'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.91623022842838,\n",
              "     'tokenization_energy': 0.12723022842407228,\n",
              "     'inference_energy': 23.789000000004307,\n",
              "     'energy_per_token': 1.2587489593909673,\n",
              "     'time': 0.5567846298217773,\n",
              "     'components': {'embeddings': np.float64(0.12448047637939454),\n",
              "      'attention': np.float64(13.99132367278065),\n",
              "      'ffn': np.float64(18.334162536377786),\n",
              "      'layernorm': np.float64(0.12458487963676454),\n",
              "      'output_layer': np.float64(0.22854142332077027)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the minimum value in a given heterogeneous list.',\n",
              "    'ground_truth_code': 'def min_val(listval):\\r\\n     min_val = min(i for i in listval if isinstance(i, int))\\r\\n     return min_val',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of a matrix matrix array of H',\n",
              "    'test_cases': [\"assert min_val(['Python', 3, 2, 4, 5, 'version'])==2\",\n",
              "     \"assert min_val(['Python', 15, 20, 25])==15\",\n",
              "     \"assert min_val(['Python', 30, 20, 40, 50, 'version'])==20\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.647832364076514,\n",
              "     'tokenization_energy': 0.12283236408233643,\n",
              "     'inference_energy': 28.52499999999418,\n",
              "     'energy_per_token': 1.9098554909384342,\n",
              "     'time': 0.5592894554138184,\n",
              "     'components': {'embeddings': np.float64(4.831999999994878),\n",
              "      'attention': np.float64(13.972600023510516),\n",
              "      'ffn': np.float64(18.101118172165588),\n",
              "      'layernorm': np.float64(0.12448264169692994),\n",
              "      'output_layer': np.float64(0.20898384094238281)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to convert the given snake case string to camel case string by using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef snake_to_camel(word):\\r\\n  return ''.join(x.capitalize() or '_' for x in word.split('_'))\",\n",
              "    'generated_code': ')\\n\\n the function that compute a digits matrix game string to a case string. removing only.\\n The',\n",
              "    'test_cases': [\"assert snake_to_camel('android_tv') == 'AndroidTv'\",\n",
              "     \"assert snake_to_camel('google_pixel') == 'GooglePixel'\",\n",
              "     \"assert snake_to_camel('apple_watch') == 'AppleWatch'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.667158139227073,\n",
              "     'tokenization_energy': 0.1221581392288208,\n",
              "     'inference_energy': 28.544999999998254,\n",
              "     'energy_per_token': 1.508797796801425,\n",
              "     'time': 0.5586669445037842,\n",
              "     'components': {'embeddings': np.float64(0.12080771398544311),\n",
              "      'attention': np.float64(13.899677104949136),\n",
              "      'ffn': np.float64(13.470636505117524),\n",
              "      'layernorm': np.float64(0.13104925990104677),\n",
              "      'output_layer': np.float64(0.23789137530326845)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a python function to remove odd numbers from a given list.',\n",
              "    'ground_truth_code': 'def remove_odd(l):\\r\\n    for i in l:\\r\\n        if i % 2 != 0:\\r\\n            l.remove(i)\\r\\n    return l',\n",
              "    'generated_code': ')\\n\\n the function function that compute all numbers from a list array of The',\n",
              "    'test_cases': ['assert remove_odd([1,2,3]) == [2]',\n",
              "     'assert remove_odd([2,4,6]) == [2,4,6]',\n",
              "     'assert remove_odd([10,20,3]) == [10,20]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.764465568543294,\n",
              "     'tokenization_energy': 0.13546556854248046,\n",
              "     'inference_energy': 23.629000000000815,\n",
              "     'energy_per_token': 1.697461826324521,\n",
              "     'time': 0.5638024806976318,\n",
              "     'components': {'embeddings': np.float64(0.13297669982910157),\n",
              "      'attention': np.float64(18.576573758842542),\n",
              "      'ffn': np.float64(13.46636026739958),\n",
              "      'layernorm': np.float64(0.12730996203422545),\n",
              "      'output_layer': np.float64(0.21610096240043639)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to extract the nth element from a given list of tuples.',\n",
              "    'ground_truth_code': 'def extract_nth_element(list1, n):\\r\\n    result = [x[n] for x in list1]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits digit from the matrix matrix of integers, The',\n",
              "    'test_cases': [\"assert extract_nth_element([('Greyson Fulton', 98, 99), ('Brady Kent', 97, 96), ('Wyatt Knott', 91, 94), ('Beau Turnbull', 94, 98)] ,0)==['Greyson Fulton', 'Brady Kent', 'Wyatt Knott', 'Beau Turnbull']\",\n",
              "     \"assert extract_nth_element([('Greyson Fulton', 98, 99), ('Brady Kent', 97, 96), ('Wyatt Knott', 91, 94), ('Beau Turnbull', 94, 98)] ,2)==[99, 96, 94, 98]\",\n",
              "     \"assert extract_nth_element([('Greyson Fulton', 98, 99), ('Brady Kent', 97, 96), ('Wyatt Knott', 91, 94), ('Beau Turnbull', 94, 98)],1)==[98, 97, 91, 94]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.502159163237433,\n",
              "     'tokenization_energy': 0.12315916323661803,\n",
              "     'inference_energy': 28.379000000000815,\n",
              "     'energy_per_token': 1.7813849477023396,\n",
              "     'time': 0.5531473159790039,\n",
              "     'components': {'embeddings': np.float64(0.12200867009162902),\n",
              "      'attention': np.float64(13.80029512237443),\n",
              "      'ffn': np.float64(18.059199784538244),\n",
              "      'layernorm': np.float64(4.720999999990454),\n",
              "      'output_layer': np.float64(0.21098625230789186)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to check whether the value exists in a sequence or not.',\n",
              "    'ground_truth_code': 'def overlapping(list1,list2):  \\r\\n    c=0\\r\\n    d=0\\r\\n    for i in list1: \\r\\n        c+=1\\r\\n    for i in list2: \\r\\n        d+=1\\r\\n    for i in range(0,c): \\r\\n        for j in range(0,d): \\r\\n            if(list1[i]==list2[j]): \\r\\n                return 1\\r\\n    return 0',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given of in the given of a.\\n The',\n",
              "    'test_cases': ['assert overlapping([1,2,3,4,5],[6,7,8,9]) == False',\n",
              "     'assert overlapping([1,2,3],[4,5,6]) == False',\n",
              "     'assert overlapping([1,4,5],[1,4,5]) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.866626430751058,\n",
              "     'tokenization_energy': 0.1466264307498932,\n",
              "     'inference_energy': 23.720000000001164,\n",
              "     'energy_per_token': 1.4039192018088857,\n",
              "     'time': 0.5674870014190674,\n",
              "     'components': {'embeddings': np.float64(0.12038391661643982),\n",
              "      'attention': np.float64(13.962637228738402),\n",
              "      'ffn': np.float64(18.18495435117686),\n",
              "      'layernorm': np.float64(0.2092437024116516),\n",
              "      'output_layer': np.float64(0.23338033318519594)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find a pair with highest product from a given array of integers.',\n",
              "    'ground_truth_code': 'def max_Product(arr): \\r\\n    arr_len = len(arr) \\r\\n    if (arr_len < 2): \\r\\n        return (\"No pairs exists\")           \\r\\n    x = arr[0]; y = arr[1]      \\r\\n    for i in range(0,arr_len): \\r\\n        for j in range(i + 1,arr_len): \\r\\n            if (arr[i] * arr[j] > x * y): \\r\\n                x = arr[i]; y = arr[j] \\r\\n    return x,y    ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of the sum in a given array of integers.\\n If',\n",
              "    'test_cases': ['assert max_Product([1,2,3,4,7,0,8,4]) == (7,8)',\n",
              "     'assert max_Product([0,-1,-2,-4,5,0,-6]) == (-4,-6)',\n",
              "     'assert max_Product([1,2,3]) == (2,3)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.85497949457227,\n",
              "     'tokenization_energy': 0.11997949457168579,\n",
              "     'inference_energy': 23.735000000000582,\n",
              "     'energy_per_token': 1.2555252365564353,\n",
              "     'time': 0.559626579284668,\n",
              "     'components': {'embeddings': np.float64(0.2109478144645691),\n",
              "      'attention': np.float64(13.792411358588026),\n",
              "      'ffn': np.float64(18.034407589681447),\n",
              "      'layernorm': np.float64(0.18885125350952148),\n",
              "      'output_layer': np.float64(0.22671660995483398)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find the maximum sum we can make by dividing number in three parts recursively and summing them up together for the given number.',\n",
              "    'ground_truth_code': 'MAX = 1000000\\r\\ndef breakSum(n): \\r\\n\\tdp = [0]*(n+1) \\r\\n\\tdp[0] = 0\\r\\n\\tdp[1] = 1\\r\\n\\tfor i in range(2, n+1): \\r\\n\\t\\tdp[i] = max(dp[int(i/2)] + dp[int(i/3)] + dp[int(i/4)], i); \\r\\n\\treturn dp[n]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of can get by selecting a n a parts....\\n...ming them... each three number. The',\n",
              "    'test_cases': ['assert breakSum(12) == 13',\n",
              "     'assert breakSum(24) == 27',\n",
              "     'assert breakSum(23) == 23'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.739048061366194,\n",
              "     'tokenization_energy': 0.11904806137084961,\n",
              "     'inference_energy': 28.619999999995343,\n",
              "     'energy_per_token': 0.9579682687122065,\n",
              "     'time': 0.5729219913482666,\n",
              "     'components': {'embeddings': np.float64(0.12023135375976562),\n",
              "      'attention': np.float64(9.549184261319343),\n",
              "      'ffn': np.float64(18.28041058802791),\n",
              "      'layernorm': np.float64(4.80000000000291),\n",
              "      'output_layer': np.float64(0.23905478310585024)},\n",
              "     'num_tokens': 30}},\n",
              "   {'prompt': 'Write a function to find common first element in given list of tuple.',\n",
              "    'ground_truth_code': 'def group_tuples(Input): \\r\\n\\tout = {} \\r\\n\\tfor elem in Input: \\r\\n\\t\\ttry: \\r\\n\\t\\t\\tout[elem[0]].extend(elem[1:]) \\r\\n\\t\\texcept KeyError: \\r\\n\\t\\t\\tout[elem[0]] = list(elem) \\r\\n\\treturn [tuple(values) for values in out.values()] ',\n",
              "    'generated_code': ')\\n\\n the function that compute the div-order of two two of lists and The',\n",
              "    'test_cases': [\"assert group_tuples([('x', 'y'), ('x', 'z'), ('w', 't')]) == [('x', 'y', 'z'), ('w', 't')]\",\n",
              "     \"assert group_tuples([('a', 'b'), ('a', 'c'), ('d', 'e')]) == [('a', 'b', 'c'), ('d', 'e')]\",\n",
              "     \"assert group_tuples([('f', 'g'), ('f', 'g'), ('h', 'i')]) == [('f', 'g', 'g'), ('h', 'i')]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.832576043849812,\n",
              "     'tokenization_energy': 0.12657604384422302,\n",
              "     'inference_energy': 23.706000000005588,\n",
              "     'energy_per_token': 1.588838402923321,\n",
              "     'time': 0.5654253959655762,\n",
              "     'components': {'embeddings': np.float64(0.12478938627243043),\n",
              "      'attention': np.float64(14.032682402623585),\n",
              "      'ffn': np.float64(13.626144554616765),\n",
              "      'layernorm': np.float64(0.1569445152282715),\n",
              "      'output_layer': np.float64(0.2827173843383789)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the sublist having maximum length.',\n",
              "    'ground_truth_code': 'def Find_Max(lst): \\r\\n    maxList = max((x) for x in lst) \\r\\n    return maxList',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number with the sum in If',\n",
              "    'test_cases': [\"assert Find_Max([['A'],['A','B'],['A','B','C']]) == ['A','B','C']\",\n",
              "     'assert Find_Max([[1],[1,2],[1,2,3]]) == [1,2,3]',\n",
              "     'assert Find_Max([[1,1],[1,2,3],[1,5,6,1]]) == [1,5,6,1]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.924972685815998,\n",
              "     'tokenization_energy': 0.1289726858139038,\n",
              "     'inference_energy': 23.796000000002095,\n",
              "     'energy_per_token': 1.8403825142935384,\n",
              "     'time': 0.5550980567932129,\n",
              "     'components': {'embeddings': np.float64(0.12287090277671815),\n",
              "      'attention': np.float64(13.861145798927637),\n",
              "      'ffn': np.float64(18.184470049377296),\n",
              "      'layernorm': np.float64(0.12468729066848754),\n",
              "      'output_layer': np.float64(0.21076081204414365)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to round every number of a given list of numbers and print the total sum multiplied by the length of the list.',\n",
              "    'ground_truth_code': 'def round_and_sum(list1):\\r\\n  lenght=len(list1)\\r\\n  round_and_sum=sum(list(map(round,list1))* lenght)\\r\\n  return round_and_sum',\n",
              "    'generated_code': ')\\n\\n the function that compute a element in a given matrix of numbers to a the result of of by the number of the list.\\n\\n So',\n",
              "    'test_cases': ['assert round_and_sum([22.4, 4.0, -16.22, -9.10, 11.00, -12.22, 14.20, -5.20, 17.50])==243',\n",
              "     'assert round_and_sum([5,2,9,24.3,29])==345',\n",
              "     'assert round_and_sum([25.0,56.7,89.2])==513'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.58865831732098,\n",
              "     'tokenization_energy': 0.12065831732749938,\n",
              "     'inference_energy': 28.46799999999348,\n",
              "     'energy_per_token': 1.0588391969378141,\n",
              "     'time': 0.5701878070831299,\n",
              "     'components': {'embeddings': np.float64(0.12286703824996947),\n",
              "      'attention': np.float64(9.581198297742404),\n",
              "      'ffn': np.float64(13.785796228395077),\n",
              "      'layernorm': np.float64(0.13180185079574586),\n",
              "      'output_layer': np.float64(0.2646110951900482)},\n",
              "     'num_tokens': 27}},\n",
              "   {'prompt': 'Write a python function to find the cube sum of first n even natural numbers.',\n",
              "    'ground_truth_code': 'def cube_Sum(n): \\r\\n    sum = 0\\r\\n    for i in range(1,n + 1): \\r\\n        sum += (2*i)*(2*i)*(2*i) \\r\\n    return sum',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number root of a n integers numbers numbers.\\n The',\n",
              "    'test_cases': ['assert cube_Sum(2) == 72',\n",
              "     'assert cube_Sum(3) == 288',\n",
              "     'assert cube_Sum(4) == 800'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.962224190720008,\n",
              "     'tokenization_energy': 0.1192241907119751,\n",
              "     'inference_energy': 23.843000000008033,\n",
              "     'energy_per_token': 1.4095425994541182,\n",
              "     'time': 0.559274435043335,\n",
              "     'components': {'embeddings': np.float64(0.1211017370223999),\n",
              "      'attention': np.float64(18.448964645388536),\n",
              "      'ffn': np.float64(13.671759662633411),\n",
              "      'layernorm': np.float64(0.13114585876464843),\n",
              "      'output_layer': np.float64(0.23379871845245362)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to concatenate each element of tuple by the delimiter.',\n",
              "    'ground_truth_code': 'def concatenate_tuple(test_tup):\\r\\n    delim = \"-\"\\r\\n    res = \\'\\'.join([str(ele) + delim for ele in test_tup])\\r\\n    res = res[ : len(res) - len(delim)]\\r\\n    return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute two row of a in element concaten in So',\n",
              "    'test_cases': ['assert concatenate_tuple((\"ID\", \"is\", 4, \"UTS\") ) == \\'ID-is-4-UTS\\'',\n",
              "     'assert concatenate_tuple((\"QWE\", \"is\", 4, \"RTY\") ) == \\'QWE-is-4-RTY\\'',\n",
              "     'assert concatenate_tuple((\"ZEN\", \"is\", 4, \"OP\") ) == \\'ZEN-is-4-OP\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.781408436771017,\n",
              "     'tokenization_energy': 0.12340843677520752,\n",
              "     'inference_energy': 28.65799999999581,\n",
              "     'energy_per_token': 2.055814888340787,\n",
              "     'time': 0.5585806369781494,\n",
              "     'components': {'embeddings': np.float64(0.12420054674148559),\n",
              "      'attention': np.float64(13.942287258859027),\n",
              "      'ffn': np.float64(9.437460842133735),\n",
              "      'layernorm': np.float64(0.1253697717189789),\n",
              "      'output_layer': np.float64(0.21010705018043518)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the average of cubes of first n natural numbers.',\n",
              "    'ground_truth_code': 'def find_Average_Of_Cube(n):  \\r\\n    sum = 0\\r\\n    for i in range(1, n + 1): \\r\\n        sum += i * i * i  \\r\\n    return round(sum / n, 6) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all in the n natural numbers.\\n So',\n",
              "    'test_cases': ['assert find_Average_Of_Cube(2) == 4.5',\n",
              "     'assert find_Average_Of_Cube(3) == 12',\n",
              "     'assert find_Average_Of_Cube(1) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.714840211388772,\n",
              "     'tokenization_energy': 0.12084021139144897,\n",
              "     'inference_energy': 23.593999999997322,\n",
              "     'energy_per_token': 1.3949906006699277,\n",
              "     'time': 0.5609073638916016,\n",
              "     'components': {'embeddings': np.float64(0.12118521475791931),\n",
              "      'attention': np.float64(13.871831307409563),\n",
              "      'ffn': np.float64(13.647013071532246),\n",
              "      'layernorm': np.float64(0.1298754014968872),\n",
              "      'output_layer': np.float64(0.22818665742874147)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to solve gold mine problem.',\n",
              "    'ground_truth_code': 'def get_maxgold(gold, m, n): \\r\\n    goldTable = [[0 for i in range(n)] \\r\\n                        for j in range(m)]   \\r\\n    for col in range(n-1, -1, -1): \\r\\n        for row in range(m):  \\r\\n            if (col == n-1): \\r\\n                right = 0\\r\\n            else: \\r\\n                right = goldTable[row][col+1] \\r\\n            if (row == 0 or col == n-1): \\r\\n                right_up = 0\\r\\n            else: \\r\\n                right_up = goldTable[row-1][col+1] \\r\\n            if (row == m-1 or col == n-1): \\r\\n                right_down = 0\\r\\n            else: \\r\\n                right_down = goldTable[row+1][col+1] \\r\\n            goldTable[row][col] = gold[row][col] + max(right, right_up, right_down) \\r\\n    res = goldTable[0][0] \\r\\n    for i in range(1, m): \\r\\n        res = max(res, goldTable[i][0])  \\r\\n    return res ',\n",
              "    'generated_code': ')\\n\\n the function that compute the coins problem.\\n The',\n",
              "    'test_cases': ['assert get_maxgold([[1, 3, 1, 5],[2, 2, 4, 1],[5, 0, 2, 3],[0, 6, 1, 2]],4,4)==16',\n",
              "     'assert get_maxgold([[10,20],[30,40]],2,2)==70',\n",
              "     'assert get_maxgold([[4,9],[3,7]],2,2)==13'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.438999999998487,\n",
              "     'tokenization_energy': 4.892999999996391,\n",
              "     'inference_energy': 23.546000000002095,\n",
              "     'energy_per_token': 2.8438999999998487,\n",
              "     'time': 0.5639266967773438,\n",
              "     'components': {'embeddings': np.float64(0.1256418170928955),\n",
              "      'attention': np.float64(9.263015841008746),\n",
              "      'ffn': np.float64(4.553664898395539),\n",
              "      'layernorm': np.float64(0.12668561220169067),\n",
              "      'output_layer': np.float64(0.2951854584217071)},\n",
              "     'num_tokens': 10}},\n",
              "   {'prompt': 'Write a function to extract only the rear index element of each string in the given tuple.',\n",
              "    'ground_truth_code': 'def extract_rear(test_tuple):\\r\\n  res = list(sub[len(sub) - 1] for sub in test_tuple)\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the the digits part of from a row in a string string.\\n The',\n",
              "    'test_cases': [\"assert extract_rear(('Mers', 'for', 'Vers') ) == ['s', 'r', 's']\",\n",
              "     \"assert extract_rear(('Avenge', 'for', 'People') ) == ['e', 'r', 'e']\",\n",
              "     \"assert extract_rear(('Gotta', 'get', 'go') ) == ['a', 't', 'o']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.740655905732652,\n",
              "     'tokenization_energy': 0.12465590572357177,\n",
              "     'inference_energy': 28.61600000000908,\n",
              "     'energy_per_token': 1.5126661003017186,\n",
              "     'time': 0.5604755878448486,\n",
              "     'components': {'embeddings': np.float64(0.12340159273147583),\n",
              "      'attention': np.float64(9.41611804938491),\n",
              "      'ffn': np.float64(13.53005377411435),\n",
              "      'layernorm': np.float64(4.735000000000582),\n",
              "      'output_layer': np.float64(0.29148575019836426)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to count the number of sublists containing a particular element.',\n",
              "    'ground_truth_code': 'def count_element_in_list(list1, x): \\r\\n    ctr = 0\\r\\n    for i in range(len(list1)): \\r\\n        if x in list1[i]: \\r\\n            ctr+= 1          \\r\\n    return ctr',\n",
              "    'generated_code': ')\\n\\n the function that compute the number of validarrays in exactly certain value in So',\n",
              "    'test_cases': ['assert count_element_in_list([[1, 3], [5, 7], [1, 11], [1, 15, 7]],1)==3',\n",
              "     \"assert count_element_in_list([['A', 'B'], ['A', 'C'], ['A', 'D', 'E'], ['B', 'C', 'D']],'A')==3\",\n",
              "     \"assert count_element_in_list([['A', 'B'], ['A', 'C'], ['A', 'D', 'E'], ['B', 'C', 'D']],'E')==1\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.08046413230081,\n",
              "     'tokenization_energy': 0.12046413230895997,\n",
              "     'inference_energy': 23.95999999999185,\n",
              "     'energy_per_token': 1.5050290082688007,\n",
              "     'time': 0.5611624717712402,\n",
              "     'components': {'embeddings': np.float64(0.12351808977127075),\n",
              "      'attention': np.float64(9.425608537443798),\n",
              "      'ffn': np.float64(13.589014200202424),\n",
              "      'layernorm': np.float64(0.13884620022773742),\n",
              "      'output_layer': np.float64(0.2947300634384155)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to filter odd numbers using lambda function.',\n",
              "    'ground_truth_code': 'def filter_oddnumbers(nums):\\r\\n odd_nums = list(filter(lambda x: x%2 != 0, nums))\\r\\n return odd_nums',\n",
              "    'generated_code': ')\\n\\n the function that compute the numbers from the expressions in The',\n",
              "    'test_cases': ['assert filter_oddnumbers([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[1,3,5,7,9]',\n",
              "     'assert filter_oddnumbers([10,20,45,67,84,93])==[45,67,93]',\n",
              "     'assert filter_oddnumbers([5,7,9,8,6,4,3])==[5,7,9,3]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.74119016957679,\n",
              "     'tokenization_energy': 0.1681901695728302,\n",
              "     'inference_energy': 28.573000000003958,\n",
              "     'energy_per_token': 2.395099180798066,\n",
              "     'time': 0.5573685169219971,\n",
              "     'components': {'embeddings': np.float64(4.834000000002561),\n",
              "      'attention': np.float64(13.876742945903445),\n",
              "      'ffn': np.float64(13.546404932978561),\n",
              "      'layernorm': np.float64(0.12768261885643006),\n",
              "      'output_layer': np.float64(0.2805974533557892)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to convert a date of yyyy-mm-dd format to dd-mm-yyyy format by using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef change_date_format(dt):\\r\\n        return re.sub(r'(\\\\d{4})-(\\\\d{1,2})-(\\\\d{1,2})', '\\\\\\\\3-\\\\\\\\2-\\\\\\\\1', dt)\",\n",
              "    'generated_code': ')\\n\\n the function that compute a given from the-mm-dd format into a...\\n-yyyy format. replacing the.\\n You',\n",
              "    'test_cases': ['assert change_date_format(\"2026-01-02\") == \\'02-01-2026\\'',\n",
              "     'assert change_date_format(\"2020-11-13\") == \\'13-11-2020\\'',\n",
              "     'assert change_date_format(\"2021-04-26\") == \\'26-04-2021\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.984463801626813,\n",
              "     'tokenization_energy': 0.12346380162239075,\n",
              "     'inference_energy': 23.861000000004424,\n",
              "     'energy_per_token': 1.090202900073946,\n",
              "     'time': 0.5560004711151123,\n",
              "     'components': {'embeddings': np.float64(0.12466259121894836),\n",
              "      'attention': np.float64(4.668235480546952),\n",
              "      'ffn': np.float64(4.590149289846421),\n",
              "      'layernorm': np.float64(0.13090162086486817),\n",
              "      'output_layer': np.float64(0.23764538192749024)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to sort the given array by using shell sort.',\n",
              "    'ground_truth_code': 'def shell_sort(my_list):\\r\\n    gap = len(my_list) // 2\\r\\n    while gap > 0:\\r\\n        for i in range(gap, len(my_list)):\\r\\n            current_item = my_list[i]\\r\\n            j = i\\r\\n            while j >= gap and my_list[j - gap] > current_item:\\r\\n                my_list[j] = my_list[j - gap]\\r\\n                j -= gap\\r\\n            my_list[j] = current_item\\r\\n        gap //= 2\\r\\n\\r\\n    return my_list',\n",
              "    'generated_code': ')\\n\\n the function that compute a sorted matrix in the the sort algorithm The',\n",
              "    'test_cases': ['assert shell_sort([12, 23, 4, 5, 3, 2, 12, 81, 56, 95]) == [2, 3, 4, 5, 12, 12, 23, 56, 81, 95]',\n",
              "     'assert shell_sort([24, 22, 39, 34, 87, 73, 68]) == [22, 24, 34, 39, 68, 73, 87]',\n",
              "     'assert shell_sort([32, 30, 16, 96, 82, 83, 74]) == [16, 30, 32, 74, 82, 83, 96]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.859068462371592,\n",
              "     'tokenization_energy': 0.12806846237182617,\n",
              "     'inference_energy': 23.730999999999767,\n",
              "     'energy_per_token': 1.704219175883685,\n",
              "     'time': 0.5586621761322021,\n",
              "     'components': {'embeddings': np.float64(0.12834292888641358),\n",
              "      'attention': np.float64(18.44278097509639),\n",
              "      'ffn': np.float64(13.786301974780159),\n",
              "      'layernorm': np.float64(0.12909620857238768),\n",
              "      'output_layer': np.float64(0.217347900390625)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to extract the elementwise and tuples from the given two tuples.',\n",
              "    'ground_truth_code': 'def and_tuples(test_tup1, test_tup2):\\r\\n  res = tuple(ele1 & ele2 for ele1, ele2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the digits from product the of a function matrix-dimensional, The',\n",
              "    'test_cases': ['assert and_tuples((10, 4, 6, 9), (5, 2, 3, 3)) == (0, 0, 2, 1)',\n",
              "     'assert and_tuples((1, 2, 3, 4), (5, 6, 7, 8)) == (1, 2, 3, 0)',\n",
              "     'assert and_tuples((8, 9, 11, 12), (7, 13, 14, 17)) == (0, 9, 10, 0)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.760075095651324,\n",
              "     'tokenization_energy': 0.12807509565353395,\n",
              "     'inference_energy': 28.631999999997788,\n",
              "     'energy_per_token': 1.6917691232736072,\n",
              "     'time': 0.5590472221374512,\n",
              "     'components': {'embeddings': np.float64(0.17765070152282714),\n",
              "      'attention': np.float64(4.680083926916122),\n",
              "      'ffn': np.float64(4.3285612201690675),\n",
              "      'layernorm': np.float64(0.1270091371536255),\n",
              "      'output_layer': np.float64(0.2547825314998627)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the directrix of a parabola.',\n",
              "    'ground_truth_code': 'def parabola_directrix(a, b, c): \\r\\n  directrix=((int)(c - ((b * b) + 1) * 4 * a ))\\r\\n  return directrix',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximumrix of a parabola given The',\n",
              "    'test_cases': ['assert parabola_directrix(5,3,2)==-198',\n",
              "     'assert parabola_directrix(9,8,4)==-2336',\n",
              "     'assert parabola_directrix(2,4,6)==-130'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.043509649988614,\n",
              "     'tokenization_energy': 0.13150964999198914,\n",
              "     'inference_energy': 23.911999999996624,\n",
              "     'energy_per_token': 1.6029006433325743,\n",
              "     'time': 0.5606949329376221,\n",
              "     'components': {'embeddings': np.float64(0.12054215312004089),\n",
              "      'attention': np.float64(9.377791851524728),\n",
              "      'ffn': np.float64(9.083081391806715),\n",
              "      'layernorm': np.float64(0.1272554533481598),\n",
              "      'output_layer': np.float64(0.21574156785011292)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function that takes two lists and returns true if they have at least one common element.',\n",
              "    'ground_truth_code': 'def common_element(list1, list2):\\r\\n     result = False\\r\\n     for x in list1:\\r\\n         for y in list2:\\r\\n             if x == y:\\r\\n                 result = True\\r\\n                 return result',\n",
              "    'generated_code': ')\\n\\n the function that, a integers of returns a if the have the least one common element.\\n How',\n",
              "    'test_cases': ['assert common_element([1,2,3,4,5], [5,6,7,8,9])==True',\n",
              "     'assert common_element([1,2,3,4,5], [6,7,8,9])==None',\n",
              "     \"assert common_element(['a','b','c'], ['d','b','e'])==True\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.78824909567961,\n",
              "     'tokenization_energy': 0.12124909567832948,\n",
              "     'inference_energy': 28.66700000000128,\n",
              "     'energy_per_token': 1.4394124547839806,\n",
              "     'time': 0.5576846599578857,\n",
              "     'components': {'embeddings': np.float64(0.12228037595748902),\n",
              "      'attention': np.float64(13.834384628524305),\n",
              "      'ffn': np.float64(9.10156294060382),\n",
              "      'layernorm': np.float64(0.12668967247009277),\n",
              "      'output_layer': np.float64(0.2283342182636261)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find the median of a trapezium.',\n",
              "    'ground_truth_code': 'def median_trapezium(base1,base2,height):\\r\\n median = 0.5 * (base1+ base2)\\r\\n return median',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a binaryapezoid.\\n The',\n",
              "    'test_cases': ['assert median_trapezium(15,25,35)==20',\n",
              "     'assert median_trapezium(10,20,30)==15',\n",
              "     'assert median_trapezium(6,9,4)==7.5'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.88910173701879,\n",
              "     'tokenization_energy': 0.1211017370223999,\n",
              "     'inference_energy': 23.76799999999639,\n",
              "     'energy_per_token': 1.5926067824679193,\n",
              "     'time': 0.5593512058258057,\n",
              "     'components': {'embeddings': np.float64(0.12285634875297546),\n",
              "      'attention': np.float64(9.19399940443854),\n",
              "      'ffn': np.float64(4.447740131616593),\n",
              "      'layernorm': np.float64(0.13107708978652954),\n",
              "      'output_layer': np.float64(0.21287181377410888)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to check whether the entered number is greater than the elements of the given array.',\n",
              "    'ground_truth_code': \"def check_greater(arr, number):\\r\\n  arr.sort()\\r\\n  if number > arr[-1]:\\r\\n    return ('Yes, the entered number is greater than those in the array')\\r\\n  else:\\r\\n    return ('No, entered number is less than those in the array')\",\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given number is a than or sum in the elements array.\\n If',\n",
              "    'test_cases': [\"assert check_greater([1, 2, 3, 4, 5], 4) == 'No, entered number is less than those in the array'\",\n",
              "     \"assert check_greater([2, 3, 4, 5, 6], 8) == 'Yes, the entered number is greater than those in the array'\",\n",
              "     \"assert check_greater([9, 7, 4, 8, 6, 1], 11) == 'Yes, the entered number is greater than those in the array'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.934594823831574,\n",
              "     'tokenization_energy': 0.2125948238372803,\n",
              "     'inference_energy': 23.721999999994296,\n",
              "     'energy_per_token': 1.1967297411915787,\n",
              "     'time': 0.5620462894439697,\n",
              "     'components': {'embeddings': np.float64(0.12408690261840821),\n",
              "      'attention': np.float64(18.445078809014408),\n",
              "      'ffn': np.float64(13.564518058779647),\n",
              "      'layernorm': np.float64(0.27901384472846985),\n",
              "      'output_layer': np.float64(0.2309715759754181)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': \"Write a function that matches a string that has an a followed by one or more b's.\",\n",
              "    'ground_truth_code': \"import re\\r\\ndef text_match_one(text):\\r\\n        patterns = 'ab+?'\\r\\n        if re.search(patterns,  text):\\r\\n                return 'Found a match!'\\r\\n        else:\\r\\n                return('Not matched!')\\r\\n\",\n",
              "    'generated_code': \")\\n\\n the function that, the given to is been odd... by a or more b's and The\",\n",
              "    'test_cases': ['assert text_match_one(\"ac\")==(\\'Not matched!\\')',\n",
              "     'assert text_match_one(\"dc\")==(\\'Not matched!\\')',\n",
              "     'assert text_match_one(\"abba\")==(\\'Found a match!\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.89410191679548,\n",
              "     'tokenization_energy': 0.13510191679000855,\n",
              "     'inference_energy': 28.75900000000547,\n",
              "     'energy_per_token': 1.444705095839774,\n",
              "     'time': 0.5605063438415527,\n",
              "     'components': {'embeddings': np.float64(0.12763772249221803),\n",
              "      'attention': np.float64(9.252491635565063),\n",
              "      'ffn': np.float64(9.171255397794535),\n",
              "      'layernorm': np.float64(4.8240000000078),\n",
              "      'output_layer': np.float64(0.23636903333663942)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to find the last digit of a given number.',\n",
              "    'ground_truth_code': 'def last_Digit(n) :\\r\\n    return (n % 10) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number digit of a number integer n The',\n",
              "    'test_cases': ['assert last_Digit(123) == 3',\n",
              "     'assert last_Digit(25) == 5',\n",
              "     'assert last_Digit(30) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.989455108394846,\n",
              "     'tokenization_energy': 0.12445510840415955,\n",
              "     'inference_energy': 23.864999999990687,\n",
              "     'energy_per_token': 1.599297007226323,\n",
              "     'time': 0.5624496936798096,\n",
              "     'components': {'embeddings': np.float64(0.12538878107070922),\n",
              "      'attention': np.float64(4.771992299318315),\n",
              "      'ffn': np.float64(9.0138554766092),\n",
              "      'layernorm': np.float64(0.13196971702575683),\n",
              "      'output_layer': np.float64(0.28862079334259033)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to print negative numbers in a list.',\n",
              "    'ground_truth_code': 'def neg_nos(list1):\\r\\n  for num in list1: \\r\\n    if num < 0: \\r\\n       return num ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the numbers in the negative of The',\n",
              "    'test_cases': ['assert neg_nos([-1,4,5,-6]) == -1,-6',\n",
              "     'assert neg_nos([-1,-2,3,4]) == -1,-2',\n",
              "     'assert neg_nos([-7,-6,8,9]) == -7,-6'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.84034269428591,\n",
              "     'tokenization_energy': 0.12734269428253173,\n",
              "     'inference_energy': 28.713000000003376,\n",
              "     'energy_per_token': 2.2184878995604547,\n",
              "     'time': 0.5541660785675049,\n",
              "     'components': {'embeddings': np.float64(4.853000000002794),\n",
              "      'attention': np.float64(18.747359046460595),\n",
              "      'ffn': np.float64(13.5932609348289),\n",
              "      'layernorm': np.float64(0.12566870737075805),\n",
              "      'output_layer': np.float64(0.21210958647727965)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to remove odd characters in a string.',\n",
              "    'ground_truth_code': \"def remove_odd(str1):\\r\\n str2 = ''\\r\\n for i in range(1, len(str1) + 1):\\r\\n    if(i % 2 == 0):\\r\\n        str2 = str2 + str1[i - 1]\\r\\n return str2\",\n",
              "    'generated_code': ')\\n\\n the function that compute the numbers from a string, The',\n",
              "    'test_cases': ['assert remove_odd(\"python\")==(\"yhn\")',\n",
              "     'assert remove_odd(\"program\")==(\"rga\")',\n",
              "     'assert remove_odd(\"language\")==(\"agae\")'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.91566808843438,\n",
              "     'tokenization_energy': 0.1206680884361267,\n",
              "     'inference_energy': 23.794999999998254,\n",
              "     'energy_per_token': 1.992972340702865,\n",
              "     'time': 0.5589606761932373,\n",
              "     'components': {'embeddings': np.float64(0.12180561661720275),\n",
              "      'attention': np.float64(13.910104748016922),\n",
              "      'ffn': np.float64(9.015612370963673),\n",
              "      'layernorm': np.float64(0.13022965598106384),\n",
              "      'output_layer': np.float64(0.21165831375122068)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to count bidirectional tuple pairs.',\n",
              "    'ground_truth_code': 'def count_bidirectional(test_list):\\r\\n  res = 0\\r\\n  for idx in range(0, len(test_list)):\\r\\n    for iidx in range(idx + 1, len(test_list)):\\r\\n      if test_list[iidx][0] == test_list[idx][1] and test_list[idx][1] == test_list[iidx][0]:\\r\\n        res += 1\\r\\n  return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute theirectional edges edges in So',\n",
              "    'test_cases': [\"assert count_bidirectional([(5, 6), (1, 2), (6, 5), (9, 1), (6, 5), (2, 1)] ) == '3'\",\n",
              "     \"assert count_bidirectional([(5, 6), (1, 3), (6, 5), (9, 1), (6, 5), (2, 1)] ) == '2'\",\n",
              "     \"assert count_bidirectional([(5, 6), (1, 2), (6, 5), (9, 2), (6, 5), (2, 1)] ) == '4'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.77148356771248,\n",
              "     'tokenization_energy': 0.13948356771469117,\n",
              "     'inference_energy': 23.631999999997788,\n",
              "     'energy_per_token': 2.1610439607011345,\n",
              "     'time': 0.5557308197021484,\n",
              "     'components': {'embeddings': np.float64(0.12435605239868164),\n",
              "      'attention': np.float64(18.103910050871434),\n",
              "      'ffn': np.float64(13.462151267285458),\n",
              "      'layernorm': np.float64(0.18580370235443114),\n",
              "      'output_layer': np.float64(0.20827834796905517)},\n",
              "     'num_tokens': 11}},\n",
              "   {'prompt': 'Write a function to convert a list of multiple integers into a single integer.',\n",
              "    'ground_truth_code': 'def multiple_to_single(L):\\r\\n  x = int(\"\".join(map(str, L)))\\r\\n  return x',\n",
              "    'generated_code': ')\\n\\n the function that compute a given of integers-choice into a list integer, The',\n",
              "    'test_cases': ['assert multiple_to_single([11, 33, 50])==113350',\n",
              "     'assert multiple_to_single([-1,2,3,4,5,6])==-123456',\n",
              "     'assert multiple_to_single([10,15,20,25])==10152025'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.649662693018676,\n",
              "     'tokenization_energy': 0.12066269302368164,\n",
              "     'inference_energy': 28.528999999994994,\n",
              "     'energy_per_token': 1.7906039183136673,\n",
              "     'time': 0.5626518726348877,\n",
              "     'components': {'embeddings': np.float64(0.225145414352417),\n",
              "      'attention': np.float64(9.463630007746398),\n",
              "      'ffn': np.float64(8.734059490920508),\n",
              "      'layernorm': np.float64(0.12487539410591125),\n",
              "      'output_layer': np.float64(0.24336053895950316)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find all adverbs and their positions in a given sentence.',\n",
              "    'ground_truth_code': 'import re\\r\\ndef find_adverb_position(text):\\r\\n for m in re.finditer(r\"\\\\w+ly\", text):\\r\\n    return (m.start(), m.end(), m.group(0))',\n",
              "    'generated_code': ')\\n\\n the function that compute the themissible in return positions in a given text.\\n The',\n",
              "    'test_cases': ['assert find_adverb_position(\"clearly!! we can see the sky\")==(0, 7, \\'clearly\\')',\n",
              "     'assert find_adverb_position(\"seriously!! there are many roses\")==(0, 9, \\'seriously\\')',\n",
              "     'assert find_adverb_position(\"unfortunately!! sita is going to home\")==(0, 13, \\'unfortunately\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.92154986334138,\n",
              "     'tokenization_energy': 0.12154986333847045,\n",
              "     'inference_energy': 23.80000000000291,\n",
              "     'energy_per_token': 1.4071499919612576,\n",
              "     'time': 0.5599222183227539,\n",
              "     'components': {'embeddings': np.float64(0.12281990575790405),\n",
              "      'attention': np.float64(18.329168352368754),\n",
              "      'ffn': np.float64(13.826922604798922),\n",
              "      'layernorm': np.float64(0.1276040940284729),\n",
              "      'output_layer': np.float64(0.23786057162284852)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the surface area of a cube.',\n",
              "    'ground_truth_code': 'def surfacearea_cube(l):\\r\\n  surfacearea= 6*l*l\\r\\n  return surfacearea',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum area of a cube.\\n The',\n",
              "    'test_cases': ['assert surfacearea_cube(5)==150',\n",
              "     'assert surfacearea_cube(3)==54',\n",
              "     'assert surfacearea_cube(10)==600'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.799340453158482,\n",
              "     'tokenization_energy': 0.12234045314788818,\n",
              "     'inference_energy': 28.677000000010594,\n",
              "     'energy_per_token': 2.215333881012191,\n",
              "     'time': 0.5966582298278809,\n",
              "     'components': {'embeddings': np.float64(0.12942956948280335),\n",
              "      'attention': np.float64(14.323323401223051),\n",
              "      'ffn': np.float64(9.14434217047086),\n",
              "      'layernorm': np.float64(0.18924937057495117),\n",
              "      'output_layer': np.float64(0.21361192321777345)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the ration of positive numbers in an array of integers.',\n",
              "    'ground_truth_code': 'from array import array\\r\\ndef positive_count(nums):\\r\\n    n = len(nums)\\r\\n    n1 = 0\\r\\n    for x in nums:\\r\\n        if x > 0:\\r\\n            n1 += 1\\r\\n        else:\\r\\n          None\\r\\n    return round(n1/n,2)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximumals the integers x a array that positive, The',\n",
              "    'test_cases': ['assert positive_count([0, 1, 2, -1, -5, 6, 0, -3, -2, 3, 4, 6, 8])==0.54',\n",
              "     'assert positive_count([2, 1, 2, -1, -5, 6, 4, -3, -2, 3, 4, 6, 8])==0.69',\n",
              "     'assert positive_count([2, 4, -6, -9, 11, -12, 14, -5, 17])==0.56'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.653153942103962,\n",
              "     'tokenization_energy': 0.1201539421081543,\n",
              "     'inference_energy': 28.53299999999581,\n",
              "     'energy_per_token': 1.6854796436531743,\n",
              "     'time': 0.6045823097229004,\n",
              "     'components': {'embeddings': np.float64(0.18423973083496095),\n",
              "      'attention': np.float64(23.327334060903286),\n",
              "      'ffn': np.float64(4.368340744256972),\n",
              "      'layernorm': np.float64(0.1383757095336914),\n",
              "      'output_layer': np.float64(0.2352771816253662)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find the largest negative number from the given list.',\n",
              "    'ground_truth_code': 'def largest_neg(list1): \\r\\n    max = list1[0] \\r\\n    for x in list1: \\r\\n        if x < max : \\r\\n             max = x  \\r\\n    return max',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number prime number in a largest array of If',\n",
              "    'test_cases': ['assert largest_neg([1,2,3,-4,-6]) == -6',\n",
              "     'assert largest_neg([1,2,3,-8,-9]) == -9',\n",
              "     'assert largest_neg([1,2,3,4,-1]) == -1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.600921810142232,\n",
              "     'tokenization_energy': 0.12192181015014648,\n",
              "     'inference_energy': 28.478999999992084,\n",
              "     'energy_per_token': 1.7875576131338895,\n",
              "     'time': 0.5998663902282715,\n",
              "     'components': {'embeddings': np.float64(4.811999999990803),\n",
              "      'attention': np.float64(5.099138594388963),\n",
              "      'ffn': np.float64(18.043235045921293),\n",
              "      'layernorm': np.float64(0.14722603917121888),\n",
              "      'output_layer': np.float64(0.22357497334480286)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to trim each tuple by k in the given tuple list.',\n",
              "    'ground_truth_code': 'def trim_tuple(test_list, K):\\r\\n  res = []\\r\\n  for ele in test_list:\\r\\n    N = len(ele)\\r\\n    res.append(tuple(list(ele)[K: N - K]))\\r\\n  return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the row in the, the function order,.\\n So',\n",
              "    'test_cases': [\"assert trim_tuple([(5, 3, 2, 1, 4), (3, 4, 9, 2, 1),(9, 1, 2, 3, 5), (4, 8, 2, 1, 7)], 2) == '[(2,), (9,), (2,), (2,)]'\",\n",
              "     \"assert trim_tuple([(5, 3, 2, 1, 4), (3, 4, 9, 2, 1), (9, 1, 2, 3, 5), (4, 8, 2, 1, 7)], 1) == '[(3, 2, 1), (4, 9, 2), (1, 2, 3), (8, 2, 1)]'\",\n",
              "     \"assert trim_tuple([(7, 8, 4, 9), (11, 8, 12, 4),(4, 1, 7, 8), (3, 6, 9, 7)], 1) == '[(8, 4), (8, 12), (1, 7), (6, 9)]'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.59189043522987,\n",
              "     'tokenization_energy': 0.12689043521881105,\n",
              "     'inference_energy': 28.46500000001106,\n",
              "     'energy_per_token': 1.786993152201867,\n",
              "     'time': 0.5993800163269043,\n",
              "     'components': {'embeddings': np.float64(4.753000000011525),\n",
              "      'attention': np.float64(14.300212988862883),\n",
              "      'ffn': np.float64(9.766253366701305),\n",
              "      'layernorm': np.float64(0.13525241088867188),\n",
              "      'output_layer': np.float64(0.2179519271850586)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to perform index wise multiplication of tuple elements in the given two tuples.',\n",
              "    'ground_truth_code': 'def index_multiplication(test_tup1, test_tup2):\\r\\n  res = tuple(tuple(a * b for a, b in zip(tup1, tup2))\\r\\n   for tup1, tup2 in zip(test_tup1, test_tup2))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the-based addition of two elements in a function matrix-dimensional. The',\n",
              "    'test_cases': ['assert index_multiplication(((1, 3), (4, 5), (2, 9), (1, 10)),((6, 7), (3, 9), (1, 1), (7, 3)) ) == ((6, 21), (12, 45), (2, 9), (7, 30))',\n",
              "     'assert index_multiplication(((2, 4), (5, 6), (3, 10), (2, 11)),((7, 8), (4, 10), (2, 2), (8, 4)) ) == ((14, 32), (20, 60), (6, 20), (16, 44))',\n",
              "     'assert index_multiplication(((3, 5), (6, 7), (4, 11), (3, 12)),((8, 9), (5, 11), (3, 3), (9, 5)) ) == ((24, 45), (30, 77), (12, 33), (27, 60))'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.4395668392136,\n",
              "     'tokenization_energy': 0.12256683921813964,\n",
              "     'inference_energy': 28.31699999999546,\n",
              "     'energy_per_token': 1.5799759355118668,\n",
              "     'time': 0.5987622737884521,\n",
              "     'components': {'embeddings': np.float64(4.757999999987078),\n",
              "      'attention': np.float64(18.680355722183247),\n",
              "      'ffn': np.float64(9.213326484693447),\n",
              "      'layernorm': np.float64(0.1328935797214508),\n",
              "      'output_layer': np.float64(0.23428720879554746)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to count the occurence of all elements of list in a tuple.',\n",
              "    'ground_truth_code': 'from collections import Counter \\r\\ndef count_Occurrence(tup, lst): \\r\\n    count = 0\\r\\n    for item in tup: \\r\\n        if item in lst: \\r\\n            count+= 1 \\r\\n    return count  ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the numberure of each the in a A another matrix, The',\n",
              "    'test_cases': [\"assert count_Occurrence(('a', 'a', 'c', 'b', 'd'),['a', 'b'] ) == 3\",\n",
              "     'assert count_Occurrence((1, 2, 3, 1, 4, 6, 7, 1, 4),[1, 4, 7]) == 6',\n",
              "     'assert count_Occurrence((1,2,3,4,5,6),[1,2]) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 33.341063714501566,\n",
              "     'tokenization_energy': 0.12206371450424193,\n",
              "     'inference_energy': 33.21899999999732,\n",
              "     'energy_per_token': 1.7547928270790298,\n",
              "     'time': 0.6273963451385498,\n",
              "     'components': {'embeddings': np.float64(4.841000000000349),\n",
              "      'attention': np.float64(5.286671226978302),\n",
              "      'ffn': np.float64(27.142795049901935),\n",
              "      'layernorm': np.float64(0.25071698808670045),\n",
              "      'output_layer': np.float64(0.24123892784118653)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to find cubes of individual elements in a list using lambda function.',\n",
              "    'ground_truth_code': 'def cube_nums(nums):\\r\\n cube_nums = list(map(lambda x: x ** 3, nums))\\r\\n return cube_nums',\n",
              "    'generated_code': ')\\n\\n the function that compute the in numbers digits in a matrix.\\n a functions in Then',\n",
              "    'test_cases': ['assert cube_nums([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]',\n",
              "     'assert cube_nums([10,20,30])==([1000, 8000, 27000])',\n",
              "     'assert cube_nums([12,15])==([1728, 3375])'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.381218339919812,\n",
              "     'tokenization_energy': 0.15021833992004394,\n",
              "     'inference_energy': 28.230999999999767,\n",
              "     'energy_per_token': 1.669483431759989,\n",
              "     'time': 0.6303730010986328,\n",
              "     'components': {'embeddings': np.float64(0.2173645076751709),\n",
              "      'attention': np.float64(14.948745029444806),\n",
              "      'ffn': np.float64(6.238879935979843),\n",
              "      'layernorm': np.float64(0.13857332468032837),\n",
              "      'output_layer': np.float64(0.24020447731018066)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to calculate the sum of perrin numbers.',\n",
              "    'ground_truth_code': 'def cal_sum(n): \\r\\n\\ta = 3\\r\\n\\tb = 0\\r\\n\\tc = 2\\r\\n\\tif (n == 0): \\r\\n\\t\\treturn 3\\r\\n\\tif (n == 1): \\r\\n\\t\\treturn 3\\r\\n\\tif (n == 2): \\r\\n\\t\\treturn 5\\r\\n\\tsum = 5\\r\\n\\twhile (n > 2): \\r\\n\\t\\td = a + b \\r\\n\\t\\tsum = sum + d \\r\\n\\t\\ta = b \\r\\n\\t\\tb = c \\r\\n\\t\\tc = d \\r\\n\\t\\tn = n-1\\r\\n\\treturn sum',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability of all-valuesing numbers.\\n The',\n",
              "    'test_cases': ['assert cal_sum(9) == 49',\n",
              "     'assert cal_sum(10) == 66',\n",
              "     'assert cal_sum(11) == 88'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.62295821715088,\n",
              "     'tokenization_energy': 0.12495821714401245,\n",
              "     'inference_energy': 28.49800000000687,\n",
              "     'energy_per_token': 2.0444970155107773,\n",
              "     'time': 0.5769011974334717,\n",
              "     'components': {'embeddings': np.float64(0.15534539222717283),\n",
              "      'attention': np.float64(10.339455737364478),\n",
              "      'ffn': np.float64(8.965945620532844),\n",
              "      'layernorm': np.float64(0.17234068155288695),\n",
              "      'output_layer': np.float64(0.21143286466598513)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to check whether the triangle is valid or not if 3 points are given.',\n",
              "    'ground_truth_code': \"def check_Triangle(x1,y1,x2,y2,x3,y3): \\r\\n    a = (x1*(y2-y3)+x2*(y3-y1)+x3*(y1-y2))   \\r\\n    if a == 0: \\r\\n        return ('No') \\r\\n    else: \\r\\n        return ('Yes') \",\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given is a, not. the0 points are given in The',\n",
              "    'test_cases': [\"assert check_Triangle(1,5,2,5,4,6) == 'Yes'\",\n",
              "     \"assert check_Triangle(1,1,1,4,1,5) == 'No'\",\n",
              "     \"assert check_Triangle(1,1,1,1,1,1) == 'No'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.108403923985897,\n",
              "     'tokenization_energy': 0.12040392398834229,\n",
              "     'inference_energy': 23.987999999997555,\n",
              "     'energy_per_token': 1.148019234475519,\n",
              "     'time': 0.5714750289916992,\n",
              "     'components': {'embeddings': np.float64(0.12168838143348694),\n",
              "      'attention': np.float64(18.568372054111446),\n",
              "      'ffn': np.float64(13.851116939769245),\n",
              "      'layernorm': np.float64(0.2270535969734192),\n",
              "      'output_layer': np.float64(0.2367788553237915)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function to extract specified size of strings from a give list of string values.',\n",
              "    'ground_truth_code': 'def extract_string(str, l):\\r\\n    result = [e for e in str if len(e) == l] \\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the elements from\\n from a given string of strings,, The',\n",
              "    'test_cases': [\"assert extract_string(['Python', 'list', 'exercises', 'practice', 'solution'] ,8)==['practice', 'solution']\",\n",
              "     \"assert extract_string(['Python', 'list', 'exercises', 'practice', 'solution'] ,6)==['Python']\",\n",
              "     \"assert extract_string(['Python', 'list', 'exercises', 'practice', 'solution'] ,9)==['exercises']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.763999999995576,\n",
              "     'tokenization_energy': 4.891999999992549,\n",
              "     'inference_energy': 23.872000000003027,\n",
              "     'energy_per_token': 1.5979999999997543,\n",
              "     'time': 0.5607223510742188,\n",
              "     'components': {'embeddings': np.float64(0.12595942592620848),\n",
              "      'attention': np.float64(9.35857526135072),\n",
              "      'ffn': np.float64(8.930500899794279),\n",
              "      'layernorm': np.float64(0.19140634059906006),\n",
              "      'output_layer': np.float64(0.230159939289093)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to remove all whitespaces from the given string using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef remove_whitespaces(text1):\\r\\n  return (re.sub(r'\\\\s+', '',text1))\",\n",
              "    'generated_code': ')\\n\\n the function that compute the thepaces from a function string.\\n only.\\n Return',\n",
              "    'test_cases': [\"assert remove_whitespaces(' Google    Flutter ') == 'GoogleFlutter'\",\n",
              "     \"assert remove_whitespaces(' Google    Dart ') == 'GoogleDart'\",\n",
              "     \"assert remove_whitespaces(' iOS    Swift ') == 'iOSSwift'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.754580137969693,\n",
              "     'tokenization_energy': 0.12158013796806334,\n",
              "     'inference_energy': 28.63300000000163,\n",
              "     'energy_per_token': 1.7971612586231058,\n",
              "     'time': 0.5642151832580566,\n",
              "     'components': {'embeddings': np.float64(0.12161387586593628),\n",
              "      'attention': np.float64(18.646406378277575),\n",
              "      'ffn': np.float64(13.771078073496232),\n",
              "      'layernorm': np.float64(4.760999999998603),\n",
              "      'output_layer': np.float64(0.21511153602600097)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function that gives loss amount if the given amount has loss else return none.',\n",
              "    'ground_truth_code': 'def loss_amount(actual_cost,sale_amount): \\r\\n  if(sale_amount > actual_cost):\\r\\n    amount = sale_amount - actual_cost\\r\\n    return amount\\r\\n  else:\\r\\n    return None',\n",
              "    'generated_code': ')\\n\\n the function that, the in for a loss loss of been in returns .\\n The',\n",
              "    'test_cases': ['assert loss_amount(1500,1200)==None',\n",
              "     'assert loss_amount(100,200)==100',\n",
              "     'assert loss_amount(2000,5000)==3000'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.94916188049165,\n",
              "     'tokenization_energy': 0.13516188049316405,\n",
              "     'inference_energy': 23.813999999998487,\n",
              "     'energy_per_token': 1.3305089933606473,\n",
              "     'time': 0.5682356357574463,\n",
              "     'components': {'embeddings': np.float64(0.12288369560241699),\n",
              "      'attention': np.float64(9.47609241366759),\n",
              "      'ffn': np.float64(13.539137030598708),\n",
              "      'layernorm': np.float64(0.12602521181106566),\n",
              "      'output_layer': np.float64(0.23484769964218138)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a python function to find the sum of even factors of a number.',\n",
              "    'ground_truth_code': 'import math \\r\\ndef sumofFactors(n) : \\r\\n    if (n % 2 != 0) : \\r\\n        return 0\\r\\n    res = 1\\r\\n    for i in range(2, (int)(math.sqrt(n)) + 1) :    \\r\\n        count = 0\\r\\n        curr_sum = 1\\r\\n        curr_term = 1\\r\\n        while (n % i == 0) : \\r\\n            count= count + 1\\r\\n            n = n // i \\r\\n            if (i == 2 and count == 1) : \\r\\n                curr_sum = 0\\r\\n            curr_term = curr_term * i \\r\\n            curr_sum = curr_sum + curr_term \\r\\n        res = res * curr_sum  \\r\\n    if (n >= 2) : \\r\\n        res = res * (1 + n) \\r\\n    return res ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all numbers of a number n The',\n",
              "    'test_cases': ['assert sumofFactors(18) == 26',\n",
              "     'assert sumofFactors(30) == 48',\n",
              "     'assert sumofFactors(6) == 8'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.038273291830556,\n",
              "     'tokenization_energy': 0.12427329182624816,\n",
              "     'inference_energy': 23.914000000004307,\n",
              "     'energy_per_token': 1.5023920807394098,\n",
              "     'time': 0.558570146560669,\n",
              "     'components': {'embeddings': np.float64(0.12408093881607055),\n",
              "      'attention': np.float64(13.881059522638797),\n",
              "      'ffn': np.float64(18.351116101020832),\n",
              "      'layernorm': np.float64(0.13407488536834716),\n",
              "      'output_layer': np.float64(0.2233912739753723)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': \"Write a function that matches a word containing 'z'.\",\n",
              "    'ground_truth_code': \"import re\\r\\ndef text_match_wordz(text):\\r\\n        patterns = '\\\\w*z.\\\\w*'\\r\\n        if re.search(patterns,  text):\\r\\n                return 'Found a match!'\\r\\n        else:\\r\\n                return('Not matched!')\",\n",
              "    'generated_code': \")\\n\\n the function that, the given by exactlya' The\",\n",
              "    'test_cases': ['assert text_match_wordz(\"pythonz.\")==(\\'Found a match!\\')',\n",
              "     'assert text_match_wordz(\"xyz.\")==(\\'Found a match!\\')',\n",
              "     'assert text_match_wordz(\"  lang  .\")==(\\'Not matched!\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.863512345790745,\n",
              "     'tokenization_energy': 0.18551234579086304,\n",
              "     'inference_energy': 28.677999999999884,\n",
              "     'energy_per_token': 2.405292695482562,\n",
              "     'time': 0.5652627944946289,\n",
              "     'components': {'embeddings': np.float64(0.1273015193939209),\n",
              "      'attention': np.float64(14.111490794654703),\n",
              "      'ffn': np.float64(9.24065580606577),\n",
              "      'layernorm': np.float64(0.1323667221069336),\n",
              "      'output_layer': np.float64(4.774999999994179)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to check whether the given month number contains 31 days or not.',\n",
              "    'ground_truth_code': 'def check_monthnumb_number(monthnum2):\\r\\n  if(monthnum2==1 or monthnum2==3 or monthnum2==5 or monthnum2==7 or monthnum2==8 or monthnum2==10 or monthnum2==12):\\r\\n    return True\\r\\n  else:\\r\\n    return False',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a given\\n and is at05 days.\\n not. The',\n",
              "    'test_cases': ['assert check_monthnumb_number(5)==True',\n",
              "     'assert check_monthnumb_number(2)==False',\n",
              "     'assert check_monthnumb_number(6)==False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.92911457776546,\n",
              "     'tokenization_energy': 0.13111457777023314,\n",
              "     'inference_energy': 23.797999999995227,\n",
              "     'energy_per_token': 1.2594270830402874,\n",
              "     'time': 0.5668141841888428,\n",
              "     'components': {'embeddings': np.float64(0.13106600332260132),\n",
              "      'attention': np.float64(14.06753601885261),\n",
              "      'ffn': np.float64(13.890154429904532),\n",
              "      'layernorm': np.float64(0.12625767016410827),\n",
              "      'output_layer': np.float64(0.23006105804443358)},\n",
              "     'num_tokens': 19}},\n",
              "   {'prompt': 'Write a function to reverse strings in a given list of string values.',\n",
              "    'ground_truth_code': 'def reverse_string_list(stringlist):\\r\\n    result = [x[::-1] for x in stringlist]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute a in a given array of strings,, The',\n",
              "    'test_cases': [\"assert reverse_string_list(['Red', 'Green', 'Blue', 'White', 'Black'])==['deR', 'neerG', 'eulB', 'etihW', 'kcalB']\",\n",
              "     \"assert reverse_string_list(['john','amal','joel','george'])==['nhoj','lama','leoj','egroeg']\",\n",
              "     \"assert reverse_string_list(['jack','john','mary'])==['kcaj','nhoj','yram']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.847446038255818,\n",
              "     'tokenization_energy': 0.12144603824615478,\n",
              "     'inference_energy': 28.726000000009662,\n",
              "     'energy_per_token': 1.9231630692170545,\n",
              "     'time': 0.5684256553649902,\n",
              "     'components': {'embeddings': np.float64(4.8510000000096625),\n",
              "      'attention': np.float64(14.286769196256994),\n",
              "      'ffn': np.float64(13.546925965793314),\n",
              "      'layernorm': np.float64(0.1253342890739441),\n",
              "      'output_layer': np.float64(0.21392340302467347)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the sublist having minimum length.',\n",
              "    'ground_truth_code': 'def Find_Min(lst): \\r\\n    minList = min((x) for x in lst) \\r\\n    return minList',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number with the sum in If',\n",
              "    'test_cases': ['assert Find_Min([[1],[1,2],[1,2,3]]) == [1]',\n",
              "     'assert Find_Min([[1,1],[1,1,1],[1,2,7,8]]) == [1,1]',\n",
              "     \"assert Find_Min([['x'],['x','y'],['x','y','z']]) == ['x']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.737890448810067,\n",
              "     'tokenization_energy': 0.12389044880867005,\n",
              "     'inference_energy': 28.614000000001397,\n",
              "     'energy_per_token': 2.2106069576007745,\n",
              "     'time': 0.5645036697387695,\n",
              "     'components': {'embeddings': np.float64(0.12148404836654664),\n",
              "      'attention': np.float64(14.143170344571),\n",
              "      'ffn': np.float64(9.073581966885946),\n",
              "      'layernorm': np.float64(0.12738531088829042),\n",
              "      'output_layer': np.float64(4.787000000011176)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the area of a rectangle.',\n",
              "    'ground_truth_code': 'def rectangle_area(l,b):\\r\\n  area=l*b\\r\\n  return area',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a triangle given The',\n",
              "    'test_cases': ['assert rectangle_area(10,20)==200',\n",
              "     'assert rectangle_area(10,5)==50',\n",
              "     'assert rectangle_area(4,2)==8'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.9879960753863,\n",
              "     'tokenization_energy': 0.1219960753917694,\n",
              "     'inference_energy': 23.86599999999453,\n",
              "     'energy_per_token': 1.9989996729488582,\n",
              "     'time': 0.5678603649139404,\n",
              "     'components': {'embeddings': np.float64(0.1233380663394928),\n",
              "      'attention': np.float64(14.18143991945521),\n",
              "      'ffn': np.float64(13.785857622638114),\n",
              "      'layernorm': np.float64(0.13015102624893188),\n",
              "      'output_layer': np.float64(0.21946944713592528)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to remove uppercase substrings from a given string by using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef remove_uppercase(str1):\\r\\n  remove_upper = lambda text: re.sub('[A-Z]', '', text)\\r\\n  result =  remove_upper(str1)\\r\\n  return (result)\",\n",
              "    'generated_code': ')\\n\\n the function that compute the lettersings from a given string.\\n using a.\\n The',\n",
              "    'test_cases': [\"assert remove_uppercase('cAstyoUrFavoRitETVshoWs') == 'cstyoravoitshos'\",\n",
              "     \"assert remove_uppercase('wAtchTheinTernEtrAdIo') == 'wtchheinerntrdo'\",\n",
              "     \"assert remove_uppercase('VoicESeaRchAndreComMendaTionS') == 'oiceachndreomendaion'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.901273411271976,\n",
              "     'tokenization_energy': 0.1252734112739563,\n",
              "     'inference_energy': 28.77599999999802,\n",
              "     'energy_per_token': 1.7000749065454104,\n",
              "     'time': 0.5685873031616211,\n",
              "     'components': {'embeddings': np.float64(4.855999999999767),\n",
              "      'attention': np.float64(14.139137440919642),\n",
              "      'ffn': np.float64(13.668235062352613),\n",
              "      'layernorm': np.float64(0.13448830342292786),\n",
              "      'output_layer': np.float64(0.3115452654361725)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to get the first element of each sublist.',\n",
              "    'ground_truth_code': 'def Extract(lst): \\r\\n    return [item[0] for item in lst] ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number-order of a row in The',\n",
              "    'test_cases': ['assert Extract([[1, 2], [3, 4, 5], [6, 7, 8, 9]]) == [1, 3, 6]',\n",
              "     'assert Extract([[1,2,3],[4, 5]]) == [1,4]',\n",
              "     'assert Extract([[9,8,1],[1,2]]) == [9,1]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.978527005442885,\n",
              "     'tokenization_energy': 0.13152700543403625,\n",
              "     'inference_energy': 28.847000000008848,\n",
              "     'energy_per_token': 2.069894786103063,\n",
              "     'time': 0.5592758655548096,\n",
              "     'components': {'embeddings': np.float64(0.12784926438331604),\n",
              "      'attention': np.float64(18.788624311440156),\n",
              "      'ffn': np.float64(13.710715895658474),\n",
              "      'layernorm': np.float64(0.12947736740112306),\n",
              "      'output_layer': np.float64(4.764000000010128)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to count the upper case characters in a given string.',\n",
              "    'ground_truth_code': \"def upper_ctr(str):\\r\\n    upper_ctr = 0\\r\\n    for i in range(len(str)):\\r\\n          if str[i] >= 'A' and str[i] <= 'Z': upper_ctr += 1\\r\\n          return upper_ctr\",\n",
              "    'generated_code': ')\\n\\n the function function that compute the number triangular letters in a string string.\\n The',\n",
              "    'test_cases': [\"assert upper_ctr('PYthon') == 1\",\n",
              "     \"assert upper_ctr('BigData') == 1\",\n",
              "     \"assert upper_ctr('program') == 0\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.08847043846757,\n",
              "     'tokenization_energy': 0.13347043848037718,\n",
              "     'inference_energy': 23.954999999987194,\n",
              "     'energy_per_token': 1.5055294024042232,\n",
              "     'time': 0.5654773712158203,\n",
              "     'components': {'embeddings': np.float64(0.14679198074340818),\n",
              "      'attention': np.float64(14.156751971954247),\n",
              "      'ffn': np.float64(9.111840398068308),\n",
              "      'layernorm': np.float64(0.12931942772865296),\n",
              "      'output_layer': np.float64(0.21921712064743043)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to find all possible combinations of the elements of a given list.',\n",
              "    'ground_truth_code': 'def combinations_list(list1):\\r\\n    if len(list1) == 0:\\r\\n        return [[]]\\r\\n    result = []\\r\\n    for el in combinations_list(list1[1:]):\\r\\n        result += [el, el+[list1[0]]]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute the the combinations of the digits in a given array that The',\n",
              "    'test_cases': [\"assert combinations_list(['orange', 'red', 'green', 'blue'])==[[], ['orange'], ['red'], ['red', 'orange'], ['green'], ['green', 'orange'], ['green', 'red'], ['green', 'red', 'orange'], ['blue'], ['blue', 'orange'], ['blue', 'red'], ['blue', 'red', 'orange'], ['blue', 'green'], ['blue', 'green', 'orange'], ['blue', 'green', 'red'], ['blue', 'green', 'red', 'orange']]\",\n",
              "     \"assert combinations_list(['red', 'green', 'blue', 'white', 'black', 'orange'])==[[], ['red'], ['green'], ['green', 'red'], ['blue'], ['blue', 'red'], ['blue', 'green'], ['blue', 'green', 'red'], ['white'], ['white', 'red'], ['white', 'green'], ['white', 'green', 'red'], ['white', 'blue'], ['white', 'blue', 'red'], ['white', 'blue', 'green'], ['white', 'blue', 'green', 'red'], ['black'], ['black', 'red'], ['black', 'green'], ['black', 'green', 'red'], ['black', 'blue'], ['black', 'blue', 'red'], ['black', 'blue', 'green'], ['black', 'blue', 'green', 'red'], ['black', 'white'], ['black', 'white', 'red'], ['black', 'white', 'green'], ['black', 'white', 'green', 'red'], ['black', 'white', 'blue'], ['black', 'white', 'blue', 'red'], ['black', 'white', 'blue', 'green'], ['black', 'white', 'blue', 'green', 'red'], ['orange'], ['orange', 'red'], ['orange', 'green'], ['orange', 'green', 'red'], ['orange', 'blue'], ['orange', 'blue', 'red'], ['orange', 'blue', 'green'], ['orange', 'blue', 'green', 'red'], ['orange', 'white'], ['orange', 'white', 'red'], ['orange', 'white', 'green'], ['orange', 'white', 'green', 'red'], ['orange', 'white', 'blue'], ['orange', 'white', 'blue', 'red'], ['orange', 'white', 'blue', 'green'], ['orange', 'white', 'blue', 'green', 'red'], ['orange', 'black'], ['orange', 'black', 'red'], ['orange', 'black', 'green'], ['orange', 'black', 'green', 'red'], ['orange', 'black', 'blue'], ['orange', 'black', 'blue', 'red'], ['orange', 'black', 'blue', 'green'], ['orange', 'black', 'blue', 'green', 'red'], ['orange', 'black', 'white'], ['orange', 'black', 'white', 'red'], ['orange', 'black', 'white', 'green'], ['orange', 'black', 'white', 'green', 'red'], ['orange', 'black', 'white', 'blue'], ['orange', 'black', 'white', 'blue', 'red'], ['orange', 'black', 'white', 'blue', 'green'], ['orange', 'black', 'white', 'blue', 'green', 'red']]\",\n",
              "     \"assert combinations_list(['red', 'green', 'black', 'orange'])==[[], ['red'], ['green'], ['green', 'red'], ['black'], ['black', 'red'], ['black', 'green'], ['black', 'green', 'red'], ['orange'], ['orange', 'red'], ['orange', 'green'], ['orange', 'green', 'red'], ['orange', 'black'], ['orange', 'black', 'red'], ['orange', 'black', 'green'], ['orange', 'black', 'green', 'red']]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.86605166961055,\n",
              "     'tokenization_energy': 0.12405166959762573,\n",
              "     'inference_energy': 28.742000000012922,\n",
              "     'energy_per_token': 1.6980030393888559,\n",
              "     'time': 0.5632932186126709,\n",
              "     'components': {'embeddings': np.float64(0.12338311386108398),\n",
              "      'attention': np.float64(18.78203739476914),\n",
              "      'ffn': np.float64(13.625046592233469),\n",
              "      'layernorm': np.float64(0.12552433919906616),\n",
              "      'output_layer': np.float64(0.2270739977359772)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the maximum product subarray of the given array.',\n",
              "    'ground_truth_code': 'def max_subarray_product(arr):\\r\\n\\tn = len(arr)\\r\\n\\tmax_ending_here = 1\\r\\n\\tmin_ending_here = 1\\r\\n\\tmax_so_far = 0\\r\\n\\tflag = 0\\r\\n\\tfor i in range(0, n):\\r\\n\\t\\tif arr[i] > 0:\\r\\n\\t\\t\\tmax_ending_here = max_ending_here * arr[i]\\r\\n\\t\\t\\tmin_ending_here = min (min_ending_here * arr[i], 1)\\r\\n\\t\\t\\tflag = 1\\r\\n\\t\\telif arr[i] == 0:\\r\\n\\t\\t\\tmax_ending_here = 1\\r\\n\\t\\t\\tmin_ending_here = 1\\r\\n\\t\\telse:\\r\\n\\t\\t\\ttemp = max_ending_here\\r\\n\\t\\t\\tmax_ending_here = max (min_ending_here * arr[i], 1)\\r\\n\\t\\t\\tmin_ending_here = temp * arr[i]\\r\\n\\t\\tif (max_so_far < max_ending_here):\\r\\n\\t\\t\\tmax_so_far = max_ending_here\\r\\n\\tif flag == 0 and max_so_far == 0:\\r\\n\\t\\treturn 0\\r\\n\\treturn max_so_far',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number ofarray in a maximum array.\\n The',\n",
              "    'test_cases': ['assert max_subarray_product([1, -2, -3, 0, 7, -8, -2]) == 112',\n",
              "     'assert max_subarray_product([6, -3, -10, 0, 2]) == 180 ',\n",
              "     'assert max_subarray_product([-2, -40, 0, -2, -3]) == 80'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.84829382013483,\n",
              "     'tokenization_energy': 0.11929382014274598,\n",
              "     'inference_energy': 28.728999999992084,\n",
              "     'energy_per_token': 1.803018363758427,\n",
              "     'time': 0.5723402500152588,\n",
              "     'components': {'embeddings': np.float64(0.18480900979042053),\n",
              "      'attention': np.float64(13.84685555220535),\n",
              "      'ffn': np.float64(13.925683262338396),\n",
              "      'layernorm': np.float64(0.12879893112182617),\n",
              "      'output_layer': np.float64(4.819999999992433)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to check if all values are same in a dictionary.',\n",
              "    'ground_truth_code': 'def check_value(dict, n):\\r\\n    result = all(x == n for x in dict.values()) \\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a the in even in a matrix.\\n Return',\n",
              "    'test_cases': [\"assert check_value({'Cierra Vega': 12, 'Alden Cantrell': 12, 'Kierra Gentry': 12, 'Pierre Cox': 12},10)==False\",\n",
              "     \"assert check_value({'Cierra Vega': 12, 'Alden Cantrell': 12, 'Kierra Gentry': 12, 'Pierre Cox': 12},12)==True\",\n",
              "     \"assert check_value({'Cierra Vega': 12, 'Alden Cantrell': 12, 'Kierra Gentry': 12, 'Pierre Cox': 12},5)==False\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.049251194962068,\n",
              "     'tokenization_energy': 0.13425119495391846,\n",
              "     'inference_energy': 23.91500000000815,\n",
              "     'energy_per_token': 1.6032834129974711,\n",
              "     'time': 0.5679609775543213,\n",
              "     'components': {'embeddings': np.float64(0.13198907804489135),\n",
              "      'attention': np.float64(14.1283364102887),\n",
              "      'ffn': np.float64(13.969210628984264),\n",
              "      'layernorm': np.float64(0.23909570932388305),\n",
              "      'output_layer': np.float64(0.2187861099243164)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to drop empty items from a given dictionary.',\n",
              "    'ground_truth_code': 'def drop_empty(dict1):\\r\\n  dict1 = {key:value for (key, value) in dict1.items() if value is not None}\\r\\n  return dict1',\n",
              "    'generated_code': ')\\n\\n the function that compute the strings from a  array of The',\n",
              "    'test_cases': [\"assert drop_empty({'c1': 'Red', 'c2': 'Green', 'c3':None})=={'c1': 'Red', 'c2': 'Green'}\",\n",
              "     \"assert drop_empty({'c1': 'Red', 'c2': None, 'c3':None})=={'c1': 'Red'}\",\n",
              "     \"assert drop_empty({'c1': None, 'c2': 'Green', 'c3':None})=={ 'c2': 'Green'}\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.909585582725935,\n",
              "     'tokenization_energy': 0.12358558273315429,\n",
              "     'inference_energy': 28.785999999992782,\n",
              "     'energy_per_token': 2.223814275594303,\n",
              "     'time': 0.5687360763549805,\n",
              "     'components': {'embeddings': np.float64(4.786999999996624),\n",
              "      'attention': np.float64(18.95702519916499),\n",
              "      'ffn': np.float64(13.361569055086466),\n",
              "      'layernorm': np.float64(0.13404151129722597),\n",
              "      'output_layer': np.float64(0.2731426680088043)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the peak element in the given array.',\n",
              "    'ground_truth_code': 'def find_peak_util(arr, low, high, n): \\r\\n\\tmid = low + (high - low)/2\\r\\n\\tmid = int(mid) \\r\\n\\tif ((mid == 0 or arr[mid - 1] <= arr[mid]) and\\r\\n\\t\\t(mid == n - 1 or arr[mid + 1] <= arr[mid])): \\r\\n\\t\\treturn mid \\r\\n\\telif (mid > 0 and arr[mid - 1] > arr[mid]): \\r\\n\\t\\treturn find_peak_util(arr, low, (mid - 1), n) \\r\\n\\telse: \\r\\n\\t\\treturn find_peak_util(arr, (mid + 1), high, n) \\r\\ndef find_peak(arr, n): \\r\\n\\treturn find_peak_util(arr, 0, n - 1, n) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum value in a matrix array.\\n The',\n",
              "    'test_cases': ['assert find_peak([1, 3, 20, 4, 1, 0], 6) == 2',\n",
              "     'assert find_peak([2, 3, 4, 5, 6], 5) == 4',\n",
              "     'assert find_peak([8, 9, 11, 12, 14, 15], 6) == 5 '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.884353023046046,\n",
              "     'tokenization_energy': 0.20035302305221558,\n",
              "     'inference_energy': 28.68399999999383,\n",
              "     'energy_per_token': 2.0631680730747175,\n",
              "     'time': 0.5686032772064209,\n",
              "     'components': {'embeddings': np.float64(0.12545240020751952),\n",
              "      'attention': np.float64(14.363766494264594),\n",
              "      'ffn': np.float64(13.634371937289485),\n",
              "      'layernorm': np.float64(0.20787563514709473),\n",
              "      'output_layer': np.float64(0.24104603433609006)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to convert decimal number to octal number.',\n",
              "    'ground_truth_code': 'def decimal_to_Octal(deciNum):\\r\\n    octalNum = 0\\r\\n    countval = 1;\\r\\n    dNo = deciNum;\\r\\n    while (deciNum!= 0):\\r\\n        remainder= deciNum % 8;\\r\\n        octalNum+= remainder*countval;\\r\\n        countval= countval*10;\\r\\n        deciNum //= 8; \\r\\n    return (octalNum)',\n",
              "    'generated_code': ')\\n\\n the function function that compute a numbers to binaryal number using The',\n",
              "    'test_cases': ['assert decimal_to_Octal(10) == 12',\n",
              "     'assert decimal_to_Octal(2) == 2',\n",
              "     'assert decimal_to_Octal(33) == 41'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.162781674386352,\n",
              "     'tokenization_energy': 0.12078167438507079,\n",
              "     'inference_energy': 24.04200000000128,\n",
              "     'energy_per_token': 1.7259129767418824,\n",
              "     'time': 0.5719377994537354,\n",
              "     'components': {'embeddings': np.float64(0.12231112575531006),\n",
              "      'attention': np.float64(14.53427956604981),\n",
              "      'ffn': np.float64(8.905687660694005),\n",
              "      'layernorm': np.float64(0.12818633556365966),\n",
              "      'output_layer': np.float64(0.3313686656951904)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to find the maximum product formed by multiplying numbers of an increasing subsequence of that array.',\n",
              "    'ground_truth_code': 'def max_product(arr, n ): \\r\\n\\tmpis =[0] * (n) \\r\\n\\tfor i in range(n): \\r\\n\\t\\tmpis[i] = arr[i] \\r\\n\\tfor i in range(1, n): \\r\\n\\t\\tfor j in range(i): \\r\\n\\t\\t\\tif (arr[i] > arr[j] and\\r\\n\\t\\t\\t\\t\\tmpis[i] < (mpis[j] * arr[i])): \\r\\n\\t\\t\\t\\t\\t\\tmpis[i] = mpis[j] * arr[i] \\r\\n\\treturn max(mpis)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number of by a three in adjacent array subsequence in a array. The',\n",
              "    'test_cases': ['assert max_product([3, 100, 4, 5, 150, 6], 6) == 45000 ',\n",
              "     'assert max_product([4, 42, 55, 68, 80], 5) == 50265600',\n",
              "     'assert max_product([10, 22, 9, 33, 21, 50, 41, 60], 8) == 21780000 '],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.80000000000291,\n",
              "     'tokenization_energy': 4.870999999999185,\n",
              "     'inference_energy': 23.929000000003725,\n",
              "     'energy_per_token': 1.3090909090910414,\n",
              "     'time': 0.5704708099365234,\n",
              "     'components': {'embeddings': np.float64(0.12424314975738525),\n",
              "      'attention': np.float64(9.266421448943088),\n",
              "      'ffn': np.float64(13.83926087546337),\n",
              "      'layernorm': np.float64(0.12544123101234436),\n",
              "      'output_layer': np.float64(0.2274829981327057)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a function to find the maximum profit earned from a maximum of k stock transactions',\n",
              "    'ground_truth_code': 'def max_profit(price, k):\\r\\n    n = len(price)\\r\\n    final_profit = [[None for x in range(n)] for y in range(k + 1)]\\r\\n    for i in range(k + 1):\\r\\n        for j in range(n):\\r\\n            if i == 0 or j == 0:\\r\\n                final_profit[i][j] = 0\\r\\n            else:\\r\\n                max_so_far = 0\\r\\n                for x in range(j):\\r\\n                    curr_price = price[j] - price[x] + final_profit[i-1][x]\\r\\n                    if max_so_far < curr_price:\\r\\n                        max_so_far = curr_price\\r\\n                final_profit[i][j] = max(final_profit[i][j-1], max_so_far)\\r\\n    return final_profit[k][n-1]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number given by a given number M non transactions.',\n",
              "    'test_cases': ['assert max_profit([1, 5, 2, 3, 7, 6, 4, 5], 3) == 10',\n",
              "     'assert max_profit([2, 4, 7, 5, 4, 3, 5], 2) == 7',\n",
              "     'assert max_profit([10, 6, 8, 4, 2], 2) == 2'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.99821404766734,\n",
              "     'tokenization_energy': 0.12021404767036438,\n",
              "     'inference_energy': 28.877999999996973,\n",
              "     'energy_per_token': 1.7057772969216083,\n",
              "     'time': 0.5640852451324463,\n",
              "     'components': {'embeddings': np.float64(0.22930357694625855),\n",
              "      'attention': np.float64(9.291521744249854),\n",
              "      'ffn': np.float64(18.81601472258172),\n",
              "      'layernorm': np.float64(0.12825866651535034),\n",
              "      'output_layer': np.float64(0.2335250825881958)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the pairwise addition of the elements of the given tuples.',\n",
              "    'ground_truth_code': 'def add_pairwise(test_tup):\\r\\n  res = tuple(i + j for i, j in zip(test_tup, test_tup[1:]))\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum distances of two numbers in a matrix matrix in So',\n",
              "    'test_cases': ['assert add_pairwise((1, 5, 7, 8, 10)) == (6, 12, 15, 18)',\n",
              "     'assert add_pairwise((2, 6, 8, 9, 11)) == (8, 14, 17, 20)',\n",
              "     'assert add_pairwise((3, 7, 9, 10, 12)) == (10, 16, 19, 22)'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.92622885894822,\n",
              "     'tokenization_energy': 0.1382288589477539,\n",
              "     'inference_energy': 23.788000000000466,\n",
              "     'energy_per_token': 1.4074252269969543,\n",
              "     'time': 0.5673670768737793,\n",
              "     'components': {'embeddings': np.float64(0.12411684894561767),\n",
              "      'attention': np.float64(13.813218827242613),\n",
              "      'ffn': np.float64(13.562593469852581),\n",
              "      'layernorm': np.float64(0.12653192949295045),\n",
              "      'output_layer': np.float64(0.2309898929595947)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find remainder of array multiplication divided by n.',\n",
              "    'ground_truth_code': 'def find_remainder(arr, lens, n): \\r\\n    mul = 1\\r\\n    for i in range(lens):  \\r\\n        mul = (mul * (arr[i] % n)) % n \\r\\n    return mul % n ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the when a after modulo by a.\\n\\n So',\n",
              "    'test_cases': ['assert find_remainder([ 100, 10, 5, 25, 35, 14 ],6,11) ==9',\n",
              "     'assert find_remainder([1,1,1],3,1) == 0',\n",
              "     'assert find_remainder([1,2,1],3,2) == 0'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.801000000006752,\n",
              "     'tokenization_energy': 4.94100000000617,\n",
              "     'inference_energy': 23.860000000000582,\n",
              "     'energy_per_token': 1.920066666667117,\n",
              "     'time': 0.5518040657043457,\n",
              "     'components': {'embeddings': np.float64(0.12704973220825197),\n",
              "      'attention': np.float64(13.880160085443753),\n",
              "      'ffn': np.float64(18.05149679159769),\n",
              "      'layernorm': np.float64(0.12653383374214172),\n",
              "      'output_layer': np.float64(0.21440109801292417)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to check whether the given list contains consecutive numbers or not.',\n",
              "    'ground_truth_code': 'def check_Consecutive(l): \\r\\n    return sorted(l) == list(range(min(l),max(l)+1)) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute whether a given \\n of exactly numbers, not. Con',\n",
              "    'test_cases': ['assert check_Consecutive([1,2,3,4,5]) == True',\n",
              "     'assert check_Consecutive([1,2,3,5,6]) == False',\n",
              "     'assert check_Consecutive([1,2,1]) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.863227935792178,\n",
              "     'tokenization_energy': 0.14322793579101561,\n",
              "     'inference_energy': 28.720000000001164,\n",
              "     'energy_per_token': 1.69783693739954,\n",
              "     'time': 0.5712029933929443,\n",
              "     'components': {'embeddings': np.float64(0.12253267455101012),\n",
              "      'attention': np.float64(9.208163566118222),\n",
              "      'ffn': np.float64(13.791983780859738),\n",
              "      'layernorm': np.float64(0.1284904170036316),\n",
              "      'output_layer': np.float64(0.2618835234642029)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the tuple intersection of elements in the given tuple list irrespective of their order.',\n",
              "    'ground_truth_code': 'def tuple_intersection(test_list1, test_list2):\\r\\n  res = set([tuple(sorted(ele)) for ele in test_list1]) & set([tuple(sorted(ele)) for ele in test_list2])\\r\\n  return (res)',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum with in two in a tuple matrix.\\n\\n.\\n of order order.\\n\\n The',\n",
              "    'test_cases': ['assert tuple_intersection([(3, 4), (5, 6), (9, 10), (4, 5)] , [(5, 4), (3, 4), (6, 5), (9, 11)]) == {(4, 5), (3, 4), (5, 6)}',\n",
              "     'assert tuple_intersection([(4, 1), (7, 4), (11, 13), (17, 14)] , [(1, 4), (7, 4), (16, 12), (10, 13)]) == {(4, 7), (1, 4)}',\n",
              "     'assert tuple_intersection([(2, 1), (3, 2), (1, 3), (1, 4)] , [(11, 2), (2, 3), (6, 2), (1, 3)]) == {(1, 3), (2, 3)}'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.329913227799114,\n",
              "     'tokenization_energy': 0.12091322779655457,\n",
              "     'inference_energy': 24.20900000000256,\n",
              "     'energy_per_token': 1.1585672965618625,\n",
              "     'time': 0.5602719783782959,\n",
              "     'components': {'embeddings': np.float64(0.12056625843048095),\n",
              "      'attention': np.float64(18.75021065379004),\n",
              "      'ffn': np.float64(13.615850646251813),\n",
              "      'layernorm': np.float64(0.12983456230163573),\n",
              "      'output_layer': np.float64(0.23379596376419068)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function to replace characters in a string.',\n",
              "    'ground_truth_code': 'def replace_char(str1,ch,newch):\\r\\n str2 = str1.replace(ch, newch)\\r\\n return str2',\n",
              "    'generated_code': ')\\n\\n the function that compute all in a matrix with The',\n",
              "    'test_cases': ['assert replace_char(\"polygon\",\\'y\\',\\'l\\')==(\"pollgon\")',\n",
              "     'assert replace_char(\"character\",\\'c\\',\\'a\\')==(\"aharaater\")',\n",
              "     'assert replace_char(\"python\",\\'l\\',\\'a\\')==(\"python\")'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.97256921005447,\n",
              "     'tokenization_energy': 0.12356921005249023,\n",
              "     'inference_energy': 28.84900000000198,\n",
              "     'energy_per_token': 2.63386992818677,\n",
              "     'time': 0.5587270259857178,\n",
              "     'components': {'embeddings': np.float64(0.12377500629425049),\n",
              "      'attention': np.float64(18.513159348496586),\n",
              "      'ffn': np.float64(13.373727202652955),\n",
              "      'layernorm': np.float64(0.1285813512802124),\n",
              "      'output_layer': np.float64(0.21231845998764037)},\n",
              "     'num_tokens': 11}},\n",
              "   {'prompt': 'Write a function to sort counter by value.',\n",
              "    'ground_truth_code': 'from collections import Counter\\r\\ndef sort_counter(dict1):\\r\\n x = Counter(dict1)\\r\\n sort_counter=x.most_common()\\r\\n return sort_counter',\n",
              "    'generated_code': ')\\n\\n the function that compute a-clock the, So',\n",
              "    'test_cases': [\"assert sort_counter({'Math':81, 'Physics':83, 'Chemistry':87})==[('Chemistry', 87), ('Physics', 83), ('Math', 81)]\",\n",
              "     \"assert sort_counter({'Math':400, 'Physics':300, 'Chemistry':250})==[('Math', 400), ('Physics', 300), ('Chemistry', 250)]\",\n",
              "     \"assert sort_counter({'Math':900, 'Physics':1000, 'Chemistry':1250})==[('Chemistry', 1250), ('Physics', 1000), ('Math', 900)]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.952997570505715,\n",
              "     'tokenization_energy': 0.12199757051467895,\n",
              "     'inference_energy': 23.830999999991036,\n",
              "     'energy_per_token': 2.3952997570505716,\n",
              "     'time': 0.5558393001556396,\n",
              "     'components': {'embeddings': np.float64(0.12379314708709717),\n",
              "      'attention': np.float64(18.303001338225673),\n",
              "      'ffn': np.float64(13.431729471215512),\n",
              "      'layernorm': np.float64(0.12811257576942445),\n",
              "      'output_layer': np.float64(0.216597740650177)},\n",
              "     'num_tokens': 10}},\n",
              "   {'prompt': 'Write a python function to find the sum of the largest and smallest value in a given array.',\n",
              "    'ground_truth_code': 'def big_sum(nums):\\r\\n      sum= max(nums)+min(nums)\\r\\n      return sum',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all digits three second numbers in a given array.\\n The',\n",
              "    'test_cases': ['assert big_sum([1,2,3]) == 4',\n",
              "     'assert big_sum([-1,2,3,4]) == 3',\n",
              "     'assert big_sum([2,3,6]) == 8'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.02599999999802,\n",
              "     'tokenization_energy': 4.889999999999418,\n",
              "     'inference_energy': 24.135999999998603,\n",
              "     'energy_per_token': 1.451299999999901,\n",
              "     'time': 0.5559780597686768,\n",
              "     'components': {'embeddings': np.float64(0.12408093881607055),\n",
              "      'attention': np.float64(14.057579893599613),\n",
              "      'ffn': np.float64(18.50181489418738),\n",
              "      'layernorm': np.float64(0.13348450660705566),\n",
              "      'output_layer': np.float64(0.32267524003982545)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a python function to convert the given string to lower case.',\n",
              "    'ground_truth_code': 'def is_lower(string):\\r\\n  return (string.lower())',\n",
              "    'generated_code': ')\\n\\n the function function that compute a matrix matrix into a case, The',\n",
              "    'test_cases': ['assert is_lower(\"InValid\") == \"invalid\"',\n",
              "     'assert is_lower(\"TruE\") == \"true\"',\n",
              "     'assert is_lower(\"SenTenCE\") == \"sentence\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.8317616133776,\n",
              "     'tokenization_energy': 0.12876161336898803,\n",
              "     'inference_energy': 28.703000000008615,\n",
              "     'energy_per_token': 2.059411543812686,\n",
              "     'time': 0.560438871383667,\n",
              "     'components': {'embeddings': np.float64(0.12863008975982665),\n",
              "      'attention': np.float64(13.88234603571845),\n",
              "      'ffn': np.float64(13.568228692057195),\n",
              "      'layernorm': np.float64(0.12659936523437498),\n",
              "      'output_layer': np.float64(4.694000000003143)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to remove lowercase substrings from a given string.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef remove_lowercase(str1):\\r\\n remove_lower = lambda text: re.sub('[a-z]', '', text)\\r\\n result =  remove_lower(str1)\\r\\n return result\",\n",
              "    'generated_code': ')\\n\\n the function that compute the lettersings from a given string. The',\n",
              "    'test_cases': ['assert remove_lowercase(\"PYTHon\")==(\\'PYTH\\')',\n",
              "     'assert remove_lowercase(\"FInD\")==(\\'FID\\')',\n",
              "     'assert remove_lowercase(\"STRinG\")==(\\'STRG\\')'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.519544673920958,\n",
              "     'tokenization_energy': 0.22754467391967773,\n",
              "     'inference_energy': 24.29200000000128,\n",
              "     'energy_per_token': 1.7513960481372113,\n",
              "     'time': 0.5553278923034668,\n",
              "     'components': {'embeddings': np.float64(0.1273405294418335),\n",
              "      'attention': np.float64(4.8516886174678815),\n",
              "      'ffn': np.float64(4.526597910165785),\n",
              "      'layernorm': np.float64(0.1262881534099579),\n",
              "      'output_layer': np.float64(0.21315701341629026)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a python function to find the first digit of a given number.',\n",
              "    'ground_truth_code': 'def first_Digit(n) :  \\r\\n    while n >= 10:  \\r\\n        n = n / 10; \\r\\n    return int(n) ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence of a number number.\\n The',\n",
              "    'test_cases': ['assert first_Digit(123) == 1',\n",
              "     'assert first_Digit(456) == 4',\n",
              "     'assert first_Digit(12) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.006706629028777,\n",
              "     'tokenization_energy': 0.12270662903785705,\n",
              "     'inference_energy': 28.88399999999092,\n",
              "     'energy_per_token': 1.9337804419352518,\n",
              "     'time': 0.5598032474517822,\n",
              "     'components': {'embeddings': np.float64(0.12169299006462096),\n",
              "      'attention': np.float64(13.897182554253844),\n",
              "      'ffn': np.float64(18.310786064377986),\n",
              "      'layernorm': np.float64(0.12801723337173462),\n",
              "      'output_layer': np.float64(0.21630733633041382)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a python function to find the maximum occurring character in a given string.',\n",
              "    'ground_truth_code': \"def get_max_occuring_char(str1):\\r\\n  ASCII_SIZE = 256\\r\\n  ctr = [0] * ASCII_SIZE\\r\\n  max = -1\\r\\n  ch = ''\\r\\n  for i in str1:\\r\\n    ctr[ord(i)]+=1;\\r\\n  for i in str1:\\r\\n    if max < ctr[ord(i)]:\\r\\n      max = ctr[ord(i)]\\r\\n      ch = i\\r\\n  return ch\",\n",
              "    'generated_code': ')\\n\\n the function function that compute the number number number in a string string, If',\n",
              "    'test_cases': ['assert get_max_occuring_char(\"data\") == \"a\"',\n",
              "     'assert get_max_occuring_char(\"create\") == \"e\"',\n",
              "     'assert get_max_occuring_char(\"brilliant girl\") == \"i\"'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.122413124565153,\n",
              "     'tokenization_energy': 0.12141312456130982,\n",
              "     'inference_energy': 24.00100000000384,\n",
              "     'energy_per_token': 1.507650820285322,\n",
              "     'time': 0.5566356182098389,\n",
              "     'components': {'embeddings': np.float64(0.1216522388458252),\n",
              "      'attention': np.float64(13.863179193483083),\n",
              "      'ffn': np.float64(18.401467534082713),\n",
              "      'layernorm': np.float64(0.1369331591129303),\n",
              "      'output_layer': np.float64(0.22916384506225584)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to determine if there is a subset of the given set with sum equal to the given sum.',\n",
              "    'ground_truth_code': 'def is_subset_sum(set, n, sum):\\r\\n\\tif (sum == 0):\\r\\n\\t\\treturn True\\r\\n\\tif (n == 0):\\r\\n\\t\\treturn False\\r\\n\\tif (set[n - 1] > sum):\\r\\n\\t\\treturn is_subset_sum(set, n - 1, sum)\\r\\n\\treturn is_subset_sum(set, n-1, sum) or is_subset_sum(set, n-1, sum-set[n-1])',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a is a solution of a given array of sum equal to zero target target. You',\n",
              "    'test_cases': ['assert is_subset_sum([3, 34, 4, 12, 5, 2], 6, 9) == True',\n",
              "     'assert is_subset_sum([3, 34, 4, 12, 5, 2], 6, 30) == False',\n",
              "     'assert is_subset_sum([3, 34, 4, 12, 5, 2], 6, 15) == True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.091184658772196,\n",
              "     'tokenization_energy': 0.13118465876579283,\n",
              "     'inference_energy': 28.960000000006403,\n",
              "     'energy_per_token': 1.2648341155987912,\n",
              "     'time': 0.5592911243438721,\n",
              "     'components': {'embeddings': np.float64(0.19700739765167238),\n",
              "      'attention': np.float64(9.258626650809308),\n",
              "      'ffn': np.float64(9.05888960600714),\n",
              "      'layernorm': np.float64(0.13129900884628296),\n",
              "      'output_layer': np.float64(0.24003118419647218)},\n",
              "     'num_tokens': 23}},\n",
              "   {'prompt': 'Write a function to find sequences of one upper case letter followed by lower case letters in the given string by using regex.',\n",
              "    'ground_truth_code': \"import re \\r\\ndef match(text): \\r\\n\\t\\tpattern = '[A-Z]+[a-z]+$'\\r\\n\\t\\tif re.search(pattern, text): \\r\\n\\t\\t\\t\\treturn('Yes') \\r\\n\\t\\telse: \\r\\n\\t\\t\\t\\treturn('No') \",\n",
              "    'generated_code': ')\\n\\n the function that compute the of consecutive or and letter followed by one case letters. a upper string. using only. The',\n",
              "    'test_cases': ['assert match(\"Geeks\") == \\'Yes\\'',\n",
              "     'assert match(\"geeksforGeeks\") == \\'Yes\\'',\n",
              "     'assert match(\"geeks\") == \\'No\\''],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.135419770712964,\n",
              "     'tokenization_energy': 0.14041977071762085,\n",
              "     'inference_energy': 28.994999999995343,\n",
              "     'energy_per_token': 1.1654167908285187,\n",
              "     'time': 0.5598347187042236,\n",
              "     'components': {'embeddings': np.float64(0.14342868185043336),\n",
              "      'attention': np.float64(14.000113357774682),\n",
              "      'ffn': np.float64(18.59614260197396),\n",
              "      'layernorm': np.float64(0.1349351477622986),\n",
              "      'output_layer': np.float64(0.24637766003608705)},\n",
              "     'num_tokens': 25}},\n",
              "   {'prompt': 'Write a python function to find the first natural number whose factorial is divisible by x.',\n",
              "    'ground_truth_code': 'def first_Factorial_Divisible_Number(x): \\r\\n    i = 1;\\r\\n    fact = 1; \\r\\n    for i in range(1,x): \\r\\n        fact = fact * i \\r\\n        if (fact % x == 0): \\r\\n            break\\r\\n    return i ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number occurrence number n first is equal by the, The',\n",
              "    'test_cases': ['assert first_Factorial_Divisible_Number(10) == 5',\n",
              "     'assert first_Factorial_Divisible_Number(15) == 5',\n",
              "     'assert first_Factorial_Divisible_Number(5) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.118234074585487,\n",
              "     'tokenization_energy': 0.13523407459259032,\n",
              "     'inference_energy': 23.9829999999929,\n",
              "     'energy_per_token': 1.339901893032527,\n",
              "     'time': 0.5654702186584473,\n",
              "     'components': {'embeddings': np.float64(0.13681620025634764),\n",
              "      'attention': np.float64(14.117980455377605),\n",
              "      'ffn': np.float64(9.26565584589122),\n",
              "      'layernorm': np.float64(0.12713079309463501),\n",
              "      'output_layer': np.float64(0.2942095310688019)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to remove the matching tuples from the given two tuples.',\n",
              "    'ground_truth_code': 'def remove_matching_tuple(test_list1, test_list2):\\r\\n  res = [sub for sub in test_list1 if sub not in test_list2]\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the top parentheses from the tuples\\n-dimensional, The',\n",
              "    'test_cases': [\"assert remove_matching_tuple([('Hello', 'dude'), ('How', 'are'), ('you', '?')], [('Hello', 'dude'), ('How', 'are')]) == [('you', '?')]\",\n",
              "     \"assert remove_matching_tuple([('Part', 'of'), ('the', 'journey'), ('is ', 'end')], [('Journey', 'the'), ('is', 'end')]) == [('Part', 'of'), ('the', 'journey'), ('is ', 'end')]\",\n",
              "     \"assert remove_matching_tuple([('Its', 'been'), ('a', 'long'), ('day', 'without')], [('a', 'long'), ('my', 'friend')]) == [('Its', 'been'), ('day', 'without')]\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.268845406066625,\n",
              "     'tokenization_energy': 0.23184540605545045,\n",
              "     'inference_energy': 29.037000000011176,\n",
              "     'energy_per_token': 1.9512563604044417,\n",
              "     'time': 0.5601818561553955,\n",
              "     'components': {'embeddings': np.float64(0.12222371220588685),\n",
              "      'attention': np.float64(18.562985630988027),\n",
              "      'ffn': np.float64(13.900961278201548),\n",
              "      'layernorm': np.float64(0.12878271484375),\n",
              "      'output_layer': np.float64(0.2818836855888367)},\n",
              "     'num_tokens': 15}},\n",
              "   {'prompt': 'Write a function to find the largest palindromic number in the given array.',\n",
              "    'ground_truth_code': 'def is_palindrome(n) : \\r\\n\\tdivisor = 1\\r\\n\\twhile (n / divisor >= 10) : \\r\\n\\t\\tdivisor *= 10\\r\\n\\twhile (n != 0) : \\r\\n\\t\\tleading = n // divisor \\r\\n\\t\\ttrailing = n % 10\\r\\n\\t\\tif (leading != trailing) : \\r\\n\\t\\t\\treturn False\\r\\n\\t\\tn = (n % divisor) // 10\\r\\n\\t\\tdivisor = divisor // 100\\r\\n\\treturn True\\r\\ndef largest_palindrome(A, n) : \\r\\n\\tA.sort() \\r\\n\\tfor i in range(n - 1, -1, -1) : \\r\\n\\t\\tif (is_palindrome(A[i])) : \\r\\n\\t\\t\\treturn A[i] \\r\\n\\treturn -1',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum primeindromic number in a range range.\\n If',\n",
              "    'test_cases': ['assert largest_palindrome([1, 232, 54545, 999991], 4) == 54545',\n",
              "     'assert largest_palindrome([1, 2, 3, 4, 5, 50], 6) == 5',\n",
              "     'assert largest_palindrome([1, 3, 7, 9, 45], 5)  == 9'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.154226457117126,\n",
              "     'tokenization_energy': 0.18122645711898805,\n",
              "     'inference_energy': 23.972999999998137,\n",
              "     'energy_per_token': 1.3419014698398404,\n",
              "     'time': 0.5582592487335205,\n",
              "     'components': {'embeddings': np.float64(0.1234663119316101),\n",
              "      'attention': np.float64(14.0575279128619),\n",
              "      'ffn': np.float64(13.719531530378152),\n",
              "      'layernorm': np.float64(0.12869596099853514),\n",
              "      'output_layer': np.float64(0.3114375305175781)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to compute binomial probability for the given number.',\n",
              "    'ground_truth_code': 'def nCr(n, r): \\r\\n\\tif (r > n / 2): \\r\\n\\t\\tr = n - r \\r\\n\\tanswer = 1 \\r\\n\\tfor i in range(1, r + 1): \\r\\n\\t\\tanswer *= (n - r + i) \\r\\n\\t\\tanswer /= i \\r\\n\\treturn answer \\r\\ndef binomial_probability(n, k, p): \\r\\n\\treturn (nCr(n, k) * pow(p, k) *\\tpow(1 - p, n - k)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute theomial coefficients for a bin parameters of The',\n",
              "    'test_cases': ['assert binomial_probability(10, 5, 1.0/3) == 0.13656454808718185',\n",
              "     'assert binomial_probability(11, 6, 2.0/4) == 0.2255859375',\n",
              "     'assert binomial_probability(12, 7, 3.0/5) == 0.227030335488'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.91799999999057,\n",
              "     'tokenization_energy': 4.976999999998952,\n",
              "     'inference_energy': 23.940999999991618,\n",
              "     'energy_per_token': 2.065571428570755,\n",
              "     'time': 0.556107759475708,\n",
              "     'components': {'embeddings': np.float64(0.1307730131149292),\n",
              "      'attention': np.float64(9.478380252847098),\n",
              "      'ffn': np.float64(13.570163296928161),\n",
              "      'layernorm': np.float64(0.12759534072875978),\n",
              "      'output_layer': np.float64(0.21610084533691407)},\n",
              "     'num_tokens': 14}},\n",
              "   {'prompt': 'Write a function to sort a list of tuples in increasing order by the last element in each tuple.',\n",
              "    'ground_truth_code': 'def sort_tuple(tup): \\r\\n\\tlst = len(tup) \\r\\n\\tfor i in range(0, lst): \\r\\n\\t\\tfor j in range(0, lst-i-1): \\r\\n\\t\\t\\tif (tup[j][-1] > tup[j + 1][-1]): \\r\\n\\t\\t\\t\\ttemp = tup[j] \\r\\n\\t\\t\\t\\ttup[j]= tup[j + 1] \\r\\n\\t\\t\\t\\ttup[j + 1]= temp \\r\\n\\treturn tup',\n",
              "    'generated_code': ')\\n\\n the function that compute a matrix of integers in Python order, using number element of each tuple.\\n If',\n",
              "    'test_cases': ['assert sort_tuple([(1, 3), (3, 2), (2, 1)] ) == [(2, 1), (3, 2), (1, 3)]',\n",
              "     'assert sort_tuple([(2, 4), (3, 3), (1, 1)] ) == [(1, 1), (3, 3), (2, 4)]',\n",
              "     'assert sort_tuple([(3, 9), (6, 7), (4, 3)] ) == [(4, 3), (6, 7), (3, 9)]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.979070491789724,\n",
              "     'tokenization_energy': 0.12707049179077148,\n",
              "     'inference_energy': 28.851999999998952,\n",
              "     'energy_per_token': 1.3799557377042726,\n",
              "     'time': 0.5586748123168945,\n",
              "     'components': {'embeddings': np.float64(0.12263209533691406),\n",
              "      'attention': np.float64(4.5488704190254206),\n",
              "      'ffn': np.float64(4.531072621822357),\n",
              "      'layernorm': np.float64(0.12793410873413086),\n",
              "      'output_layer': np.float64(4.882999999987078)},\n",
              "     'num_tokens': 21}},\n",
              "   {'prompt': 'Write a function to find the area of a pentagon.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef area_pentagon(a):\\r\\n  area=(math.sqrt(5*(5+2*math.sqrt(5)))*pow(a,2))/4.0\\r\\n  return area',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a triangleagon given The',\n",
              "    'test_cases': ['assert area_pentagon(5)==43.01193501472417',\n",
              "     'assert area_pentagon(10)==172.0477400588967',\n",
              "     'assert area_pentagon(15)==387.10741513251753'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.186206046587206,\n",
              "     'tokenization_energy': 0.1392060465812683,\n",
              "     'inference_energy': 24.047000000005937,\n",
              "     'energy_per_token': 1.8604773881990158,\n",
              "     'time': 0.5643613338470459,\n",
              "     'components': {'embeddings': np.float64(0.13894744348526),\n",
              "      'attention': np.float64(13.941690274466875),\n",
              "      'ffn': np.float64(13.683327483426545),\n",
              "      'layernorm': np.float64(0.13073869705200195),\n",
              "      'output_layer': np.float64(0.28069961547851563)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to find the frequency of the largest value in a given array.',\n",
              "    'ground_truth_code': 'def frequency_Of_Largest(n,arr): \\r\\n    mn = arr[0] \\r\\n    freq = 1\\r\\n    for i in range(1,n): \\r\\n        if (arr[i] >mn): \\r\\n            mn = arr[i] \\r\\n            freq = 1\\r\\n        elif (arr[i] == mn): \\r\\n            freq += 1\\r\\n    return freq ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of each most number in a matrix matrix.\\n The',\n",
              "    'test_cases': ['assert frequency_Of_Largest(5,[1,2,3,4,4]) == 2',\n",
              "     'assert frequency_Of_Largest(3,[5,6,5]) == 1',\n",
              "     'assert frequency_Of_Largest(4,[2,7,7,7]) == 3'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.00878428459633,\n",
              "     'tokenization_energy': 0.1287842845916748,\n",
              "     'inference_energy': 28.880000000004657,\n",
              "     'energy_per_token': 1.6115991269220185,\n",
              "     'time': 0.5554959774017334,\n",
              "     'components': {'embeddings': np.float64(0.12420866012573242),\n",
              "      'attention': np.float64(18.442925821550304),\n",
              "      'ffn': np.float64(18.225538813588095),\n",
              "      'layernorm': np.float64(0.12884074997901915),\n",
              "      'output_layer': np.float64(0.23464775228500365)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to extract all the pairs which are symmetric in the given tuple list.',\n",
              "    'ground_truth_code': 'def extract_symmetric(test_list):\\r\\n  temp = set(test_list) & {(b, a) for a, b in test_list}\\r\\n  res = {(a, b) for a, b in temp if a < b}\\r\\n  return (res) ',\n",
              "    'generated_code': ')\\n\\n the function that compute the the digits of are in in a symmetric matrix.\\n.\\n The',\n",
              "    'test_cases': ['assert extract_symmetric([(6, 7), (2, 3), (7, 6), (9, 8), (10, 2), (8, 9)] ) == {(8, 9), (6, 7)}',\n",
              "     'assert extract_symmetric([(7, 8), (3, 4), (8, 7), (10, 9), (11, 3), (9, 10)] ) == {(9, 10), (7, 8)}',\n",
              "     'assert extract_symmetric([(8, 9), (4, 5), (9, 8), (11, 10), (12, 4), (10, 11)] ) == {(8, 9), (10, 11)}'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.105010445587688,\n",
              "     'tokenization_energy': 0.12201044559478759,\n",
              "     'inference_energy': 23.9829999999929,\n",
              "     'energy_per_token': 1.3391672469770937,\n",
              "     'time': 0.5591516494750977,\n",
              "     'components': {'embeddings': np.float64(0.1217709858417511),\n",
              "      'attention': np.float64(4.676217130422592),\n",
              "      'ffn': np.float64(9.045524149411593),\n",
              "      'layernorm': np.float64(0.1268114676475525),\n",
              "      'output_layer': np.float64(0.2917695665359497)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the sum of geometric progression series.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef sum_gp(a,n,r):\\r\\n total = (a * (1 - math.pow(r, n ))) / (1- r)\\r\\n return total',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of all series terms in The',\n",
              "    'test_cases': ['assert sum_gp(1,5,2)==31',\n",
              "     'assert sum_gp(1,5,4)==341',\n",
              "     'assert sum_gp(2,6,3)==728'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.934230243211378,\n",
              "     'tokenization_energy': 0.12223024320602416,\n",
              "     'inference_energy': 28.812000000005355,\n",
              "     'energy_per_token': 2.2257100187085674,\n",
              "     'time': 0.5546219348907471,\n",
              "     'components': {'embeddings': np.float64(0.14910035133361815),\n",
              "      'attention': np.float64(4.736392431497574),\n",
              "      'ffn': np.float64(4.581465658426285),\n",
              "      'layernorm': np.float64(0.19181042432785034),\n",
              "      'output_layer': np.float64(0.21473922586441038)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to search an element in the given array by using binary search.',\n",
              "    'ground_truth_code': 'def binary_search(item_list,item):\\r\\n\\tfirst = 0\\r\\n\\tlast = len(item_list)-1\\r\\n\\tfound = False\\r\\n\\twhile( first<=last and not found):\\r\\n\\t\\tmid = (first + last)//2\\r\\n\\t\\tif item_list[mid] == item :\\r\\n\\t\\t\\tfound = True\\r\\n\\t\\telse:\\r\\n\\t\\t\\tif item < item_list[mid]:\\r\\n\\t\\t\\t\\tlast = mid - 1\\r\\n\\t\\t\\telse:\\r\\n\\t\\t\\t\\tfirst = mid + 1\\t\\r\\n\\treturn found',\n",
              "    'generated_code': ')\\n\\n the function that compute for array in a matrix matrix, using the search. The',\n",
              "    'test_cases': ['assert binary_search([1,2,3,5,8], 6) == False',\n",
              "     'assert binary_search([7, 8, 9, 10, 13], 10) == True',\n",
              "     'assert binary_search([11, 13, 14, 19, 22, 36], 23) == False'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.860318850987824,\n",
              "     'tokenization_energy': 0.12331885099411011,\n",
              "     'inference_energy': 28.736999999993714,\n",
              "     'energy_per_token': 1.6976658147639896,\n",
              "     'time': 0.5610682964324951,\n",
              "     'components': {'embeddings': np.float64(0.13471521377563475),\n",
              "      'attention': np.float64(13.92755059290165),\n",
              "      'ffn': np.float64(18.153792007923013),\n",
              "      'layernorm': np.float64(0.1895448124408722),\n",
              "      'output_layer': np.float64(0.23877389001846314)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to calculate a grid of hexagon coordinates where function returns a list of lists containing 6 tuples of x, y point coordinates.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef calculate_polygons(startx, starty, endx, endy, radius):\\r\\n    sl = (2 * radius) * math.tan(math.pi / 6)\\r\\n    p = sl * 0.5\\r\\n    b = sl * math.cos(math.radians(30))\\r\\n    w = b * 2\\r\\n    h = 2 * sl   \\r\\n    startx = startx - w\\r\\n    starty = starty - h\\r\\n    endx = endx + w\\r\\n    endy = endy + h\\r\\n    origx = startx\\r\\n    origy = starty\\r\\n    xoffset = b\\r\\n    yoffset = 3 * p\\r\\n    polygons = []\\r\\n    row = 1\\r\\n    counter = 0\\r\\n    while starty < endy:\\r\\n        if row % 2 == 0:\\r\\n            startx = origx + xoffset\\r\\n        else:\\r\\n            startx = origx\\r\\n        while startx < endx:\\r\\n            p1x = startx\\r\\n            p1y = starty + p\\r\\n            p2x = startx\\r\\n            p2y = starty + (3 * p)\\r\\n            p3x = startx + b\\r\\n            p3y = starty + h\\r\\n            p4x = startx + w\\r\\n            p4y = starty + (3 * p)\\r\\n            p5x = startx + w\\r\\n            p5y = starty + p\\r\\n            p6x = startx + b\\r\\n            p6y = starty\\r\\n            poly = [\\r\\n                (p1x, p1y),\\r\\n                (p2x, p2y),\\r\\n                (p3x, p3y),\\r\\n                (p4x, p4y),\\r\\n                (p5x, p5y),\\r\\n                (p6x, p6y),\\r\\n                (p1x, p1y)]\\r\\n            polygons.append(poly)\\r\\n            counter += 1\\r\\n            startx += w\\r\\n        starty += yoffset\\r\\n        row += 1\\r\\n    return polygons',\n",
              "    'generated_code': ')\\n\\n the function that compute the  of numbersag shapes, each returns a grid of lists of the6 coordinates, coordinates, y coordinates coordinates. The',\n",
              "    'test_cases': ['assert calculate_polygons(1,1, 4, 4, 3)==[[(-5.0, -4.196152422706632), (-5.0, -0.7320508075688767), (-2.0, 1.0), (1.0, -0.7320508075688767), (1.0, -4.196152422706632), (-2.0, -5.928203230275509), (-5.0, -4.196152422706632)], [(1.0, -4.196152422706632), (1.0, -0.7320508075688767), (4.0, 1.0), (7.0, -0.7320508075688767), (7.0, -4.196152422706632), (4.0, -5.928203230275509), (1.0, -4.196152422706632)], [(7.0, -4.196152422706632), (7.0, -0.7320508075688767), (10.0, 1.0), (13.0, -0.7320508075688767), (13.0, -4.196152422706632), (10.0, -5.928203230275509), (7.0, -4.196152422706632)], [(-2.0, 1.0000000000000004), (-2.0, 4.464101615137755), (1.0, 6.196152422706632), (4.0, 4.464101615137755), (4.0, 1.0000000000000004), (1.0, -0.7320508075688767), (-2.0, 1.0000000000000004)], [(4.0, 1.0000000000000004), (4.0, 4.464101615137755), (7.0, 6.196152422706632), (10.0, 4.464101615137755), (10.0, 1.0000000000000004), (7.0, -0.7320508075688767), (4.0, 1.0000000000000004)], [(-5.0, 6.196152422706632), (-5.0, 9.660254037844387), (-2.0, 11.392304845413264), (1.0, 9.660254037844387), (1.0, 6.196152422706632), (-2.0, 4.464101615137755), (-5.0, 6.196152422706632)], [(1.0, 6.196152422706632), (1.0, 9.660254037844387), (4.0, 11.392304845413264), (7.0, 9.660254037844387), (7.0, 6.196152422706632), (4.0, 4.464101615137755), (1.0, 6.196152422706632)], [(7.0, 6.196152422706632), (7.0, 9.660254037844387), (10.0, 11.392304845413264), (13.0, 9.660254037844387), (13.0, 6.196152422706632), (10.0, 4.464101615137755), (7.0, 6.196152422706632)], [(-2.0, 11.392304845413264), (-2.0, 14.85640646055102), (1.0, 16.588457268119896), (4.0, 14.85640646055102), (4.0, 11.392304845413264), (1.0, 9.660254037844387), (-2.0, 11.392304845413264)], [(4.0, 11.392304845413264), (4.0, 14.85640646055102), (7.0, 16.588457268119896), (10.0, 14.85640646055102), (10.0, 11.392304845413264), (7.0, 9.660254037844387), (4.0, 11.392304845413264)]]',\n",
              "     'assert calculate_polygons(5,4,7,9,8)==[[(-11.0, -9.856406460551018), (-11.0, -0.6188021535170058), (-3.0, 4.0), (5.0, -0.6188021535170058), (5.0, -9.856406460551018), (-3.0, -14.475208614068023), (-11.0, -9.856406460551018)], [(5.0, -9.856406460551018), (5.0, -0.6188021535170058), (13.0, 4.0), (21.0, -0.6188021535170058), (21.0, -9.856406460551018), (13.0, -14.475208614068023), (5.0, -9.856406460551018)], [(21.0, -9.856406460551018), (21.0, -0.6188021535170058), (29.0, 4.0), (37.0, -0.6188021535170058), (37.0, -9.856406460551018), (29.0, -14.475208614068023), (21.0, -9.856406460551018)], [(-3.0, 4.0), (-3.0, 13.237604307034012), (5.0, 17.856406460551018), (13.0, 13.237604307034012), (13.0, 4.0), (5.0, -0.6188021535170058), (-3.0, 4.0)], [(13.0, 4.0), (13.0, 13.237604307034012), (21.0, 17.856406460551018), (29.0, 13.237604307034012), (29.0, 4.0), (21.0, -0.6188021535170058), (13.0, 4.0)], [(-11.0, 17.856406460551018), (-11.0, 27.09401076758503), (-3.0, 31.712812921102035), (5.0, 27.09401076758503), (5.0, 17.856406460551018), (-3.0, 13.237604307034012), (-11.0, 17.856406460551018)], [(5.0, 17.856406460551018), (5.0, 27.09401076758503), (13.0, 31.712812921102035), (21.0, 27.09401076758503), (21.0, 17.856406460551018), (13.0, 13.237604307034012), (5.0, 17.856406460551018)], [(21.0, 17.856406460551018), (21.0, 27.09401076758503), (29.0, 31.712812921102035), (37.0, 27.09401076758503), (37.0, 17.856406460551018), (29.0, 13.237604307034012), (21.0, 17.856406460551018)], [(-3.0, 31.712812921102035), (-3.0, 40.95041722813605), (5.0, 45.569219381653056), (13.0, 40.95041722813605), (13.0, 31.712812921102035), (5.0, 27.09401076758503), (-3.0, 31.712812921102035)], [(13.0, 31.712812921102035), (13.0, 40.95041722813605), (21.0, 45.569219381653056), (29.0, 40.95041722813605), (29.0, 31.712812921102035), (21.0, 27.09401076758503), (13.0, 31.712812921102035)]]',\n",
              "     'assert calculate_polygons(9,6,4,3,2)==[[(5.0, 2.5358983848622456), (5.0, 4.8452994616207485), (7.0, 6.0), (9.0, 4.8452994616207485), (9.0, 2.5358983848622456), (7.0, 1.3811978464829942), (5.0, 2.5358983848622456)], [(7.0, 6.0), (7.0, 8.309401076758503), (9.0, 9.464101615137753), (11.0, 8.309401076758503), (11.0, 6.0), (9.0, 4.8452994616207485), (7.0, 6.0)]]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.01773440552305,\n",
              "     'tokenization_energy': 0.13373440551757812,\n",
              "     'inference_energy': 23.88400000000547,\n",
              "     'energy_per_token': 0.8005911468507684,\n",
              "     'time': 0.5644485950469971,\n",
              "     'components': {'embeddings': np.float64(0.20758457565307617),\n",
              "      'attention': np.float64(14.287764313936233),\n",
              "      'ffn': np.float64(4.6394096529483795),\n",
              "      'layernorm': np.float64(0.12949378323554991),\n",
              "      'output_layer': np.float64(0.2353668465614319)},\n",
              "     'num_tokens': 30}},\n",
              "   {'prompt': 'Write a function to convert the given binary tuple to integer.',\n",
              "    'ground_truth_code': 'def binary_to_integer(test_tup):\\r\\n  res = int(\"\".join(str(ele) for ele in test_tup), 2)\\r\\n  return (str(res)) ',\n",
              "    'generated_code': ')\\n\\n the function that compute a digits matrix string to a.\\n The',\n",
              "    'test_cases': [\"assert binary_to_integer((1, 1, 0, 1, 0, 0, 1)) == '105'\",\n",
              "     \"assert binary_to_integer((0, 1, 1, 0, 0, 1, 0, 1)) == '101'\",\n",
              "     \"assert binary_to_integer((1, 1, 0, 1, 0, 1)) == '53'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.88308980536356,\n",
              "     'tokenization_energy': 0.15608980536460876,\n",
              "     'inference_energy': 28.726999999998952,\n",
              "     'energy_per_token': 2.22177613887412,\n",
              "     'time': 0.5563926696777344,\n",
              "     'components': {'embeddings': np.float64(0.12250977230072022),\n",
              "      'attention': np.float64(4.616325594186783),\n",
              "      'ffn': np.float64(4.29731667470932),\n",
              "      'layernorm': np.float64(0.1524834506511688),\n",
              "      'output_layer': np.float64(0.2122877140045166)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to remove lowercase substrings from a given string by using regex.',\n",
              "    'ground_truth_code': \"import re\\r\\ndef remove_lowercase(str1):\\r\\n  remove_lower = lambda text: re.sub('[a-z]', '', text)\\r\\n  result =  remove_lower(str1)\\r\\n  return (result)\",\n",
              "    'generated_code': ')\\n\\n the function that compute the lettersings from a given string. using a.\\n The',\n",
              "    'test_cases': [\"assert remove_lowercase('KDeoALOklOOHserfLoAJSIskdsf') == 'KDALOOOHLAJSI'\",\n",
              "     \"assert remove_lowercase('ProducTnamEstreAmIngMediAplAYer') == 'PTEAIMAAY'\",\n",
              "     \"assert remove_lowercase('maNufacTuredbYSheZenTechNolOGIes') == 'NTYSZTNOGI'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.12138433456421,\n",
              "     'tokenization_energy': 0.12138433456420898,\n",
              "     'inference_energy': 24.0,\n",
              "     'energy_per_token': 1.4189049608567181,\n",
              "     'time': 0.5614972114562988,\n",
              "     'components': {'embeddings': np.float64(0.1232388174533844),\n",
              "      'attention': np.float64(9.384807314648059),\n",
              "      'ffn': np.float64(13.746933464516538),\n",
              "      'layernorm': np.float64(0.12731552124023438),\n",
              "      'output_layer': np.float64(0.23267045617103577)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a function to find the smallest integers from a given list of numbers using heap queue algorithm.',\n",
              "    'ground_truth_code': 'import heapq as hq\\r\\ndef heap_queue_smallest(nums,n):\\r\\n  smallest_nums = hq.nsmallest(n, nums)\\r\\n  return smallest_nums',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum number a a given set of integers, the sorting.\\n The',\n",
              "    'test_cases': ['assert heap_queue_smallest( [25, 35, 22, 85, 14, 65, 75, 25, 58],3)==[14, 22, 25] ',\n",
              "     'assert heap_queue_smallest( [25, 35, 22, 85, 14, 65, 75, 25, 58],2)==[14, 22]',\n",
              "     'assert heap_queue_smallest( [25, 35, 22, 85, 14, 65, 75, 22, 58],5)==[14, 22, 22, 25, 35]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.852341777805123,\n",
              "     'tokenization_energy': 0.12034177780151367,\n",
              "     'inference_energy': 28.73200000000361,\n",
              "     'energy_per_token': 1.442617088890256,\n",
              "     'time': 0.5549521446228027,\n",
              "     'components': {'embeddings': np.float64(0.14729372024536133),\n",
              "      'attention': np.float64(4.619933105230331),\n",
              "      'ffn': np.float64(4.480526636123657),\n",
              "      'layernorm': np.float64(0.18858456659317016),\n",
              "      'output_layer': np.float64(0.2350409288406372)},\n",
              "     'num_tokens': 20}},\n",
              "   {'prompt': 'Write a function to find the surface area of a cone.',\n",
              "    'ground_truth_code': 'import math\\r\\ndef surfacearea_cone(r,h):\\r\\n  l = math.sqrt(r * r + h * h)\\r\\n  SA = math.pi * r * (r + l)\\r\\n  return SA',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum area of a cube given The',\n",
              "    'test_cases': ['assert surfacearea_cone(5,12)==282.7433388230814',\n",
              "     'assert surfacearea_cone(10,15)==880.5179353159282',\n",
              "     'assert surfacearea_cone(19,17)==2655.923961165254'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 29.007042042253772,\n",
              "     'tokenization_energy': 0.14004204225540162,\n",
              "     'inference_energy': 28.86699999999837,\n",
              "     'energy_per_token': 2.2313109263272133,\n",
              "     'time': 0.5599193572998047,\n",
              "     'components': {'embeddings': np.float64(0.22234450149536134),\n",
              "      'attention': np.float64(9.292888587463764),\n",
              "      'ffn': np.float64(13.568936297905633),\n",
              "      'layernorm': np.float64(0.20118858003616333),\n",
              "      'output_layer': np.float64(0.2265436563491821)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to find gcd of two positive integers.',\n",
              "    'ground_truth_code': 'def gcd(x, y):\\r\\n    gcd = 1\\r\\n    if x % y == 0:\\r\\n        return y\\r\\n    for k in range(int(y / 2), 0, -1):\\r\\n        if x % k == 0 and y % k == 0:\\r\\n            gcd = k\\r\\n            break  \\r\\n    return gcd',\n",
              "    'generated_code': ')\\n\\n the function function that compute the of two numbers integers using Write',\n",
              "    'test_cases': ['assert gcd(12, 17) == 1',\n",
              "     'assert gcd(4,6) == 2',\n",
              "     'assert gcd(2,9) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.985619900699355,\n",
              "     'tokenization_energy': 0.13061990070343016,\n",
              "     'inference_energy': 23.854999999995925,\n",
              "     'energy_per_token': 1.8450476846691812,\n",
              "     'time': 0.5580253601074219,\n",
              "     'components': {'embeddings': np.float64(0.23215120887756346),\n",
              "      'attention': np.float64(4.6979193201065055),\n",
              "      'ffn': np.float64(4.502462321043015),\n",
              "      'layernorm': np.float64(0.187296302318573),\n",
              "      'output_layer': np.float64(0.21144984722137453)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to find the diameter of a circle.',\n",
              "    'ground_truth_code': 'def diameter_circle(r):\\r\\n  diameter=2*r\\r\\n  return diameter',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of a circle given The',\n",
              "    'test_cases': ['assert diameter_circle(10)==20',\n",
              "     'assert diameter_circle(40)==80',\n",
              "     'assert diameter_circle(15)==30'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.906420755155267,\n",
              "     'tokenization_energy': 0.12042075514793396,\n",
              "     'inference_energy': 28.786000000007334,\n",
              "     'energy_per_token': 2.408868396262939,\n",
              "     'time': 0.558952808380127,\n",
              "     'components': {'embeddings': np.float64(0.12149524092674255),\n",
              "      'attention': np.float64(14.020845853335226),\n",
              "      'ffn': np.float64(18.30363290142664),\n",
              "      'layernorm': np.float64(4.789000000004307),\n",
              "      'output_layer': np.float64(0.21432610368728638)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to concatenate all elements of the given list into a string.',\n",
              "    'ground_truth_code': \"def concatenate_elements(list):\\r\\n  ans = ' '\\r\\n  for i in list:\\r\\n    ans = ans+ ' '+i\\r\\n  return (ans) \",\n",
              "    'generated_code': ')\\n\\n the function that compute two the of a matrix array into a single, The',\n",
              "    'test_cases': [\"assert concatenate_elements(['hello','there','have','a','rocky','day'] ) == '  hello there have a rocky day'\",\n",
              "     \"assert concatenate_elements([ 'Hi', 'there', 'How','are', 'you'] ) == '  Hi there How are you'\",\n",
              "     \"assert concatenate_elements([ 'Part', 'of', 'the','journey', 'is', 'end'] ) == '  Part of the journey is end'\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.0805062184321,\n",
              "     'tokenization_energy': 0.12250621843338014,\n",
              "     'inference_energy': 23.95799999999872,\n",
              "     'energy_per_token': 1.5050316386520062,\n",
              "     'time': 0.566624641418457,\n",
              "     'components': {'embeddings': np.float64(0.1228819694519043),\n",
              "      'attention': np.float64(18.526246965872474),\n",
              "      'ffn': np.float64(13.591532742988552),\n",
              "      'layernorm': np.float64(0.12966175484657286),\n",
              "      'output_layer': np.float64(0.38408204102516175)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a python function to find common divisor between two numbers in a given pair.',\n",
              "    'ground_truth_code': 'def ngcd(x,y):\\r\\n    i=1\\r\\n    while(i<=x and i<=y):\\r\\n        if(x%i==0 and y%i == 0):\\r\\n            gcd=i;\\r\\n        i+=1\\r\\n    return gcd;\\r\\ndef num_comm_div(x,y):\\r\\n  n = ngcd(x,y)\\r\\n  result = 0\\r\\n  z = int(n**0.5)\\r\\n  i = 1\\r\\n  while(i <= z):\\r\\n    if(n % i == 0):\\r\\n      result += 2 \\r\\n      if(i == n/i):\\r\\n        result-=1\\r\\n    i+=1\\r\\n  return result',\n",
              "    'generated_code': ')\\n\\n the function function that compute the div of two numbers.\\n Python way range of The',\n",
              "    'test_cases': ['assert num_comm_div(2,4) == 2',\n",
              "     'assert num_comm_div(2,8) == 2',\n",
              "     'assert num_comm_div(12,24) == 6'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 23.85284285330365,\n",
              "     'tokenization_energy': 0.122842853307724,\n",
              "     'inference_energy': 23.729999999995925,\n",
              "     'energy_per_token': 1.4031084031355088,\n",
              "     'time': 0.5591659545898438,\n",
              "     'components': {'embeddings': np.float64(0.1227365837097168),\n",
              "      'attention': np.float64(13.857111974005935),\n",
              "      'ffn': np.float64(18.13382139443443),\n",
              "      'layernorm': np.float64(0.13203948307037355),\n",
              "      'output_layer': np.float64(0.23882056760787965)},\n",
              "     'num_tokens': 17}},\n",
              "   {'prompt': 'Write a python function to find remainder of two numbers.',\n",
              "    'ground_truth_code': 'def find(n,m):\\r\\n  r = n%m\\r\\n  return (r)',\n",
              "    'generated_code': ')\\n\\n the function function that compute the when a numbers without Write',\n",
              "    'test_cases': ['assert find(3,3) == 0',\n",
              "     'assert find(10,3) == 1',\n",
              "     'assert find(16,5) == 1'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.89892668485362,\n",
              "     'tokenization_energy': 0.1269266848564148,\n",
              "     'inference_energy': 28.771999999997206,\n",
              "     'energy_per_token': 2.4082438904044685,\n",
              "     'time': 0.561387300491333,\n",
              "     'components': {'embeddings': np.float64(0.12615094995498657),\n",
              "      'attention': np.float64(9.453979533198407),\n",
              "      'ffn': np.float64(4.587599585056306),\n",
              "      'layernorm': np.float64(0.12850684833526613),\n",
              "      'output_layer': np.float64(4.708999999988009)},\n",
              "     'num_tokens': 12}},\n",
              "   {'prompt': 'Write a function to add consecutive numbers of a given list.',\n",
              "    'ground_truth_code': 'def add_consecutive_nums(nums):\\r\\n    result = [b+a for a, b in zip(nums[:-1], nums[1:])]\\r\\n    return result',\n",
              "    'generated_code': ')\\n\\n the function that compute two numbers starting the given length, For',\n",
              "    'test_cases': ['assert add_consecutive_nums([1, 1, 3, 4, 4, 5, 6, 7])==[2, 4, 7, 8, 9, 11, 13]',\n",
              "     'assert add_consecutive_nums([4, 5, 8, 9, 6, 10])==[9, 13, 17, 15, 16]',\n",
              "     'assert add_consecutive_nums([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])==[3, 5, 7, 9, 11, 13, 15, 17, 19]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.009591274261474,\n",
              "     'tokenization_energy': 0.1345912742614746,\n",
              "     'inference_energy': 23.875,\n",
              "     'energy_per_token': 1.8468916364816519,\n",
              "     'time': 0.5557734966278076,\n",
              "     'components': {'embeddings': np.float64(0.1369865427017212),\n",
              "      'attention': np.float64(13.901316959138727),\n",
              "      'ffn': np.float64(18.296709667925025),\n",
              "      'layernorm': np.float64(0.13391290140151976),\n",
              "      'output_layer': np.float64(0.24236590671539307)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a python function to find the cube sum of first n natural numbers.',\n",
              "    'ground_truth_code': 'def sum_Of_Series(n): \\r\\n    sum = 0\\r\\n    for i in range(1,n + 1): \\r\\n        sum += i * i*i       \\r\\n    return sum',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number root of a n integers numbers.\\n\\n The',\n",
              "    'test_cases': ['assert sum_Of_Series(5) == 225',\n",
              "     'assert sum_Of_Series(2) == 9',\n",
              "     'assert sum_Of_Series(3) == 36'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.599767094133423,\n",
              "     'tokenization_energy': 0.12676709413528442,\n",
              "     'inference_energy': 28.472999999998137,\n",
              "     'energy_per_token': 1.787485443383339,\n",
              "     'time': 0.5668931007385254,\n",
              "     'components': {'embeddings': np.float64(0.12602175331115723),\n",
              "      'attention': np.float64(9.40766444945184),\n",
              "      'ffn': np.float64(9.243174228186952),\n",
              "      'layernorm': np.float64(0.12689620471000673),\n",
              "      'output_layer': np.float64(0.30683544564247134)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to move all zeroes to the end of the given array.',\n",
              "    'ground_truth_code': 'def re_order(A):\\r\\n    k = 0\\r\\n    for i in A:\\r\\n        if i:\\r\\n            A[k] = i\\r\\n            k = k + 1\\r\\n    for i in range(k, len(A)):\\r\\n        A[i] = 0\\r\\n    return A',\n",
              "    'generated_code': ')\\n\\n the function that compute the the in the end of an array array.\\n The',\n",
              "    'test_cases': ['assert re_order([6, 0, 8, 2, 3, 0, 4, 0, 1]) == [6, 8, 2, 3, 4, 1, 0, 0, 0]',\n",
              "     'assert re_order([4, 0, 2, 7, 0, 9, 0, 12, 0]) == [4, 2, 7, 9, 12, 0, 0, 0, 0]',\n",
              "     'assert re_order([3, 11, 0, 74, 14, 0, 1, 0, 2]) == [3, 11, 74, 14, 1, 2, 0, 0, 0]'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.10917823577067,\n",
              "     'tokenization_energy': 0.12017823576927186,\n",
              "     'inference_energy': 23.989000000001397,\n",
              "     'energy_per_token': 1.506823639735667,\n",
              "     'time': 0.5603690147399902,\n",
              "     'components': {'embeddings': np.float64(0.12181323814392091),\n",
              "      'attention': np.float64(18.375204968453968),\n",
              "      'ffn': np.float64(13.770973573446156),\n",
              "      'layernorm': np.float64(0.16480224466323853),\n",
              "      'output_layer': np.float64(0.2752016923427582)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to calculate the permutation coefficient of given p(n, k).',\n",
              "    'ground_truth_code': 'def permutation_coefficient(n, k): \\r\\n\\tP = [[0 for i in range(k + 1)] \\r\\n\\t\\t\\tfor j in range(n + 1)] \\r\\n\\tfor i in range(n + 1): \\r\\n\\t\\tfor j in range(min(i, k) + 1): \\r\\n\\t\\t\\tif (j == 0): \\r\\n\\t\\t\\t\\tP[i][j] = 1\\r\\n\\t\\t\\telse: \\r\\n\\t\\t\\t\\tP[i][j] = P[i - 1][j] + ( \\r\\n\\t\\t\\t\\t\\t\\tj * P[i - 1][j - 1]) \\r\\n\\t\\t\\tif (j < k): \\r\\n\\t\\t\\t\\tP[i][j + 1] = 0\\r\\n\\treturn P[n][k] ',\n",
              "    'generated_code': ')\\n\\n the function that compute the probability of C a n and, k) Note',\n",
              "    'test_cases': ['assert permutation_coefficient(10, 2) == 90',\n",
              "     'assert permutation_coefficient(10, 3) == 720',\n",
              "     'assert permutation_coefficient(10, 1) == 10'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.59000000001106,\n",
              "     'tokenization_energy': 4.841000000000349,\n",
              "     'inference_energy': 23.74900000001071,\n",
              "     'energy_per_token': 1.7868750000006912,\n",
              "     'time': 0.56172776222229,\n",
              "     'components': {'embeddings': np.float64(0.12401321887969971),\n",
              "      'attention': np.float64(13.84605721378862),\n",
              "      'ffn': np.float64(13.526528207297554),\n",
              "      'layernorm': np.float64(0.12547473859786987),\n",
              "      'output_layer': np.float64(0.21163391017913818)},\n",
              "     'num_tokens': 16}},\n",
              "   {'prompt': 'Write a function to remove specific words from a given list.',\n",
              "    'ground_truth_code': 'def remove_words(list1, removewords):\\r\\n    for word in list(list1):\\r\\n        if word in removewords:\\r\\n            list1.remove(word)\\r\\n    return list1  ',\n",
              "    'generated_code': ')\\n\\n the function that compute the characters from a string string of The',\n",
              "    'test_cases': [\"assert remove_words(['red', 'green', 'blue', 'white', 'black', 'orange'],['white', 'orange'])==['red', 'green', 'blue', 'black']\",\n",
              "     \"assert remove_words(['red', 'green', 'blue', 'white', 'black', 'orange'],['black', 'orange'])==['red', 'green', 'blue', 'white']\",\n",
              "     \"assert remove_words(['red', 'green', 'blue', 'white', 'black', 'orange'],['blue', 'white'])==['red', 'green', 'black', 'orange']\"],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.654771793357448,\n",
              "     'tokenization_energy': 0.12277179336547851,\n",
              "     'inference_energy': 28.531999999991967,\n",
              "     'energy_per_token': 2.2042132148736497,\n",
              "     'time': 0.560354471206665,\n",
              "     'components': {'embeddings': np.float64(0.1254300618171692),\n",
              "      'attention': np.float64(9.187525087593356),\n",
              "      'ffn': np.float64(13.588125794401392),\n",
              "      'layernorm': np.float64(4.788000000000466),\n",
              "      'output_layer': np.float64(0.2153111479282379)},\n",
              "     'num_tokens': 13}},\n",
              "   {'prompt': 'Write a function to check if the common elements between two given lists are in the same order or not.',\n",
              "    'ground_truth_code': 'def same_order(l1, l2):\\r\\n    common_elements = set(l1) & set(l2)\\r\\n    l1 = [e for e in l1 if e in common_elements]\\r\\n    l2 = [e for e in l2 if e in common_elements]\\r\\n    return l1 == l2',\n",
              "    'generated_code': ')\\n\\n the function that compute whether a number div in two sets integers are the the same order.\\n not.\\n The',\n",
              "    'test_cases': ['assert same_order([\"red\",\"green\",\"black\",\"orange\"],[\"red\",\"pink\",\"green\",\"white\",\"black\"])==True',\n",
              "     'assert same_order([\"red\",\"pink\",\"green\",\"white\",\"black\"],[\"white\",\"orange\",\"pink\",\"black\"])==False',\n",
              "     'assert same_order([\"red\",\"green\",\"black\",\"orange\"],[\"red\",\"pink\",\"green\",\"white\",\"black\"])==True'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 24.106674981117017,\n",
              "     'tokenization_energy': 0.12567498111724854,\n",
              "     'inference_energy': 23.980999999999767,\n",
              "     'energy_per_token': 1.0957579536871371,\n",
              "     'time': 0.5575666427612305,\n",
              "     'components': {'embeddings': np.float64(0.12222699856758118),\n",
              "      'attention': np.float64(18.760778192753556),\n",
              "      'ffn': np.float64(13.71615674925328),\n",
              "      'layernorm': np.float64(0.12659414792060852),\n",
              "      'output_layer': np.float64(0.29399183177947996)},\n",
              "     'num_tokens': 22}},\n",
              "   {'prompt': 'Write a python function to find the average of odd numbers till a given odd number.',\n",
              "    'ground_truth_code': 'def average_Odd(n) : \\r\\n    if (n%2==0) : \\r\\n        return (\"Invalid Input\") \\r\\n        return -1 \\r\\n    sm =0\\r\\n    count =0\\r\\n    while (n>=1) : \\r\\n        count=count+1\\r\\n        sm = sm + n \\r\\n        n = n-2\\r\\n    return sm//count ',\n",
              "    'generated_code': ')\\n\\n the function function that compute the number of all numbers in n certain n number N So',\n",
              "    'test_cases': ['assert average_Odd(9) == 5',\n",
              "     'assert average_Odd(5) == 3',\n",
              "     'assert average_Odd(11) == 6'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.85457587600511,\n",
              "     'tokenization_energy': 0.17457587599754334,\n",
              "     'inference_energy': 28.680000000007567,\n",
              "     'energy_per_token': 1.603031993111395,\n",
              "     'time': 0.5669057369232178,\n",
              "     'components': {'embeddings': np.float64(0.12107591271400452),\n",
              "      'attention': np.float64(14.219552836654824),\n",
              "      'ffn': np.float64(13.700563683742075),\n",
              "      'layernorm': np.float64(0.19773415446281434),\n",
              "      'output_layer': np.float64(0.23547551107406617)},\n",
              "     'num_tokens': 18}},\n",
              "   {'prompt': 'Write a function to find the number of subsequences having product smaller than k for the given non negative array.',\n",
              "    'ground_truth_code': 'def no_of_subsequences(arr, k): \\r\\n\\tn = len(arr) \\r\\n\\tdp = [[0 for i in range(n + 1)] \\r\\n\\t\\t\\tfor j in range(k + 1)] \\r\\n\\tfor i in range(1, k + 1): \\r\\n\\t\\tfor j in range(1, n + 1): \\r\\n\\t\\t\\tdp[i][j] = dp[i][j - 1] \\r\\n\\t\\t\\tif arr[j - 1] <= i and arr[j - 1] > 0: \\r\\n\\t\\t\\t\\tdp[i][j] += dp[i // arr[j - 1]][j - 1] + 1\\r\\n\\treturn dp[k][n]',\n",
              "    'generated_code': ')\\n\\n the function that compute the maximum of uniqueences in exactly equal than or in a given array-negative integers A The',\n",
              "    'test_cases': ['assert no_of_subsequences([1,2,3,4], 10) == 11',\n",
              "     'assert no_of_subsequences([4,8,7,2], 50) == 9',\n",
              "     'assert no_of_subsequences([5,6,7,8], 15) == 4'],\n",
              "    'is_correct': False,\n",
              "    'stats': {'total_energy': 28.82795275354176,\n",
              "     'tokenization_energy': 0.12395275354385375,\n",
              "     'inference_energy': 28.703999999997905,\n",
              "     'energy_per_token': 1.2533892501539896,\n",
              "     'time': 0.5663013458251953,\n",
              "     'components': {'embeddings': np.float64(0.12504066753387452),\n",
              "      'attention': np.float64(9.31502922463289),\n",
              "      'ffn': np.float64(13.984289025776787),\n",
              "      'layernorm': np.float64(0.1276666235923767),\n",
              "      'output_layer': np.float64(4.790999999997439)},\n",
              "     'num_tokens': 23}}],\n",
              "  'summary': {'avg_energy': 25.83692049777992,\n",
              "   'avg_time': 0.5672959794998169,\n",
              "   'energy_per_token': 1.524481974143257,\n",
              "   'accuracy': 0.0,\n",
              "   'carbon_emissions': 394.7307298271932,\n",
              "   'total_examples': 500}}}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from utils.test_generation import test_generation_MBPP\n",
        "MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "test_generation_MBPP(MODEL_NAME)\n",
        "# def run_MBPP_benchmark(quantization=\"fp16\"):\n",
        "#     \"\"\"Run full benchmark with the safest settings\"\"\"\n",
        "#     MODEL_NAME = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "#     print(f\"Running full safe benchmark on {MODEL_NAME}\")\n",
        "\n",
        "#     carbon_intensity = get_carbon_intensity()\n",
        "#     print(f\"Carbon intensity: {carbon_intensity} gCO2eq/kWh\")\n",
        "#     # Use only INT4 for best memory efficiency\n",
        "#     # results = {\n",
        "#     #     'generation': {},\n",
        "#     #     'glue': {}\n",
        "#     # }\n",
        "\n",
        "#     # Clean memory\n",
        "#     clean_memory()\n",
        "#     print_gpu_memory()\n",
        "\n",
        "#     # Part 1: Generation benchmark with INT4 only\n",
        "#     print(f\"\\n==== PART 1: GENERATION BENCHMARK MBPP in {quantization} mode ====\")\n",
        "#     gen_results = compare_generation_energy(\n",
        "#         model_name=MODEL_NAME,\n",
        "#         prompt=\"DeepSeek AI is an advanced language model.\",  # Shorter prompt\n",
        "#         quantization_modes=['int4'],\n",
        "#         verbose=True\n",
        "#     )\n",
        "#     results['generation'] = gen_results\n",
        "\n",
        "#     # Clean up thoroughly between tests\n",
        "#     clean_memory()\n",
        "#     print_gpu_memory()\n",
        "\n",
        "\n",
        "#     # Final cleanup\n",
        "#     clean_memory()\n",
        "#     print_gpu_memory()\n",
        "\n",
        "#     return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "edffbf1fcaa9499bbe4d3c79857d9af4",
            "5e80ecadc000477fbc9650bd0f545d39",
            "955e0ad0aea34c278f8498e239e488df",
            "55eac686068042bc83ba0f9f069bc15c",
            "02544ea003764b429799bdb4fbf5ddd2",
            "bd7f74267439449e86b93f3d2caf5374",
            "e27caf5d66ff48d7b9588a90ed003c28",
            "55857b2ab450453f9aa6e0e083394bd8",
            "779c1a31722f466280118aa720bf155d",
            "a9dcea0778f34259a47eca9c74713b35",
            "47dc775a4c9243a7835931b12f9aee29",
            "88234e461ca6432495a53c3632f6be40",
            "e0f32cd5ed7d475e86e87378b3c1097b",
            "1eff52ca633640f29e5da8e8db153e1d",
            "00e9566f9d814aa896361dabb8991c61",
            "bac0a1a2f5aa4550b7243e45b7ea4b10",
            "c20c6bc23ff444b2b71c7cfd0e54a7f0",
            "ffd64f29561a454bab29075a47661187",
            "3115632c05f449b2a2d553fdd5c7f2fa",
            "4eda3b84042041dcb170fe5c11e30841",
            "fec1968850a24f65995de4f3953cb044",
            "a4e70ffd7a054f1499c5e50818618be7",
            "ca5994f69a6d4b6dbfc95261b9375901",
            "b3fd2840a2a44e029a0cef1a55e70091",
            "2040332449fd4c29800c29ca2d778192",
            "c10d436b4a1645a7a0ff6164c6b61a05",
            "dbdb637014ab49c497b02f7f0ef45f3b",
            "c76874c4d92248b5b565dd0b987a01d3",
            "2f68b96214ed4c68b8d25c0c880064f6",
            "ec0707af77e5470da375777617c1ea43",
            "ff401cb11ef343f8bda8c9dbf05b4123",
            "15319419d55c4abe9f49c37b4a2637d2",
            "ff2f9b3f869d4699a2e972162839b1d2",
            "c6132b7a28384e6e805d2f3af7a3cc70",
            "7c3e63b6a71c4c1e9d6442a369218d8c",
            "48164e8174db423cbe2f015309ae0632",
            "2d1119a28cac49e7ad3ec64171f5bc01",
            "a4629c338475461ca169fc0aa3ddcf88",
            "37ed2ad2e9c94070a1dbc5f95971e4c8",
            "86ab60f2e38745dea1b2c604cba5e280",
            "503625b069354b38a7427c89ead9f8f5",
            "50fdd49376c746dda7a22fdb7b1895d5",
            "9bf5064342b1434ea8268ea70e5f88c6",
            "a34aa5570bb54e09a8a6d1a2a57db5d1",
            "bdf47280f7414da483a551dcc17b100c",
            "f3ce2f2c99644df99ccc3d98acb4d983",
            "975f947466bf4f58bdb0ebd92eabfd1a",
            "4f7a7084d2594f7cb98aae2da902b602",
            "cf93c07a136c41eaa098575613a45ca1",
            "bf7e429c6918452792f80071b5ef6b4e",
            "3d5c5bb572d141439a1d8a693a2b663b",
            "a095f352de934139b5daf2cc5487267b",
            "e834c568f45f4e5e9c09acd64707c54e",
            "b5607ee72c8149bb9ddc16e06cc5c126",
            "57e65d956efa4eefa36c847bf2bb02fd",
            "ab6f6034ebd1430bb646a8abff0a5c03",
            "a5c6fe1172b848afabb7d7e43b217a31",
            "28c67056daa8432a96c26019d5f53714",
            "0c73143807454bdda42e21918db7fb84",
            "ec0c92795dd8424a8c9b256e9862f4ae",
            "94c311e09c6d48598c995cfa1738b8ef",
            "6e9b027d80224b9988344159fed80b9d",
            "0430df46ec1e41afaf9d0738c0ba8a1b",
            "da85a44ebda94ef783e65dcd61ae7e66",
            "c6f16396de654cd4bf0688c569f433ce",
            "0ad0d263a63a4032ae380bd58e40fe56",
            "ff91d073157c4efb982c37b14029a271",
            "1bd5f5b9a40d4828a3eb120b4c9df1bc",
            "e6ded8f29a10419db9f3d07548116251",
            "61341542ff8648fc8ffa1774e69e3e36",
            "f190a2d4de714fe5a66f1d84abaace71",
            "cc44006899ba4c729a14a00ace307646",
            "14b16ba0df494ec3b5d8ff4270f82ca0",
            "915202424b0648b1ab95a497521372a2",
            "85ba597bdd6b47b595165ae786994e19",
            "3ca2ca374be148d3a5c5dbe596db6321",
            "aa76fb16aef94fa2a5149ce76d359141"
          ]
        },
        "id": "SAECKQ8tH8Xx",
        "outputId": "218a2110-45c4-4047-9cf6-c79bbefcf687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running quick test on deepseek-ai/DeepSeek-R1-Distill-Qwen-7B with INT4 quantization\n",
            "GPU Memory: Allocated: 0.01 GB | Reserved: 7.62 GB | Max: 41.77 GB\n",
            "Quick test for deepseek-ai/DeepSeek-R1-Distill-Qwen-7B with int4 quantization\n",
            "Starting to load model in INT4 mode...\n",
            "GPU Memory: Allocated: 0.01 GB | Reserved: 7.62 GB | Max: 41.77 GB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edffbf1fcaa9499bbe4d3c79857d9af4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully in INT4 mode\n",
            "GPU Memory: Allocated: 5.57 GB | Reserved: 15.30 GB | Max: 41.77 GB\n",
            "[2025-04-18 23:04:21,559] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
            "[2025-04-18 23:04:21,559] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
            "Successfully initialized ZeusMonitor\n",
            "Running inference with prompt: 'DeepSeek AI is an advanced open-source language model designed to power AI applications.'\n",
            "Location detected: Council Bluffs, US (lat: 41.2619, lon: -95.8608)\n",
            "Using estimated carbon intensity.\n",
            "Using estimated carbon intensity for US: 417 gCO2eq/kWh\n",
            "\n",
            "Results:\n",
            "Total Energy: 39.6380 J\n",
            "Energy per token: 2.331649 J/token\n",
            "Inference time: 0.583 s\n",
            "Carbon emissions: 4.591406 gCO2eq\n",
            "\n",
            "Component Energy Breakdown:\n",
            "  embeddings: 0.1574 J (0.4%)\n",
            "  attention: 15.8848 J (43.5%)\n",
            "  ffn: 19.7889 J (54.2%)\n",
            "  layernorm: 0.1450 J (0.4%)\n",
            "  output_layer: 0.5376 J (1.5%)\n",
            "Running GLUE benchmark on deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n",
            "GPU Memory: Allocated: 0.01 GB | Reserved: 7.62 GB | Max: 41.77 GB\n",
            "Location detected: Council Bluffs, US (lat: 41.2619, lon: -95.8608)\n",
            "Using estimated carbon intensity.\n",
            "Using estimated carbon intensity for US: 417 gCO2eq/kWh\n",
            "Carbon intensity: 417 gCO2eq/kWh\n",
            "\n",
            "===== Testing GLUE Task: sst2 =====\n",
            "\n",
            "----- Testing INT8 Mode -----\n",
            "Task sst2 has 2 classes\n",
            "Starting to load classifier in INT8 mode...\n",
            "GPU Memory: Allocated: 0.01 GB | Reserved: 7.62 GB | Max: 41.77 GB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88234e461ca6432495a53c3632f6be40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-7B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier loaded successfully in INT8 mode\n",
            "GPU Memory: Allocated: 7.63 GB | Reserved: 7.97 GB | Max: 41.77 GB\n",
            "[2025-04-18 23:04:37,129] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
            "[2025-04-18 23:04:37,129] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
            "Successfully initialized ZeusMonitor\n",
            "Running GLUE task sst2 with int8 quantization...\n",
            "Running GLUE task: sst2\n",
            "Successfully loaded sst2 dataset\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca5994f69a6d4b6dbfc95261b9375901",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6132b7a28384e6e805d2f3af7a3cc70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdf47280f7414da483a551dcc17b100c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Limiting validation dataset to 50 samples (from 872)\n",
            "Dataset columns before processing: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask']\n",
            "Final dataset format: {'type': 'torch', 'format_kwargs': {}, 'columns': ['label', 'input_ids', 'attention_mask'], 'output_all_columns': False}\n",
            "Dataset columns after processing: ['label', 'input_ids', 'attention_mask']\n",
            "Created DataLoader with 50 batches\n",
            "[2025-04-18 23:04:41,004] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
            "[2025-04-18 23:04:41,004] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
            "Successfully initialized ZeusMonitor\n",
            "Evaluating 50 batches...\n",
            "Batch keys: dict_keys(['label', 'input_ids', 'attention_mask'])\n",
            "label shape: torch.Size([1])\n",
            "input_ids shape: torch.Size([1, 48])\n",
            "attention_mask shape: torch.Size([1, 48])\n",
            "Processing batch 1/10...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 2/10...\n",
            "Processing batch 3/10...\n",
            "Processing batch 4/10...\n",
            "Processing batch 5/10...\n",
            "Processing batch 6/10...\n",
            "Processing batch 7/10...\n",
            "Processing batch 8/10...\n",
            "Processing batch 9/10...\n",
            "Processing batch 10/10...\n",
            "Reached batch limit (10). Stopping early to save time.\n",
            "GLUE score: 0.5000\n",
            "Total Energy: 493.6460 J\n",
            "Energy per token: 1.028429 J/token\n",
            "GLUE Score: 0.5000\n",
            "Carbon emissions: 57.180662 gCO2eq\n",
            "\n",
            "----- Testing INT4 Mode -----\n",
            "Task sst2 has 2 classes\n",
            "Starting to load classifier in INT4 mode...\n",
            "GPU Memory: Allocated: 0.01 GB | Reserved: 7.62 GB | Max: 41.77 GB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab6f6034ebd1430bb646a8abff0a5c03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-7B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier loaded successfully in INT4 mode\n",
            "GPU Memory: Allocated: 4.48 GB | Reserved: 7.69 GB | Max: 41.77 GB\n",
            "[2025-04-18 23:05:09,737] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
            "[2025-04-18 23:05:09,737] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
            "Successfully initialized ZeusMonitor\n",
            "Running GLUE task sst2 with int4 quantization...\n",
            "Running GLUE task: sst2\n",
            "Successfully loaded sst2 dataset\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff91d073157c4efb982c37b14029a271",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Limiting validation dataset to 50 samples (from 872)\n",
            "Dataset columns before processing: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask']\n",
            "Final dataset format: {'type': 'torch', 'format_kwargs': {}, 'columns': ['label', 'input_ids', 'attention_mask'], 'output_all_columns': False}\n",
            "Dataset columns after processing: ['label', 'input_ids', 'attention_mask']\n",
            "Created DataLoader with 50 batches\n",
            "[2025-04-18 23:05:13,553] [zeus.monitor.energy](energy.py:209) Monitoring GPU indices [0].\n",
            "[2025-04-18 23:05:13,554] [zeus.monitor.energy](energy.py:210) Monitoring CPU indices []\n",
            "Successfully initialized ZeusMonitor\n",
            "Evaluating 50 batches...\n",
            "Batch keys: dict_keys(['label', 'input_ids', 'attention_mask'])\n",
            "label shape: torch.Size([1])\n",
            "input_ids shape: torch.Size([1, 48])\n",
            "attention_mask shape: torch.Size([1, 48])\n",
            "Processing batch 1/10...\n",
            "Processing batch 2/10...\n",
            "Processing batch 3/10...\n",
            "Processing batch 4/10...\n",
            "Processing batch 5/10...\n",
            "Processing batch 6/10...\n",
            "Processing batch 7/10...\n",
            "Processing batch 8/10...\n",
            "Processing batch 9/10...\n",
            "Processing batch 10/10...\n",
            "Reached batch limit (10). Stopping early to save time.\n",
            "GLUE score: 0.5000\n",
            "Total Energy: 694.1090 J\n",
            "Energy per token: 1.446060 J/token\n",
            "GLUE Score: 0.5000\n",
            "Carbon emissions: 80.400959 gCO2eq\n",
            "\n",
            "----- Efficiency Comparison for sst2 -----\n",
            "Using INT4 as baseline (694.1090 J)\n",
            "INT8 saves 28.88% energy compared to INT4\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'sst2': {'int8': {'task': 'sst2',\n",
              "   'glue_score': 0.5,\n",
              "   'total_energy': 493.6459999998915,\n",
              "   'energy_per_token': 1.0284291666664407,\n",
              "   'throughput': 52.15629287737328,\n",
              "   'total_time': 9.203108072280884,\n",
              "   'total_tokens': 480,\n",
              "   'component_energy': {'embeddings': 3.2358207805156707,\n",
              "    'attention': 307.8890423270283,\n",
              "    'ffn': 272.0061959060663,\n",
              "    'layernorm': 3.6667682304382323,\n",
              "    'output_layer': 0.0},\n",
              "   'carbon_emissions': 57.1806616666541,\n",
              "   'energy_savings': 28.880622495917642},\n",
              "  'int4': {'task': 'sst2',\n",
              "   'glue_score': 0.5,\n",
              "   'total_energy': 694.1090000001132,\n",
              "   'energy_per_token': 1.4460604166669024,\n",
              "   'throughput': 50.31287752321803,\n",
              "   'total_time': 9.540301084518433,\n",
              "   'total_tokens': 480,\n",
              "   'component_energy': {'embeddings': 8.08597039892664,\n",
              "    'attention': 449.81224457510655,\n",
              "    'ffn': 447.4687229082501,\n",
              "    'layernorm': 4.616246213912963,\n",
              "    'output_layer': 0.0},\n",
              "   'carbon_emissions': 80.40095916667978}}}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00e9566f9d814aa896361dabb8991c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fec1968850a24f65995de4f3953cb044",
            "placeholder": "​",
            "style": "IPY_MODEL_a4e70ffd7a054f1499c5e50818618be7",
            "value": " 2/2 [00:09&lt;00:00,  4.54s/it]"
          }
        },
        "02544ea003764b429799bdb4fbf5ddd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0430df46ec1e41afaf9d0738c0ba8a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "086ede220eae40cbb89ed0903c113444": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad0d263a63a4032ae380bd58e40fe56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c73143807454bdda42e21918db7fb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f16396de654cd4bf0688c569f433ce",
            "placeholder": "​",
            "style": "IPY_MODEL_0ad0d263a63a4032ae380bd58e40fe56",
            "value": " 2/2 [00:09&lt;00:00,  4.61s/it]"
          }
        },
        "14b16ba0df494ec3b5d8ff4270f82ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15319419d55c4abe9f49c37b4a2637d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd5f5b9a40d4828a3eb120b4c9df1bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc44006899ba4c729a14a00ace307646",
            "placeholder": "​",
            "style": "IPY_MODEL_14b16ba0df494ec3b5d8ff4270f82ca0",
            "value": "Map: 100%"
          }
        },
        "1eff52ca633640f29e5da8e8db153e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3115632c05f449b2a2d553fdd5c7f2fa",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4eda3b84042041dcb170fe5c11e30841",
            "value": 2
          }
        },
        "2040332449fd4c29800c29ca2d778192": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0707af77e5470da375777617c1ea43",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff401cb11ef343f8bda8c9dbf05b4123",
            "value": 67349
          }
        },
        "2181aff111534ffcb8a2135ce0eebcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99e7217490484dc787603199a9c010ef",
              "IPY_MODEL_23b2354c8fe9472eb8fc2e3fd35ea85b",
              "IPY_MODEL_c8fa98b9a86d4a7b9d061801d99c6322"
            ],
            "layout": "IPY_MODEL_f842a74d578e4c12b48b42016d42c5db"
          }
        },
        "23b2354c8fe9472eb8fc2e3fd35ea85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4898ad2260c244928d90cc7d12df9a50",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8542633b8f1d483d88c09499a1f760cd",
            "value": 2
          }
        },
        "28c67056daa8432a96c26019d5f53714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0430df46ec1e41afaf9d0738c0ba8a1b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da85a44ebda94ef783e65dcd61ae7e66",
            "value": 2
          }
        },
        "2d1119a28cac49e7ad3ec64171f5bc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf5064342b1434ea8268ea70e5f88c6",
            "placeholder": "​",
            "style": "IPY_MODEL_a34aa5570bb54e09a8a6d1a2a57db5d1",
            "value": " 872/872 [00:00&lt;00:00, 18900.97 examples/s]"
          }
        },
        "2f68b96214ed4c68b8d25c0c880064f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3115632c05f449b2a2d553fdd5c7f2fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d3d15ccc5a46c2b704c68b4697a5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37ed2ad2e9c94070a1dbc5f95971e4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca2ca374be148d3a5c5dbe596db6321": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d5c5bb572d141439a1d8a693a2b663b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "443f27f2ab074fe2b80d196a7f18bef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47dc775a4c9243a7835931b12f9aee29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48164e8174db423cbe2f015309ae0632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_503625b069354b38a7427c89ead9f8f5",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50fdd49376c746dda7a22fdb7b1895d5",
            "value": 872
          }
        },
        "4898ad2260c244928d90cc7d12df9a50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eda3b84042041dcb170fe5c11e30841": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f7a7084d2594f7cb98aae2da902b602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5607ee72c8149bb9ddc16e06cc5c126",
            "placeholder": "​",
            "style": "IPY_MODEL_57e65d956efa4eefa36c847bf2bb02fd",
            "value": " 1821/1821 [00:00&lt;00:00, 22183.64 examples/s]"
          }
        },
        "503625b069354b38a7427c89ead9f8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50fdd49376c746dda7a22fdb7b1895d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55857b2ab450453f9aa6e0e083394bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55eac686068042bc83ba0f9f069bc15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9dcea0778f34259a47eca9c74713b35",
            "placeholder": "​",
            "style": "IPY_MODEL_47dc775a4c9243a7835931b12f9aee29",
            "value": " 2/2 [00:09&lt;00:00,  4.78s/it]"
          }
        },
        "57e65d956efa4eefa36c847bf2bb02fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e80ecadc000477fbc9650bd0f545d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd7f74267439449e86b93f3d2caf5374",
            "placeholder": "​",
            "style": "IPY_MODEL_e27caf5d66ff48d7b9588a90ed003c28",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "61341542ff8648fc8ffa1774e69e3e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ca2ca374be148d3a5c5dbe596db6321",
            "placeholder": "​",
            "style": "IPY_MODEL_aa76fb16aef94fa2a5149ce76d359141",
            "value": " 67349/67349 [00:02&lt;00:00, 20383.12 examples/s]"
          }
        },
        "6e9b027d80224b9988344159fed80b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "779c1a31722f466280118aa720bf155d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c3e63b6a71c4c1e9d6442a369218d8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37ed2ad2e9c94070a1dbc5f95971e4c8",
            "placeholder": "​",
            "style": "IPY_MODEL_86ab60f2e38745dea1b2c604cba5e280",
            "value": "Map: 100%"
          }
        },
        "8542633b8f1d483d88c09499a1f760cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85ba597bdd6b47b595165ae786994e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86ab60f2e38745dea1b2c604cba5e280": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88234e461ca6432495a53c3632f6be40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f32cd5ed7d475e86e87378b3c1097b",
              "IPY_MODEL_1eff52ca633640f29e5da8e8db153e1d",
              "IPY_MODEL_00e9566f9d814aa896361dabb8991c61"
            ],
            "layout": "IPY_MODEL_bac0a1a2f5aa4550b7243e45b7ea4b10"
          }
        },
        "915202424b0648b1ab95a497521372a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94c311e09c6d48598c995cfa1738b8ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955e0ad0aea34c278f8498e239e488df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55857b2ab450453f9aa6e0e083394bd8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_779c1a31722f466280118aa720bf155d",
            "value": 2
          }
        },
        "975f947466bf4f58bdb0ebd92eabfd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a095f352de934139b5daf2cc5487267b",
            "max": 1821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e834c568f45f4e5e9c09acd64707c54e",
            "value": 1821
          }
        },
        "99e7217490484dc787603199a9c010ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91c56525cc44258a8034e67a9256301",
            "placeholder": "​",
            "style": "IPY_MODEL_443f27f2ab074fe2b80d196a7f18bef5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9bf5064342b1434ea8268ea70e5f88c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a095f352de934139b5daf2cc5487267b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34aa5570bb54e09a8a6d1a2a57db5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4629c338475461ca169fc0aa3ddcf88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e70ffd7a054f1499c5e50818618be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5c6fe1172b848afabb7d7e43b217a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c311e09c6d48598c995cfa1738b8ef",
            "placeholder": "​",
            "style": "IPY_MODEL_6e9b027d80224b9988344159fed80b9d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a91c56525cc44258a8034e67a9256301": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9dcea0778f34259a47eca9c74713b35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa76fb16aef94fa2a5149ce76d359141": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab6f6034ebd1430bb646a8abff0a5c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5c6fe1172b848afabb7d7e43b217a31",
              "IPY_MODEL_28c67056daa8432a96c26019d5f53714",
              "IPY_MODEL_0c73143807454bdda42e21918db7fb84"
            ],
            "layout": "IPY_MODEL_ec0c92795dd8424a8c9b256e9862f4ae"
          }
        },
        "b3fd2840a2a44e029a0cef1a55e70091": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76874c4d92248b5b565dd0b987a01d3",
            "placeholder": "​",
            "style": "IPY_MODEL_2f68b96214ed4c68b8d25c0c880064f6",
            "value": "Map: 100%"
          }
        },
        "b5607ee72c8149bb9ddc16e06cc5c126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bac0a1a2f5aa4550b7243e45b7ea4b10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7f74267439449e86b93f3d2caf5374": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf47280f7414da483a551dcc17b100c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3ce2f2c99644df99ccc3d98acb4d983",
              "IPY_MODEL_975f947466bf4f58bdb0ebd92eabfd1a",
              "IPY_MODEL_4f7a7084d2594f7cb98aae2da902b602"
            ],
            "layout": "IPY_MODEL_cf93c07a136c41eaa098575613a45ca1"
          }
        },
        "bf7e429c6918452792f80071b5ef6b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c10d436b4a1645a7a0ff6164c6b61a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15319419d55c4abe9f49c37b4a2637d2",
            "placeholder": "​",
            "style": "IPY_MODEL_ff2f9b3f869d4699a2e972162839b1d2",
            "value": " 67349/67349 [00:02&lt;00:00, 27802.75 examples/s]"
          }
        },
        "c20c6bc23ff444b2b71c7cfd0e54a7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6132b7a28384e6e805d2f3af7a3cc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c3e63b6a71c4c1e9d6442a369218d8c",
              "IPY_MODEL_48164e8174db423cbe2f015309ae0632",
              "IPY_MODEL_2d1119a28cac49e7ad3ec64171f5bc01"
            ],
            "layout": "IPY_MODEL_a4629c338475461ca169fc0aa3ddcf88"
          }
        },
        "c6f16396de654cd4bf0688c569f433ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76874c4d92248b5b565dd0b987a01d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8fa98b9a86d4a7b9d061801d99c6322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_086ede220eae40cbb89ed0903c113444",
            "placeholder": "​",
            "style": "IPY_MODEL_36d3d15ccc5a46c2b704c68b4697a5a5",
            "value": " 2/2 [00:09&lt;00:00,  4.77s/it]"
          }
        },
        "ca5994f69a6d4b6dbfc95261b9375901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3fd2840a2a44e029a0cef1a55e70091",
              "IPY_MODEL_2040332449fd4c29800c29ca2d778192",
              "IPY_MODEL_c10d436b4a1645a7a0ff6164c6b61a05"
            ],
            "layout": "IPY_MODEL_dbdb637014ab49c497b02f7f0ef45f3b"
          }
        },
        "cc44006899ba4c729a14a00ace307646": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf93c07a136c41eaa098575613a45ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da85a44ebda94ef783e65dcd61ae7e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbdb637014ab49c497b02f7f0ef45f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f32cd5ed7d475e86e87378b3c1097b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c20c6bc23ff444b2b71c7cfd0e54a7f0",
            "placeholder": "​",
            "style": "IPY_MODEL_ffd64f29561a454bab29075a47661187",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e27caf5d66ff48d7b9588a90ed003c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6ded8f29a10419db9f3d07548116251": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_915202424b0648b1ab95a497521372a2",
            "max": 67349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85ba597bdd6b47b595165ae786994e19",
            "value": 67349
          }
        },
        "e834c568f45f4e5e9c09acd64707c54e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec0707af77e5470da375777617c1ea43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec0c92795dd8424a8c9b256e9862f4ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edffbf1fcaa9499bbe4d3c79857d9af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e80ecadc000477fbc9650bd0f545d39",
              "IPY_MODEL_955e0ad0aea34c278f8498e239e488df",
              "IPY_MODEL_55eac686068042bc83ba0f9f069bc15c"
            ],
            "layout": "IPY_MODEL_02544ea003764b429799bdb4fbf5ddd2"
          }
        },
        "f190a2d4de714fe5a66f1d84abaace71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ce2f2c99644df99ccc3d98acb4d983": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf7e429c6918452792f80071b5ef6b4e",
            "placeholder": "​",
            "style": "IPY_MODEL_3d5c5bb572d141439a1d8a693a2b663b",
            "value": "Map: 100%"
          }
        },
        "f842a74d578e4c12b48b42016d42c5db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec1968850a24f65995de4f3953cb044": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2f9b3f869d4699a2e972162839b1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff401cb11ef343f8bda8c9dbf05b4123": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff91d073157c4efb982c37b14029a271": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bd5f5b9a40d4828a3eb120b4c9df1bc",
              "IPY_MODEL_e6ded8f29a10419db9f3d07548116251",
              "IPY_MODEL_61341542ff8648fc8ffa1774e69e3e36"
            ],
            "layout": "IPY_MODEL_f190a2d4de714fe5a66f1d84abaace71"
          }
        },
        "ffd64f29561a454bab29075a47661187": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
